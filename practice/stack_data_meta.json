{"7": {"ParentId": 4, "Score": 17, "Body": "<p>No, data science and the implementation of artificial intelligence are off-topic. <a href=\"https://area51.meta.stackexchange.com/a/24016/136466\">A community manager explicitly said so in the Area 51 discussions for this site.</a> There have been at least two AI sites on SE before, and they've all failed. We need to bring something new to the table, especially in the private beta stage. Once that's over, we can consider whether we can bring a new viewpoint to such questions.</p>\n"}, "8": {"ParentId": 4, "Score": 6, "Body": "<p>Definitely not. In some minutes we can see lots of questions asking for specific technical solutions about neural networks and genetic algorithms. I agree with Ben that we need to make this site different and start migrating all these questions to other sites, where there <em>is already</em> an answer to most of them.</p>\n\n<p>Why would we want to ask them again?\n(apart from rush for reputation)</p>\n"}, "10": {"ParentId": 2, "Score": 6, "Body": "<p>I created a new <a href=\"http://chat.stackexchange.com/rooms/43371/artificial-intelligence\">chat room for this site</a>.</p>\n\n<p>Seems like the one from the previous AI site prevented creating a chat room.</p>\n"}, "12": {"ParentId": 4, "Score": 3, "Body": "<p>I'm going to say \"yes\".  That doesn't mean we need to <em>solicit</em> those kinds of questions, but if / when they show up, I think we should just handle them \"organically\" if you will.  That is, up/down vote them, answer them, comment on them, etc., exactly as we would anything else.  I don't see any point in us taking on the effort of cross-checking with other sites and migrating questions, etc.   IF the SE infrastructure makes it super easy to do some in some cases, then sure, fine, I guess.  But I oppose having ai.se mods waste their energy and time dealing with pedantic quibbling over which site is \"most\" appropriate for a question.</p>\n"}, "13": {"ParentId": 11, "Score": 7, "Body": "<p>If an answer is wrong, it should be downvoted, plain and simple. Clearly we want to discourage wrong information, and downvotes are designed to point out incorrect, irrelevant, or otherwise poor content. You seem to have really good examples that show such answers are wrong, so please feel free to mention them in a comment when downvoting!</p>\n"}, "14": {"ParentId": 6, "Score": 7, "Body": "<p>Experience with many beta sites from the start and through initial pro-tem moderation suggests that yes, for questions that could be on topic, let's give the benefit of the doubt in the early stages to help growth.</p>\n\n<p>For posts that are definitely off topic, close them down as fast as possible, though - and a good way to do this in the Public Beta stage before we hit critical mass is to have frequent use of the chat room and point the CM's or mods at such questions.</p>\n\n<p>Once we have a good number of folks with close privileges, it gets easier and I'd agree that normal voting should carry it from there.</p>\n\n<p>The corollary to this is that we must use our votes. Upvote good posts, and downvote the bad ones - this helps make sure the good ones are seen and their owners rewarded, but also gets us that critical mass of users with the necessary privileges as fast as possible.</p>\n"}, "16": {"ParentId": 1, "Score": 5, "Body": "<p>As Franck neatly put: First step would be to clearly define the scope of the site.</p>\n\n<p>Next, there are very active Data Science, AI and ML communities on Reddit and other community sites like facebook groups, etc; and they would be an excellent way to get new users.</p>\n\n<p>And as AI is a very hot topic right now, we would be getting traffic and users as long as we keep the scope well pruned and the posts well curated.</p>\n"}, "17": {"ParentId": 15, "Score": 9, "Body": "<p>To answer the title question, easy-to-Google questions are <strong>not OK</strong> for the private beta. Flooding the site with trivial questions and simple answers is a great way to demolish any chance of attracting big-name experts. Artificial intelligence site proposals have already failed a couple times - once explicitly <a href=\"https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/\">because of terribad pedestrian questions</a>.</p>\n\n<p>If we want to survive and grow, we have to keep quality high. We can do that by downvoting low-effort questions and closing non-constructive questions (e.g. requests for off-site resources). And of course, we'll need to dig into the literature to see what kinds of good questions we can explore.</p>\n"}, "19": {"ParentId": 4, "Score": 5, "Body": "<p><strong>Yes</strong></p>\n\n<p>I am sorry to be the one who posts Yes, but as we are in the beta, I want to be straight forward.</p>\n\n<p>In addition to that, AI is also on-topic in the CS site. <a href=\"https://area51.meta.stackexchange.com/q/22939/142759\">I was the one who raised this in the definition phase</a>.</p>\n\n<p>So, a lot of topic which this site aims to cover are already covered in the existing sites.</p>\n"}, "20": {"ParentId": 9, "Score": 6, "Body": "<p>Most Stack Exchange sites (including this one) are English-only, and it's not expected that users will be able to use other languages. Therefore, if there are resources that are not available in English, it would be very good to make them accessible to English speakers somewhere, and this site would be a fine place for doing so. </p>\n\n<p>Make sure, of course, that the question is good (i.e. well-researched, not trivially Google-able in English) and constructive (i.e. on-topic). To avoid accusations of cross-language plagiarism, try to paraphrase rather than translating word-for-word. In the same vein, link back to the original site when you draw heavily from it. That's all part of being a good Internet citizen. If you can improve the answer by drawing from additional sources, that's great too!</p>\n\n<p>Relevant SE blog post: <a href=\"https://blog.stackoverflow.com/2011/02/are-some-questions-too-simple/\">Are some questions too simple?</a></p>\n"}, "21": {"ParentId": 5, "Score": 7, "Body": "<p>Stack Exchange sites have a mechanism called \"intrinsic tag blacklisting\" that's intended to do exactly this - prevent the tag that simply describes the topic from being used.</p>\n\n<p>However, the way the system works means that it doesn't always work. The system takes the URL slug <em>before</em> <code>.stackexchange.com</code>, and blacklists that as an intrinsic tag. For this site, that means that the <a href=\"https://ai.stackexchange.com/questions/tagged/ai\" class=\"post-tag\" title=\"show questions tagged &#39;ai&#39;\" rel=\"tag\">ai</a> tag is blacklisted, but <a href=\"https://ai.stackexchange.com/questions/tagged/artificial-intelligence\" class=\"post-tag\" title=\"show questions tagged &#39;artificial-intelligence&#39;\" rel=\"tag\">artificial-intelligence</a> is not. That's the explanation of the bug.</p>\n"}, "23": {"ParentId": 18, "Score": 3, "Body": "<p>I would say yes. I don't know many people who use the term \"deep network\" like that. You may hear \"deep neural network\", but that's still basically synonymous with \"deep learning\" as far as I can tell.</p>\n"}, "24": {"ParentId": 22, "Score": 12, "Body": "<p>Certainly, asking real AI researchers to join would be great!</p>\n\n<p>Paper authors include their e-mail addresses in their publications exactly for the purpose of being contacted about their work. I'm sure it would bring most students great happiness to know that their work has been noticed.</p>\n\n<p>Students who aren't terribly busy will probably be willing to read all the e-mails they receive in their academic/professional e-mail inboxes, no matter whether the messages from from an <code>@stackexchange.com</code> address or a personal address. Indeed, composing a personal (non-automated) message mentioning how you enjoyed a paper would be appreciated, even if the person doesn't have the time or inclination to check out our site.</p>\n"}, "26": {"ParentId": 22, "Score": 4, "Body": "<p>Yes, that sounds like an excellent idea to me.  </p>\n"}, "28": {"ParentId": 5, "Score": 7, "Body": "<p>It appears that a community manager has now blacklisted <a href=\"https://ai.stackexchange.com/questions/tagged/artificial-intelligence\" class=\"post-tag\" title=\"show questions tagged &#39;artificial-intelligence&#39;\" rel=\"tag\">artificial-intelligence</a>. Questions that only had that tag are now <a href=\"https://ai.stackexchange.com/questions/tagged/untagged\" class=\"post-tag\" title=\"show questions tagged &#39;untagged&#39;\" rel=\"tag\">untagged</a>. (The version without the hyphen, <a href=\"https://ai.stackexchange.com/questions/tagged/artificialintelligence\" class=\"post-tag\" title=\"show questions tagged &#39;artificialintelligence&#39;\" rel=\"tag\">artificialintelligence</a>, is blocked too.)</p>\n"}, "29": {"ParentId": 27, "Score": 2, "Body": "<p><a href=\"https://ai.stackexchange.com/questions/tagged/artificial-intelligence\" class=\"post-tag\" title=\"show questions tagged &#39;artificial-intelligence&#39;\" rel=\"tag\">artificial-intelligence</a> is what SE calls an <strong>intrinsic</strong> tag, as is <a href=\"https://ai.stackexchange.com/questions/tagged/ai\" class=\"post-tag\" title=\"show questions tagged &#39;ai&#39;\" rel=\"tag\">ai</a>.</p>\n\n<p>Intrinsic tags are effectively pointless tags on a site, ie this site is about artificial intelligence, so does not need a tag on artificial intelligence. Likewise, <a href=\"https://ai.stackexchange.com/questions/tagged/programming\" class=\"post-tag\" title=\"show questions tagged &#39;programming&#39;\" rel=\"tag\">programming</a> is not needed on Programming.SE</p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/tagged/optimization\" class=\"post-tag\" title=\"show questions tagged &#39;optimization&#39;\" rel=\"tag\">optimization</a> is much more relevant, as it is a specific class of questions within the site scope.</p>\n"}, "31": {"ParentId": 25, "Score": 1, "Body": "<p>For those unfamiliar, the <a href=\"https://en.wikipedia.org/wiki/Semantic_Web\" rel=\"nofollow\">Semantic Web</a> is basically an extension to HTML that calls out the content of certain elements as certain kinds of information. For example, the sentence \"John Smith was born in Chicago\" would have the name and birthplace marked up appropriately, with a reference to a schema on the enclosing element.</p>\n\n<p>It doesn't seem like the Semantic Web is itself an AI thing, but if questions about artificial intelligence happen to touch on it, I see no reason to reject them.</p>\n"}, "32": {"ParentId": 30, "Score": 4, "Body": "<p>If a question is off-topic here, just close it with the generic off-topic reason. Our scope isn't set in stone yet, so we want to keep things on our site in case they need to be reopened. If a <strong>question owner</strong> - not just any user passing by - really wants their question migrated, they can raise a custom mod flag and a CM will take care of it. (Though if the question didn't get any answers, it's easier to just delete it here and ask it somewhere else.)</p>\n\n<p>Once the site graduates, we'll get migration paths to other SE sites and we'll become eligible as a migration target from other sites.</p>\n"}, "34": {"ParentId": 33, "Score": 3, "Body": "<p>Certainly, assuming the questions are reasonably scoped. \"What are the principles of computer vision?\" would be way too broad and closed as such. More specific questions like \"Can a computer know the difference between someone's face and a printed-out held-up photograph of that face?\" would be interesting.</p>\n\n<p>Do be careful that we don't get bogged down in the implementation, which is the subject of existing sites like Data Science. Programming is also off-topic, in my understanding. We're focused on the academic/somewhat-theoretical aspects of artificial intelligence.</p>\n"}, "36": {"ParentId": 35, "Score": 4, "Body": "<p>While it might be nice to have for some questions, most questions you would need LaTeX for should be off-topic here. This site is not meant for machine learning questions, as Cross Validated and Data Science Stack Exchange sufficiently cover those subjects. </p>\n\n<p>See: <a href=\"https://ai.meta.stackexchange.com/questions/4/are-all-questions-asked-on-stats-and-data-science-se-also-on-topic-here?cb=1\">Are all questions asked on stats and data science SE also on topic here?</a></p>\n\n<blockquote>\n  <p><strong>Note:</strong> I posted this answer when I didn't know very much about AI, and I have misunderstood or missed some of the parts of AI that should be on-topic here, I am now of the opinion that we should have LaTeX here. I'll leave this answer here because of the votes (and vote balance) on it, but I don't agree myself anymore with it. So please count an extra downvote from me.</p>\n</blockquote>\n"}, "37": {"ParentId": 18, "Score": 1, "Body": "<p>If <code>deep-learning</code> is preferred, then <code>deep-network</code> should be set up as a <a href=\"https://meta.stackexchange.com/a/70718/135236\">tag synonym</a> for it, that way if anyone tries to use it, it gets mapped to the preferred name.  We need someone with 1250 reputation to do that.</p>\n"}, "39": {"ParentId": 38, "Score": 8, "Body": "<h1>Turing Testing Room</h1>\n\n<p>A play on the term \"Turing test\" (an examination of how well a machine mimics natural conversation with a human): tests taken by human students are usually administered in a testing room.</p>\n\n<p>Questions on the main site are currently posted to the ticker, so we don't see the username, but if that's changed, it could be called <strong><a href=\"https://en.wikipedia.org/wiki/Multivac\" rel=\"nofollow\">Multivac</a></strong> after the computer from some of Asimov's stories. We could call the meta bot <strong><a href=\"https://en.wikipedia.org/wiki/Watson_(computer)\" rel=\"nofollow\">Watson</a></strong>.</p>\n"}, "41": {"ParentId": 38, "Score": 2, "Body": "<h1>Automata</h1>\n\n<p>Study of abstract machines as well as the computational problems that can be solved using them.</p>\n"}, "42": {"ParentId": 38, "Score": 3, "Body": "<h1>The Thought</h1>\n\n<blockquote>\n  <p>Artificial intelligence is based on the assumption that the process of human <strong>thought</strong> can be mechanized.</p>\n</blockquote>\n"}, "43": {"ParentId": 38, "Score": 15, "Body": "<h2><strong>The Singularity</strong></h2>\n\n<p>I probably don't need to explain that :-)</p>\n\n<p>And for the bots, how about Daneel and Giskard?</p>\n"}, "44": {"ParentId": 38, "Score": 2, "Body": "<h1>Searle's Room</h1>\n\n<p>Bots: Meta &amp; Cognition</p>\n"}, "45": {"ParentId": 40, "Score": 5, "Body": "<p>First up, when I posted <a href=\"https://ai.meta.stackexchange.com/a/7/75\">my answer to the question you reference</a>, I was just passing along the information given to us by Robert Cartaino. I'm not wedded to that opinion.</p>\n\n<p>I think all the scientists working on AI would be helpful here even though we're not working on implementation. This is what the original Area 51 Discussion post said (excerpted):</p>\n\n<blockquote>\n  <p>Data Science is an <em>applied</em> site for all the programmers/statisticians/mathematicians who are trying to make this stuff <em>work</em>.</p>\n</blockquote>\n\n<p>There's some leeway there. Specifically, technical questions seem to be OK, as long as they're not super in depth about the math or programming. There are also \"why\" questions (as opposed to \"how\") that are very interesting and educational. I like <a href=\"https://ai.stackexchange.com/q/92/75\">this question</a> a lot. Scientists are welcome.</p>\n\n<p>We don't <em>have</em> to limit ourselves to the philosophy and practical effects of AI, though they're in scope. Philosophers are welcome too.</p>\n"}, "46": {"ParentId": 40, "Score": 6, "Body": "<p>First there is a need to distinguish modeling from implementation. They are not exactly the same, although strongly related. This was a very difficult lesson to learn among mathematicians and early programmers, notably in the 70s (mathematical proofs can demand a lot of non-trivial programming work to make them \"computable\", as in runnable on a computer).</p>\n\n<p>As for Machine Learning (by far the most active AI category), modeling belongs to Data Science SE---perhaps the one thing that most people agree on. Implementation should be out of there, as the issues and focus differ (but again, they are related).</p>\n\n<p>Now, should implementation issues be in AI SE, or StackOverflow? The recurring example is TensorFlow, who's home page states that questions should go to StackOverflow. And we should respect that...</p>\n\n<p>But we should keep in mind that the TensorFlow team will choose SO, because it is the largest community, and because the team has something else to do rather than experimenting with hardly visible communities. Well, size matters. We may think that if AI SE becomes big enough on the implementation side, the TensorFlow team (and other major frameworks) may move actually.</p>\n\n<p>In fact, I think now that implementation questions would benefit from a dedicated site (my view has evolved since the Area 51 definition phase). I have replied and tried to reply to several SO questions related to ML tools, and I think some are out of place compared to other questions. For example, <a href=\"https://stackoverflow.com/questions/38321024/why-this-simple-tensorflow-code-is-not-successful-convnetjs-using-tensorflow/38368469#comment64172189_38368469\">some</a> TensorFlow questions are not really programming questions, and not really framework questions. I mean, there is background knowledge on graph construction and execution, as well as background knowledge about statistics and probabilities that are really necessary to make meaningful contributions.</p>\n\n<p>This is not to say that <em>all</em> questions are out of place on SO. <a href=\"https://stackoverflow.com/questions/38297581/tensorflow-gpu-utilization-is-almost-always-at-0#comment64124967_38297581\">Some</a> are <em>really</em> framework issues or (Python) programming issues, and they are good there.</p>\n\n<p>Based on this opinion, I think the site should be interested in implementation experts, whether they work on ML or Expert Systems (or both?).</p>\n\n<p>See also some threads on Area 51 like <a href=\"https://area51.meta.stackexchange.com/questions/23789/the-example-questions-will-not-attract-experts\">this one</a> and <a href=\"https://area51.meta.stackexchange.com/a/23528/69948\">this one</a>.</p>\n"}, "47": {"ParentId": 11, "Score": 2, "Body": "<blockquote>\n  <p>I'm seeing a lot of answers from people along the lines of \"AI is just bits and bytes and ultimately cannot be smarter than its creator because its creator would have to use their brain to make something smarter than themselves, which isn't possible.\"</p>\n</blockquote>\n\n<p>I think this argument is a bit unclear and needs some refinement. It is true that AI can indeed be smarter than the creator at certain tasks (AlphaGo being better at Go than the programmers of AlphaGo, for instance). What I think this argument is really saying is:</p>\n\n<blockquote>\n  <p>\"AI is just bits and bytes programmed by its creator. The creator would be able to <em>know</em> how the AI works, otherwise he would be unable to create it in the first place. Therefore, the creator can be said to be <em>superior</em> to that of its creation, since the creator can understand its creation.\"</p>\n</blockquote>\n\n<p>That seems like a more logical premise. Sure, AlphaGo is better at Go than the programmers of AlphaGo, but AlphaGo's programmers actually knows how AlphaGo operates. This type of argument was made in the paper <a href=\"http://kryten.mm.rpi.edu/lovelace.pdf\" rel=\"nofollow\">Creativity, the Turing Test, and the (better) Lovelace Test</a>, which specifically argues that  AIs cannot be creative since programmers are able to figure out what their creations (AIs) are doing. Another paper <a href=\"http://arxiv.org/pdf/1410.6142v3.pdf\" rel=\"nofollow\">\"The Lovelace 2.0 Test of Artificial Creativity and Intelligence\"</a> saw this argument as so self-evidently true that it tried to create a weaker version of the Lovelace Test to identify and measure AI creativity.</p>\n\n<p>The programmers, basically, know how their program works. That doesn't mean the program is less intelligent than the programmers. Just that the programmers can understand why their programs behave the way they do, given enough time and patience.</p>\n\n<p>Either way, I would not support discouraging answers such as these, if only because this view does have support within the AI scholarly community. If you have experts who hold this view, then we should let this view be given exposure.</p>\n"}, "48": {"ParentId": 38, "Score": 4, "Body": "<h1><strong>The nth layer</strong></h1>\n<p>This would be about deep learning which is about multiple layers of neurons. So, as DL has been very hot in the domain currently, I think this name would be appropriate.</p>\n"}, "49": {"ParentId": 38, "Score": 2, "Body": "<h1>Replicants</h1>\n\n<p>As in Blade Runner. And HAL and Computer for the bots.</p>\n"}, "50": {"ParentId": 38, "Score": 4, "Body": "<p><strong>Electric sheep</strong></p>\n\n<p>I think everyone knows this, just in case: <a href=\"https://en.wikipedia.org/wiki/Do_Androids_Dream_of_Electric_Sheep%3F\" rel=\"nofollow\">wiki link</a></p>\n"}, "51": {"ParentId": 38, "Score": 5, "Body": "<h1>The Chinese Room</h1>\n<p>A reference to the <a href=\"https://en.wikipedia.org/wiki/Chinese_room\" rel=\"nofollow noreferrer\">Chinese Room Argument</a>.</p>\n<p>We would need to make it clear that we're separate from <a href=\"https://chinese.stackexchange.com\">Chinese.SE</a> though...!</p>\n<p>One of the bots could be named Searle, who invented the thought experiment.<br />\nThen we really have a Searle getting inputs and producing outputs, just as in the thought experiment.</p>\n"}, "52": {"ParentId": 38, "Score": 4, "Body": "<h2>Back Propagation</h2>\n<p>A reference to backpropagation neural networks. We could use this name because in our chatroom, ideas will be propagated back and forth.</p>\n"}, "56": {"ParentId": 53, "Score": 4, "Body": "<p>In British English it has to be \"AI\". \nIn American English it can be both \"AI\" and \"A.I.\".</p>\n\n<p>Sources:</p>\n\n<ul>\n<li><a href=\"http://www.oxforddictionaries.com/us/words/punctuation-in-abbreviations-american\" rel=\"nofollow\">http://www.oxforddictionaries.com/us/words/punctuation-in-abbreviations-american</a></li>\n<li>Oxford A\u2013Z of Grammar and Punctuation by John Seely.</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Full_stop#Abbreviations_and_personal_titles_of_address\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Full_stop#Abbreviations_and_personal_titles_of_address</a></li>\n</ul>\n"}, "57": {"ParentId": 27, "Score": 2, "Body": "<p>AGI stands for Artificial General Intelligence, which is an AI that's powerful enough to be applied in general. A human would be an AGI, so to say - the human is generally applicable. So when your question is about such an AI - one that is not made for one specific task, but instead for things in general - where you'd need an AI that can think and learn as it goes - to deal with moving goalposts - that's the sort of question you'd use <a href=\"https://ai.stackexchange.com/questions/tagged/agi\" class=\"post-tag\" title=\"show questions tagged &#39;agi&#39;\" rel=\"tag\">agi</a> for.</p>\n"}, "58": {"ParentId": 54, "Score": 1, "Body": "<p>I'd (personally) go for <strong>computing</strong> because it is about doing things with computers rather than the computers themselves, as you state in the question yourself.</p>\n"}, "60": {"ParentId": 55, "Score": 3, "Body": "<p>The question you link is a perfectly valid question in the philosophy of artificial intelligence. Philosophy is the other large part of AI, together with technology, so they should be on-topic here.</p>\n\n<p>However, one should be careful when answering these questions, that one does not base the answer on own opinions. One should reference what philosophers have said in the past, like one of the answers on the question you link mentions the Trolley problem.</p>\n"}, "61": {"ParentId": 59, "Score": 1, "Body": "<p>Migration to and from this site, in private beta, is most likely not going to be done. You'd have to invite people to the community in order for them to see the question - and when it comes to migrating from this site, it's easier to just close and re-ask (provided there are no answers yet).</p>\n\n<p>After private beta... well, I suppose you could post a comment on such an Stack Overflow question that their question might be better off at ai.stackexchange. But those would have to be some good questions, and they'd have to be served here better than at Stack Overflow.</p>\n\n<p>As for the example question, I think such a migration wouldn't be helping all that much - it's already answered, and as you can see, after migration, not much else happened to the question. It seems it was moved because both the asker and the answerer have an established presence on the other site, and because it fits better there. </p>\n\n<p>Migration is not something to do quickly.</p>\n"}, "63": {"ParentId": 59, "Score": 6, "Body": "<p>No, that wouldn't happen. A site only becomes eligible as a migration target from other sites' close dialogs after it loses the \"beta\" label entirely. Also, questions older than 60 days <a href=\"https://meta.stackexchange.com/a/156255/295684\">cannot be migrated</a>, even by moderators! The migration you mentioned took place before that rule was instated.</p>\n\n<p>Besides, a question being on-topic at the target site is not a sufficient reason to migrate it. It would have to be explicitly off-topic on the source too. (There's an exception for question owners who want their unanswered question moved: they can flag their post with a custom reason requesting migration.)</p>\n"}, "64": {"ParentId": 1, "Score": 3, "Body": "<p>Once we figure out what we're about exactly, we need to haul in some real experts.</p>\n\n<p>This is a good idea right here: <a href=\"https://ai.meta.stackexchange.com/q/22/75\">Can we send messages to young researchers who have recently published papers in artificial intelligence related journals during the private beta?</a> Scholarly papers generally include their authors' e-mail addresses. Papers that don't have e-mails will at least have author names, and some Googling could turn up contact information.</p>\n"}, "65": {"ParentId": 53, "Score": 3, "Body": "<p>To be honest, I've never seen it written \"A.I.\", but both look fine to me. If somebody wants to use the dots, more power to them. As Marqin showed, it's kind of dependent on whether a person is using British or American English. Suggested edits that only change stylistic things like this should be rejected; let the post author choose as long as it's consistent within a post. </p>\n\n<p>If there is ever a similar question about tag names, the official policy is that the American style should be used. (SE is an American company.)</p>\n\n<p>Source: <a href=\"https://meta.stackexchange.com/a/23873/295684\">Meta Stack Exchange</a></p>\n"}, "66": {"ParentId": 55, "Score": 2, "Body": "<p>During this private beta, you actually can downvote infinitely - the minimum rep for that privilege in this stage is 1. I think we're still subject to the <a href=\"https://blog.stackoverflow.com/2010/03/important-reputation-rule-changes/\">\"upvote one thing for every two things you downvote\"</a> rule, though, but that shouldn't be limiting, especially considering you have to have cast 300 votes before it takes effect.</p>\n\n<p>It looks like you've already figured out what to do with nonconstructive answers and questions: downvote. For answers, you'll take a little hit of 1 point, but if it means saving the site from drivel, that's a fine price to pay. Questions that can <em>only</em> be answered subjectively can be closed as primarily opinion-based.</p>\n"}, "68": {"ParentId": 62, "Score": 10, "Body": "<p>I'm going to make something of a counterpoint here.</p>\n\n<p>If everybody upvotes all the good content, good stuff will look the same as great stuff. Everybody should put some effort into looking at each post and judging the quality thereof. The community needs at least a few people with higher standards so higher vote counts call out our best content. You're right, though, in that we currently don't have very much voting activity at all.</p>\n\n<p>If an answer or question is good but could be better, a comment would be a great way to provide positive feedback and advise slight adjustment if necessary. That way, we can improve our content even more.</p>\n\n<p>Content that is misleading or actively bad should of course be downvoted. Don't be afraid to downvote. Once the problem is fixed with an edit, you can remove or reverse your downvote.</p>\n"}, "69": {"ParentId": 67, "Score": 6, "Body": "<p>Yes! Explaining what the various tags are <em>for</em> is critical for a new site. Besides that, it also looks good when one goes to tag a question and sees that work has been put into the tag system.</p>\n\n<p>Anybody can suggest tag wiki/excerpt edits. At the moment, we don't have any users able to approve them (it takes 750 rep to review tag edits during private beta), but that shouldn't stop anybody from getting a head start on filling in our tags. Besides, community managers will hopefully be around to work the queues that we can't yet handle.</p>\n"}, "70": {"ParentId": 54, "Score": 5, "Body": "<p>I consolidated the tags to <a href=\"https://ai.stackexchange.com/questions/tagged/quantum-computing\" class=\"post-tag\" title=\"show questions tagged &#39;quantum-computing&#39;\" rel=\"tag\">quantum-computing</a> because this is not an <em>applied</em> hardware and programming site. </p>\n\n<p>A tag synonym isn't really appropriate here. Synonyms were intended to link two completely separate words meaning essentially the same thing (think 'car' vs 'auto'). For simple variations on the <em>same</em> word, there's no need to bulk up the tag listings with every word inflection. Text completion will help guide the user to the correct usage:</p>\n\n<p><kbd>q</kbd><kbd>u</kbd><kbd>a</kbd><kbd>n</kbd> &rarr; <kbd>quantum-computing</kbd></p>\n"}, "72": {"ParentId": 71, "Score": 7, "Body": "<p>I would suggest that \"programming\" and \"implementation problems\" be explicitly listed as outside the scope of <strong><em>this</em></strong> site. If you see them, I would <em>thoughtfully</em> direct the authors to bring these questions to sites which were explicitly created to handle these \"technical\" issues.</p>\n\n<h3>But why can't we have these questions here, too?</h3>\n\n<p>Many sites have <em>some</em> overlap in their subject spaces, but we do not want to optimize for sites that explicitly do so. In the formative stages of this proposal, many opponents argued that the development of AI is clearly already covered among sites like Stack Overflow, Statistics, Data Science, and similar <em>applied</em> sites. </p>\n\n<p><strong>But&hellip;</strong> the <strong><em>claim</em></strong> that we've identified a collection of academic, sociological, and <em>conceptual</em> questions that fall between the cracks of these site is what gave this proposal a chance to launch.  See <a href=\"https://area51.meta.stackexchange.com/a/17846/5\">Apparently this is a duplicate</a>. </p>\n\n<p>We still have to see how that claim stands up in actual practice.</p>\n\n<p>I wrote a bit more about this during the proposal process &mdash; <a href=\"https://area51.meta.stackexchange.com/a/24016/5\">Will machine learning be considered as on-topic?</a> &mdash;  and the folks looking on seemed widely accepting of that premise as justification for trying out this site. </p>\n\n<blockquote>\n  <h3>Will [machine learning] be considered as on-topic?</h3>\n  \n  <p>No, machine learning as far as implementation goes is not on topic for this site. We've had two previous failures in launching a site about AI (which already included machine learning) &mdash; and the resolution following those failures was to create a more-comprehensive site which included the development of AI, machine learning, statistical tools, big data, NLP, data mining, etc, etc.</p>\n  \n  <p>That site is <a href=\"http://datascience.stackexchange.com\"><strong>Data Science</strong></a> [among others].</p>\n  \n  <p>Data Science is an <em>applied</em> site for all the programmers/statisticians/mathematicians who are trying to make this stuff <em>work.</em></p>\n  \n  <h3>So why are we trying an AI site&hellip; again?</h3>\n  \n  <p>Notice that this proposal is in the 'Science' category; <em>not</em> 'Technology'. Despite the creation of a Data Science site to cover this topic, the community made a sufficiently compelling case that there is a swath of <strong>questions in the academic humanities arena</strong> that are <em>not</em> covered by our current sites. </p>\n  \n  <p>It was convincing enough to give this site another try, but if this site were to simply start reiterating the implementation/tools questions that are already covered elsewhere, this site will not likely make it out of private beta. </p>\n</blockquote>\n"}, "73": {"ParentId": 40, "Score": -2, "Body": "<p>For FSM's sake, not this again.  Please, no... stop with the \"let's attract experts\" verbiage.  I mean, don't get me wrong.. of course we <em>want</em> experts, but we don't want <em>only</em> experts and we don't want to anoint \"experts\" with some special degree of relevance.  This is a HUGE part of what made it so hard to have a successful ai.se before... we chased away the good, in pursuit of the perfect. </p>\n"}, "75": {"ParentId": 4, "Score": 4, "Body": "<p><a href=\"https://ai.meta.stackexchange.com/a/72/8\">@RobertCartaino suggested in this post</a> that:</p>\n<blockquote>\n<p>&quot;programming&quot; and &quot;implementation problems&quot; be explicitly listed as outside the scope of this site</p>\n</blockquote>\n<p>in order to direct the authors to sites which were explicitly created to handle these &quot;technical&quot; issues.</p>\n<p>This site failed already two times, because people didn't ask the right questions and most of them were already covered by somewhere else (e.g. Stack Overflow, Statistics, Data Science, and similar applied sites).</p>\n<p>Basically:</p>\n<blockquote>\n<p>Data Science is an applied site for all the programmers/statisticians/mathematicians who are trying to make this stuff work.</p>\n<p>a more-comprehensive site which included the development of AI, machine learning, statistical tools, big data, NLP, data mining, etc,</p>\n</blockquote>\n<p>so:</p>\n<blockquote>\n<p>No, machine learning as far as implementation goes is not on topic for this site.</p>\n</blockquote>\n<p>and:</p>\n<blockquote>\n<p>if this site were to simply start reiterating the implementation/tools questions that are already covered elsewhere, this site will not likely make it out of private beta.</p>\n</blockquote>\n<hr />\n<p>On the <a href=\"https://area51.meta.stackexchange.com/questions/24014/will-machine-learning-be-considered-as-on-topic/24016#comment38287_24016\">other hand</a>:</p>\n<blockquote>\n<p>Everything in the proposal is considered when evaluating whether the site would likely be viable. If the proposal looks good across the board, that is the &quot;compelling case&quot;</p>\n</blockquote>\n"}, "1074": {"ParentId": 74, "Score": 6, "Body": "<p>Conceptually speaking, I think it can be useful when a community decides that a <strong>rare</strong> \"big list\" question would be so incredibly useful, the community agrees collectively that it is worth the careful curation and on-going upkeep needed to keep it up to date [I'm hoping to build a feature to that effect in the future]. The downside of allowing these questions <strong><em>broadly</em></strong> is that these open-ended polls and all-in-one resource collections are <em>so</em> easy to ask, folks inevitably keep shoveling out boundless \"me too\" iterations in every conceivable topic space. The whole thing becomes annoying when folks become tired these questions and most of the threads fall into disrepair like <a href=\"https://en.wikipedia.org/wiki/Abandonware\" rel=\"nofollow noreferrer\">abandonware</a>.</p>\n\n<p><strong>However&hellip;</strong></p>\n\n<p>the examples you cited I believe are <strong>clearly off topic</strong> for this site. You seem to be advocating for some type of programming reference collection, API list, or some other type of programming resource for this community. That is not what this site is about. </p>\n\n<p>This is supposed to be a site dealing in largely academic, sociological, and conceptual issues. To explain why, please see this post:</p>\n\n<p><a href=\"https://ai.meta.stackexchange.com/a/72/95\"><strong>Is asking about AI algorithm recommendation on-topic?</strong></a></p>\n"}, "1076": {"ParentId": 22, "Score": 4, "Body": "<p>Technically I guess you could, but I think it would be fair to add some warnings such as the site might closed, and questions on Stack Exchange are sometimes deleted or closed for moderation reason. </p>\n"}, "1079": {"ParentId": 1077, "Score": 8, "Body": "<p>Post consists almost entirely of content copied from elsewhere should NOT be considered a useful 'answer' in the context of this site. </p>\n\n<p>Copying answers from external sources without permission is not allowed (and quoting or linking back to that site does <strong><em>not</em></strong> make that okay). Even posting an answer copied almost entirely from <em>reusable</em> content should be frowned upon, or even flagged to be removed. </p>\n\n<p>This site was created to add something unique (and better) to the Internet. If we're simply copying stuff that's already out there, why bother? We're just adding another barrier between the folks searching for this stuff and the original source of the content.</p>\n\n<p>Answers should create something original and useful for this community specifically. That is why we bring together individual communities of experts to host these topics. </p>\n\n<p>And vetting is a <strong><em>big</em></strong> part of this site. Your <em>best</em> content should be rising to the top. <strong>Please stop up-voting these posts!</strong></p>\n"}, "1080": {"ParentId": 1075, "Score": 6, "Body": "<p>Yes, absolutely. Tag excerpts are not meant to simply define what the <em>word</em> of a tag means. They are meant to describe when and how those tags should be used on this site specifically. </p>\n\n<p>Since this site is not generically about either <em>algorithms</em> OR <em>history</em>, it becomes especially important to describe how those subjects fit in the context of <em>this</em> site. </p>\n\n<p>I see some potentially misleading tags like [python], [engine], and [storage]. Adding a bit of context about where they should be used can help avoid the occasional off-topic question that may not fit this site at all. </p>\n"}, "1082": {"ParentId": 1078, "Score": 0, "Body": "<p>Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in <a href=\"https://ai.meta.stackexchange.com/q/4/4\">other SE</a>, such as Stats and Data Science.</p>\n\n<p>Data science and the Stats SE already have a huge overlap (>~80%), and I am worried to have a third SE that also significantly overlaps with them. Personally, it would further demotivate me to write any answer, as it gets tiring to copy-paste content, and updating duplicated answers is a pain.</p>\n"}, "1083": {"ParentId": 1077, "Score": -2, "Body": "<p>As long as it does answer the question, clearly indicates it is a quote, doesn't infringe licenses, and gives proper attribution, it is fine. </p>\n\n<p>(Why reinventing the wheel?)</p>\n"}, "1084": {"ParentId": 35, "Score": 7, "Body": "<p>I think we should discourage the use of LaTeX, but should allow it. Our goal is to attract experts in AI, and the language of AI (today) is math. Like that post in the OP (which I wrote, btw), I think math makes a lot of concepts easier to understand. </p>\n\n<p>I think this SE should focus on the <em>design</em> aspects of AI and AI research instead of the programming and libraries (those questions should go to Data Science) or the statistics (those should go to Cross Validated), but some mathematics is often a core component of AI theory.</p>\n"}, "1086": {"ParentId": 38, "Score": 1, "Body": "<h3>The early stopping</h3>\n\n<blockquote>\n  <p>Form of regularization used to avoid overfitting when training.</p>\n</blockquote>\n\n<p>See: <a href=\"https://ai.stackexchange.com/q/16/8\">What is early stopping?</a></p>\n"}, "1087": {"ParentId": 1085, "Score": 1, "Body": "<p>To give examples of questions I think are good, and that we should promote, in order with the best questions at the top:</p>\n\n<ul>\n<li><a href=\"https://ai.stackexchange.com/questions/92/how-is-it-possible-that-deep-neural-networks-are-so-easily-fooled\">How is it possible that deep neural networks are so easily fooled?</a> I would not have put \"easily\" in the title, but it is an excellent question that the AI experts I know spend a lot of time thinking about.</li>\n<li><a href=\"https://ai.stackexchange.com/questions/1294/how-does-hintons-capsules-theory-work\">How does Hinton&#39;s &quot;capsules theory&quot; work?</a></li>\n<li><a href=\"https://ai.stackexchange.com/questions/77/is-lisp-still-being-used-to-tackle-ai-problems\">Is Lisp still being used to tackle AI problems?</a></li>\n<li><a href=\"https://ai.stackexchange.com/questions/227/what-is-the-difference-between-mlp-and-rbf\">What is the difference between MLP and RBF?</a> : This can go to Crossvalidated but I'd argue it's out of place there and more at home here. Though it is a comparison of two specific algorithms, it reflects wider design issues in AI algorithms.</li>\n</ul>\n\n<p>Others may disagree on this list, but I'd like to put up here the questions I think are more on-topic here than I think in other SEs. Some overlap is inevitable.</p>\n"}, "1088": {"ParentId": 38, "Score": 0, "Body": "<h1>The Dropout</h1>\n\n<blockquote>\n  <p>A technique of reducing overfitting in neural networks. The term \"dropout\" refers to dropping out units in a neural network.</p>\n</blockquote>\n"}, "1089": {"ParentId": 1085, "Score": 1, "Body": "<p>These are some ways to highlight and promote nice content on the site:</p>\n\n<ol>\n<li>Organizing a quarterly post, where people are encouraged to post their favourite qns/ans and the top three would be awarded bounties by the mods or whoever is interested in contributing.</li>\n<li>Cross-posting the nice ones to other sites like reddit, etc. This would help in marketing the site, as well as good karma by sharing good content.</li>\n</ol>\n"}, "1092": {"ParentId": 1091, "Score": 1, "Body": "<p>Escaping local optima is an extremely ubiquitous problem (in case it's unclear - there are vastly more applications than backprop), leading to many open questions (a great deal of metaheuristics research, indisputably part of AI, is concerned with this). </p>\n\n<p>So, it is much more open-ended (and therefore subject to heuristic/AI solutions) than the more pedestrian questions (with procedural anwers) about e.g. backprop that appear to be within the AI SE remit.</p>\n\n<p>Hence, I'd say it is definitely on topic ;-)</p>\n"}, "1093": {"ParentId": 1090, "Score": 7, "Body": "<p><sub><sub>(Without seeing any actual examples&hellip;)</sub></sub></p>\n\n<p>These can likely be closed as off topic <em>already.</em> A question sufficiently detailed enough to ask how to defeat a system based in AI will likely no longer be about the <strong><em>subject</em></strong> of AI itself. It would be like asking how to defeat the smart aliens in Galactic Uberblast 2020, or how to remove the T47/a access panel of your robot butler if he wont let you. </p>\n\n<p>There's a point where a question is only <em>coincidentally</em> related to the subject of AI itself &mdash; close it as off topic.</p>\n\n<p>There will always be sticky edge cases where someone might be asking how an AI-based security system <strong>works,</strong> but it becomes somewhat problematic to preempt any such questions by presuming the <em>intent</em> of an author before you see such questions in actual practice. It's probably too early to conjure up a broad policy statement when there is really no tangible problem to defeat. </p>\n"}, "1094": {"ParentId": 1090, "Score": 0, "Body": "<p>Asking about how Captcha works or what is mechanism of AI recognising the text from the image, isn't illegal.</p>\n<p>Neither whether has been cracked/hacked or not, which has been asked at Stack Overflow:</p>\n<ul>\n<li><a href=\"https://stackoverflow.com/q/448963/55075\">Has reCaptcha been cracked / hacked / OCR'd / defeated / broken?</a></li>\n</ul>\n<p>Captcha is just a type of challenge-response test used in determine whether somebody is human or not and this technology is not owned by anybody. There are many research studies how to improve this technology to keep spammers away.</p>\n<p>If the post doesn't indicate it's against the law and doesn't show any illegal activity, there is no reason to close it. If it's unethical, you can always down-vote it or ask for clarification. There are special agencies which deals with that problem, so you don't have to worry about it.</p>\n<p>If it's not illegal, it's up to you how you'll use the knowledge from the posts. As it can be always used for research and educational purposes.</p>\n<p>See also:</p>\n<ul>\n<li><p><a href=\"https://meta.stackexchange.com/q/21706/191655\">Should unethical questions be answered?</a></p>\n</li>\n<li><p><a href=\"https://meta.stackexchange.com/q/80495/191655\">Policy regarding questions related to unethical or \u201cshady\u201d practices</a></p>\n<blockquote>\n<p>we bury our heads in the sand, we're just pretending the problem doesn't exist and we can't help defend against it</p>\n<p>If a process is clearly illegal, especially in the US, then it should not be discussed.</p>\n</blockquote>\n</li>\n</ul>\n"}, "1095": {"ParentId": 1085, "Score": 3, "Body": "<p>I think that Harsh's list is a good start if we want to get people who think of themselves as AI experts, instead of people who think of themselves as AGI experts. (The G is for 'general.') But in order to differentiate this site from Cross Validated or Data Science, we're trying to focus on the humanities / philosophy side. </p>\n\n<p>I worry that this means that we're going to have a parade of AI 101 questions, like <a href=\"https://ai.stackexchange.com/questions/179/how-do-multiple-intelligences-fit-in-ai\">How does multiple intelligences fit in AI?</a> or <a href=\"https://ai.stackexchange.com/questions/1320/how-does-artificial-intelligence-work-in-games\">How does artificial intelligence Work in games?</a>, which isn't an implementation or algorithms question because it's so broad and basic, or simple discussions of complicated issues, like the on-hold <a href=\"https://ai.stackexchange.com/questions/7/why-does-stephen-hawking-say-artificial-intelligence-will-kill-us-all\">Why does Stephen Hawking say \"Artificial Intelligence will kill us all\"?</a>.</p>\n\n<p>And this suggests that the AI experts are going to become rapidly bored and leave, since they can't ask the questions they're interested in and don't see any interesting questions to answer, and so they won't be around to contribute to the humanities side of the discussion. What good humanities questions have we had, so far? My short list is something like:</p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/74/what-is-the-difference-between-strong-ai-and-weak-ai\">What is the different between strong-AI and weak-AI?</a> (though this is another 101 question)</p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/15/is-the-turing-test-or-any-of-its-variants-a-reliable-test-of-artificial-intell\">Is the Turing Test, or any of its variants, a reliable test of artificial intelligence?</a></p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/148/what-limits-if-any-does-the-halting-problem-put-on-artificial-intelligence\">What limits, if any, does the halting problem put on Artificial Intelligence?</a></p>\n\n<p>But that's three good humanities questions out of the <a href=\"https://ai.stackexchange.com/questions?sort=votes\">15 currently most upvoted questions</a>.</p>\n"}, "1096": {"ParentId": 1091, "Score": 3, "Body": "<p>The question is off-topic, as it's about how to the use of machine learning algorithms. (the other questions on neural nets, their architectures, backpropogation, are also off-topic).</p>\n\n<p>Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in <a href=\"https://ai.meta.stackexchange.com/q/4/4\">other SE</a>, such as Stats and Data Science.</p>\n\n<p>Data science and the Stats SE already have a huge overlap (>~80%), and I am worried to have a third SE that also significantly overlaps with them. Personally, it would further demotivate me to write any answer, as it gets tiring to copy-paste content, and updating duplicated answers is a pain.</p>\n"}, "1098": {"ParentId": 1091, "Score": 0, "Body": "<p>Personally, I consider gradient descent something akin to what something like differential equations is to physics - a useful piece of mathematics that has a large array of applications, but not really an AI topic by itself.</p>\n\n<hr>\n\n<p>When we talk about AI, there are different levels of detail and \"technicalness\" we can go into and I believe it's necessary to draw the line somewhere.</p>\n\n<p>To illustrate what I mean, let me use the example of self-driving cars:</p>\n\n<ul>\n<li>There's the concept of the <strong>self-driving car</strong> itself</li>\n<li>The car has some sort of <strong>computer-vision</strong> system</li>\n<li>That system might involve a <strong>neural network</strong></li>\n<li>That network needs to be <strong>trained</strong> somehow - there are different algorithms for that</li>\n<li>One of the most common ones is <strong>backpropagation</strong></li>\n<li>Backpropagation often uses <strong>gradient descent</strong></li>\n<li>Gradient descent is an <strong>optimization algorithm</strong></li>\n<li>and so on...</li>\n</ul>\n\n<p>We could look at an AI problem at any of those levels. But at some point, it becomes no longer really about AI but rather about mathematics or statistics. And those topics are already covered well by other sites.</p>\n\n<p>Basically, what I believe is that this site should mainly concentrate on the top few lines of that list, and leave the rest to more appropriate venues.</p>\n"}, "1100": {"ParentId": 1099, "Score": 4, "Body": "<p>I was one of the close voters.</p>\n\n<p>First up, the close message you see is the generic off-topic message - we only get one reason under the \"off-topic\" branch of the close dialogs because we currently have no moderators to create and approve off-topic reasons. Therefore, anything deemed off-topic will get that one message. It's not that your question wasn't about AI, it wasn't about AI <em>as defined in the help center</em> (or, again, since we have no moderators yet, as defined on meta).</p>\n\n<p>Your question, in my understanding, is about specific algorithms and how they work. We're not really into the math/statistics/implementation on this site, because those are already well covered by existing places.</p>\n\n<p>I think that the question could be reopened if it was adjusted to ask something like \"Why is Alpha Go's approach more appropriate for games than existing technologies?\" Then the question wouldn't be about a specific algorithm, but answers could still dive in if they wanted.</p>\n\n<p>As for whether we have a scope, we're still working on that, as evidenced by our abundance of meta posts about topicality! I think we do have at least some sketches of what should by on- and off-topic, though.</p>\n"}, "1101": {"ParentId": 1099, "Score": 0, "Body": "<p>The initial scope on <a href=\"http://area51.stackexchange.com/proposals/93481/artificial-intelligence\">Area 51</a> proposal was:</p>\n\n<blockquote>\n  <p>Conceptual questions about life and challenges in a world where \"cognitive\" functions can be mimicked in purely digital environment.</p>\n</blockquote>\n\n<p>Of course this isn't a strict rule, because the final scope is defined by community based on the questions being asked, so if you have any great question related to AI, please ask. So after some time this site can find a distinct and unique scope in comparison to other existing <a href=\"http://stackexchange.com/sites#science-questionsperday\">network sites</a>.</p>\n\n<p>However please note that the questions about <a href=\"https://stackoverflow.com/\">programming</a>, <a href=\"https://ai.meta.stackexchange.com/q/71/8\">algorithms</a>, <a href=\"https://stats.stackexchange.com/questions/tagged/machine-learning\">implementation</a> and <a href=\"https://datascience.stackexchange.com/questions/tagged/machine-learning\">data modelling</a> are already on-topic on the other dedicated sites and are likely to be off-topic here in order to avoid <a href=\"https://ai.meta.stackexchange.com/q/4/8\">huge overlap</a>.</p>\n\n<hr>\n\n<p>Basically the scope is still about <strong>artificial intelligence</strong>, but coming from the technical background, asking the right question could be challenging (because we've already a lot of sites dedicated to different aspects of AI). You can think about it like <a href=\"https://softwareengineering.stackexchange.com/\">Programmers</a> SE site, but without asking actual programming questions.</p>\n"}, "1104": {"ParentId": 1103, "Score": 4, "Body": "<p>Yes, that would definitely be a good idea; we get a lot of questions that belong there.</p>\n\n<p>The trick is that sites only get migration paths (in or out) after they graduate fully. The reasoning behind this is that beta sites are still figuring out their scopes, and it would be bad to send a question away forever with no way to reopen it at the source site.</p>\n\n<p>Moderators can migrate things anywhere, but only if the question is less than 60 days old. If we get pro-tem mods in time, we could consider sending any good-but-definitely-off-topic questions away.</p>\n\n<p>People might also want to migrate to <a href=\"https://datascience.stackexchange.com/\">Data Science</a>, but it's still in public beta and is therefore not guaranteed to stick around. Migrations to beta sites are <a href=\"https://meta.stackexchange.com/a/258601/295684\">discouraged</a>.</p>\n"}, "1105": {"ParentId": 1081, "Score": 2, "Body": "<p>Implementation problems may refer to the \"how to do X with the Y tool/framework\" kind of questions. Such kind of questions are indirectly related to AI, via the X part, which could lead to ask the OP to change the question focus. So questions that solely pertain to Y should be off-topic.</p>\n\n<p>One issue with this approach, is that, say, 10 years ago, Y would have been seen as AI from science fictions. At some point in time, \"we did it\", and Y just looks like another tool.</p>\n"}, "1106": {"ParentId": 1099, "Score": 2, "Body": "<p>I don't know, but that shouldn't have been closed.  It should be, in almost every case, sufficient to simply <em>ignore</em> any question which falls into a \"grey area\" regarding scope.  We should only close questions which are blatant spam, trolling, or so wildly off-topic that a 2 year old could see it (like a question about the best fuel injector cleaner to use for  1972 Ford Pinto, or something).</p>\n\n<p>If questions are desired by the community, they'l bubble to the top. If they aren't, they'll die from lack of activity.  Explicitly closing a question is an aggressive and hostile act and should always be a measure of last resort.</p>\n"}, "1107": {"ParentId": 1081, "Score": 4, "Body": "<p>Personally I disagree with the entire premise that \"implementation should be off topic\".  I don't see any point in talking nothing but theory and never talking implementation.  My fear is that that will lead us into fringe-land with a lot of sketch posts asking philosophical questions that aren't really helpful to anybody. </p>\n"}, "1109": {"ParentId": 1085, "Score": 0, "Body": "<h2>Add bounties.</h2>\n\n<p>What else can you do? Adding bounties to questions puts them in a special category on the front page. If you want, you could even have two users who 'bounce' a bounty to each other on  few questions, to make sure that they stay there in the 'featured' tab.</p>\n"}, "1112": {"ParentId": 1111, "Score": 7, "Body": "<p>As you point out, it is a copy-paste without attribution, which is a <a href=\"https://ai.stackexchange.com/help/licensing\">violation of the Stack Exchange rules</a>.</p>\n\n<p>So it should be flagged, using a custom moderator flag to explain the situation.</p>\n\n<p>I have raised that flag.</p>\n"}, "1113": {"ParentId": 1110, "Score": 2, "Body": "<p>I would go with <a href=\"https://ai.stackexchange.com/questions/tagged/gaming\" class=\"post-tag\" title=\"show questions tagged &#39;gaming&#39;\" rel=\"tag\">gaming</a>. It's implied that questions on an AI site will be about AI, so there's no need to specify that in a tag. The gerund form makes it clear that gaming is something the AIs are doing.</p>\n\n<p>We can add tags for specific games (like Go) if they become big topics.</p>\n"}, "1114": {"ParentId": 1103, "Score": 1, "Body": "<p>I think we should have first the list of questions which are off-topic here, and on-topic there. If we've enough number of them, the migration target probably can be added later on. For now you can flag each question for moderation, so it can be migrated manually when accepted.</p>\n\n<p>However as far as I've checked, there are only 73 questions tagged with <a href=\"https://stats.stackexchange.com/questions/tagged/artificial-intelligence\">artificial-intelligence</a> on Stat.SE where 1/3 of them are still unanswered (24), so I believe some questions about artificial intelligence probably are better suited here. Unless they're specifically related to <a href=\"https://stats.stackexchange.com/questions/tagged/machine-learning\">machine-learning</a> where, again, 40% of them are unanswered which make us think where they really belong.</p>\n\n<p>On the other hand, using/programming/implementing AI, at the same time doesn't make me expert on statistics aka cross-validation/rotation estimation model, which to be honest, I don't know nothing about.</p>\n\n<p>And it's not only me:</p>\n\n<blockquote>\n  <p>statistical learning is not the path to AI (Artificial Intelligence)</p>\n</blockquote>\n\n<p>Source: <a href=\"https://www.quora.com/I-once-heard-statistical-learning-is-not-the-path-to-AI-Artificial-Intelligence-what-are-the-arguments-that-support-this-statement-claim\" rel=\"nofollow noreferrer\">Quora</a>.</p>\n"}, "1115": {"ParentId": 1077, "Score": 0, "Body": "<p>Plagiarism is unethical, IMHO: if you're providing a link to a source, it's more than enough. But if you want to provide <em>a cite</em>, then it must be referenced and marked up in appropriate manner</p>\n"}, "1116": {"ParentId": 1110, "Score": 2, "Body": "<p>Some of these tags seem related but I think <a href=\"https://ai.stackexchange.com/questions/tagged/game-theory\" class=\"post-tag\" title=\"show questions tagged &#39;game-theory&#39;\" rel=\"tag\">game-theory</a> has a well-known definition (from <a href=\"https://en.wikipedia.org/wiki/Game_theory\" rel=\"nofollow noreferrer\">wikipedia</a>)</p>\n\n<blockquote>\n  <p>the study of mathematical models of conflict and cooperation between\n  intelligent rational decision-makers</p>\n</blockquote>\n\n<p>and it's applied in other fields besides AI.</p>\n\n<p>IMO there should also be different tags for <code>AI that's used in games</code> and <code>AI that plays games</code>, the first may correspond to <a href=\"https://ai.stackexchange.com/questions/tagged/gaming\" class=\"post-tag\" title=\"show questions tagged &#39;gaming&#39;\" rel=\"tag\">gaming</a> <a href=\"https://ai.stackexchange.com/questions/tagged/games\" class=\"post-tag\" title=\"show questions tagged &#39;games&#39;\" rel=\"tag\">games</a> or so and I would call the second <a href=\"https://ai.stackexchange.com/questions/tagged/game-play\" class=\"post-tag\" title=\"show questions tagged &#39;game-play&#39;\" rel=\"tag\">game-play</a>.</p>\n\n<p>Moreover <a href=\"https://en.wikipedia.org/wiki/Go_(game)\" rel=\"nofollow noreferrer\">Go</a> refers to that specific board game, which had for long been considered as the only game that humans play better than machines until the AI <a href=\"https://en.wikipedia.org/wiki/AlphaGo\" rel=\"nofollow noreferrer\">AlphaGo</a> came into play. So <a href=\"https://ai.stackexchange.com/questions/tagged/go-game\" class=\"post-tag\" title=\"show questions tagged &#39;go-game&#39;\" rel=\"tag\">go-game</a> seems to be particularly for <a href=\"https://en.wikipedia.org/wiki/Go_(game)\" rel=\"nofollow noreferrer\">Go</a>.</p>\n\n<p>So IMO at least <a href=\"https://ai.stackexchange.com/questions/tagged/game-theory\" class=\"post-tag\" title=\"show questions tagged &#39;game-theory&#39;\" rel=\"tag\">game-theory</a> <a href=\"https://ai.stackexchange.com/questions/tagged/go-game\" class=\"post-tag\" title=\"show questions tagged &#39;go-game&#39;\" rel=\"tag\">go-game</a> have clear definitions, and among the others there should be separate tags for <code>AI that's used in games</code> and <code>AI that plays games</code>.</p>\n"}, "1119": {"ParentId": 4, "Score": 4, "Body": "<p>I believe questions asked at <a href=\"https://stats.stackexchange.com/\">Stats.SE</a> about <a href=\"https://stats.stackexchange.com/questions/tagged/artificial-intelligence\">artificial intelligence</a> should be on-topic here as well, because:</p>\n\n<ul>\n<li>since past 6 years there were only <a href=\"https://stats.stackexchange.com/questions/tagged/artificial-intelligence\">~73 questions asked about AI</a>, 1/3 of them still <a href=\"https://stats.stackexchange.com/questions/tagged/artificial-intelligence?sort=unanswered\">unanswered</a>,</li>\n<li>40% of question about <a href=\"https://stats.stackexchange.com/questions/tagged/machine-learning\">machine-learning</a> are also <a href=\"https://stats.stackexchange.com/questions/tagged/machine-learning?sort=unanswered\">unanswered</a>, try scrolling.</li>\n</ul>\n\n<p>You may suggest they may lacking of AI experts there, so lets move there. However not all AI experts are using or are interested in statistics models with AI.</p>\n\n<p>For example I'm no where near as statistician, I've no idea about cross-validation aka rotation estimation models, but I may use and implement practical AI algorithms.</p>\n\n<p>Therefore I think our site has already its own distinct and unique scope in comparison to Stats.SE, because it is about pure Artificial Intelligence and beyond.</p>\n\n<p>You can still asks about AI at Stats.SE, but it should be focused to <em>statistical learning</em>. To support that, <a href=\"https://stats.meta.stackexchange.com/a/2095/12989\">check this post</a>:</p>\n\n<blockquote>\n  <p>Question on AI including a comparison with statistical learning would be pretty clearly on topic here.</p>\n</blockquote>\n\n<p>They were accepting even without that, but I think most likely because people didn't have the right place to ask. If they've asked, didn't have much attention (maybe AI experts aren't interested in statistical models).</p>\n\n<p>If you've question about theoretical AI, you can consider asking at: <a href=\"https://cstheory.stackexchange.com/questions/tagged/ai.artificial-intel\">CSTheory.SE</a> (not active either).</p>\n\n<p>We can only hope that after <a href=\"http://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/\">6 years</a> of previous failures, we're able to break some ice this time.</p>\n\n<p>We've one-time final opportunity to not have AI spread across the whole network:</p>\n\n<p>Stats.SE, CSTheory.SE, CogSci.SE, Philosophy.SE, Worldbuilding.SE, SO.SE, CS.SE, HSM.SE, Robotics.SE, GameDev.SE, gosh where else, with no real AI experts in one place.</p>\n\n<p>So basically the goal of this site is as pointed by <a href=\"https://area51.meta.stackexchange.com/questions/11658/faked-artificial-intelligence-like-in-game-development#comment18885_11709\">@lejlot</a>:</p>\n\n<blockquote>\n  <p>To bring people from this one particular field, which exists in\n  between all above in one place. I see the reason behind it - as now\n  questions regarding AI are scattered across these sites and get very\n  little attention from actual experts, who also visit just a subset of\n  these. Additionally - on each site these questions are tagged in a\n  different way, so it is impossible to track them. Unification (new\n  site) would make all of it much easier (and in fact - possible for the\n  first time).</p>\n</blockquote>\n\n<p>If this going to fail this time, people still will have to have 10-20 different accounts to ask the right questions on the right sites (which is very inconvenient). This would be very sad. </p>\n\n<hr>\n\n<p>To summary, <a href=\"https://www.quora.com/I-once-heard-statistical-learning-is-not-the-path-to-AI-Artificial-Intelligence-what-are-the-arguments-that-support-this-statement-claim\" rel=\"nofollow noreferrer\">some say</a>:</p>\n\n<blockquote>\n  <p>statistical learning is not the path to AI (Artificial Intelligence)</p>\n</blockquote>\n\n<p>but it's open to debate.</p>\n"}, "1120": {"ParentId": 1118, "Score": 4, "Body": "<p>I don't think that question would be on-topic, as it has nothing to do with AI. It is more like a current affairs question.</p>\n\n<p>A relevant question from the article would be maybe about the <code>limitations/shortcomings behind Skynet's AI program which have caused the disaster</code></p>\n"}, "1121": {"ParentId": 1117, "Score": 2, "Body": "<p>I think the tags are different. Let me explain with an example:</p>\n\n<p><strong>definitions:</strong> What is a deep neural network?</p>\n\n<p><strong>Terminology:</strong> Would this (&lt; Insert some tech. behind some AI product/bot >) be a deep neural network or a RNN?</p>\n"}, "1125": {"ParentId": 1124, "Score": 4, "Body": "<p>I believe so, since all user contributions are licensed under cc by-sa 3.0 with attribution required (including the one from the previous dumps), so as long you give the attribution, that should be fine. In this case, it won't be stealing, but republishing.</p>\n\n<p>See: <a href=\"https://ai.stackexchange.com/help/licensing\">What is the license for the content I post?</a></p>\n\n<blockquote>\n  <p><a href=\"http://blog.stackoverflow.com/2009/06/attribution-required/\">Proper attribution</a> is required if you republish any Stack Exchange content.</p>\n</blockquote>\n"}, "1127": {"ParentId": 1123, "Score": 3, "Body": "<p>I'm of the opinion that we should allow ML and AI research-style questions here, of the sort that would also <em>could</em> be on-topic at Cross Validated but would be less likely to hit their intended audience there than they would here.</p>\n\n<p>That is, I don't think there is a difference in topics so much as there is a difference between clusters of people who care about those topics, and the perspectives that they bring and the sort of questions and answers that they'll consider interestingly on-topic. </p>\n"}, "1128": {"ParentId": 1123, "Score": -1, "Body": "<blockquote>\n  <p>While at the same time Cross Validated is not about machine learning, but about statistics.</p>\n</blockquote>\n\n<p>This is not a valid point, as all machine learning questions are on-topic on CV.</p>\n\n<p>It's unclear to me what extent non-statistical AI is on-topic on CV, so I asked there <a href=\"https://stats.meta.stackexchange.com/questions/4257/what-is-our-stance-on-questions-about-non-statistical-artificial-intelligence\">https://stats.meta.stackexchange.com/questions/4257/what-is-our-stance-on-questions-about-non-statistical-artificial-intelligence</a> If no, it makes sense to have a (non-stat?) AI site. If yes, I think we should merge and rename CV.</p>\n"}, "1129": {"ParentId": 1122, "Score": 10, "Body": "<p>It's a tricky question.</p>\n<p><sub><sup><em>This is NOT a site review, but a personal observation having followed this subject on the network for some time.</em></sup></sub></p>\n<p>I think we've done a better job at scoping out something fundamentally more useful as a site. The formative question is whether we have a suitable audience to actually build out this space. But that has to happen here and now; they won't just <em>show up</em> later.</p>\n<p>Stack Exchange is billed as a network of practitioners helping their peers solve everyday problems. Unfortunately, a large percentage of the questions being asked here sit squarely in the curiosity-seekers space. Questions mostly wallow conspicuously in played-out subjects which &quot;real&quot; AI researches have stopped asking a long ago \u2014 Is <em>this</em> AI? What does <em>concept</em> mean? When are we going to get there? When is AI going to do {x}?</p>\n<p>I won't pass judgement on whether we've given up on actually building a peer-review site. I talked about some of this in <a href=\"https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/\">no artificial intelligence in Area 51</a>.</p>\n<p>There are certainly at least a few very knowledgeable people in this community \u2014 actual researchers working in this field \u2014 but there's a bifurcation of posts from folks with <em>active</em> experience and someone just showing up with whatever they find in a cursory Google search. <strong>The problem is that the community either doesn't know the difference, or doesn't care to vote up one over the other.</strong> It's hard to fault anyone for trying valiantly to get something going here, but watching something from Wikipedia being voted on with equal alacrity is somewhat\u2026 discouraging.</p>\n<h3>Have we brought something new to the network?</h3>\n<p>Probably. Questions here don't generally fit elsewhere.</p>\n<h3>Have we created something useful?</h3>\n<p>Hard to say; that's a big question for the final review.</p>\n<h3>Does this a address a peer group prevalent in this space?</h3>\n<p>That does not seem likely \u2014  If you read <a href=\"https://blog.stackoverflow.com/2010/07/area-51-asking-the-first-questions/\"><strong>Asking the First Questions</strong></a>, I suspect that ship will have sailed by time we reach public beta.</p>\n<h3>Have we improved the Internet in general?</h3>\n<p>My suspicion is the lack of true peer review in this space will make most of what is posted here about <em>status quo</em> with what you can already find elsewhere. That is by no means certain; that is just my observation.</p>\n"}, "1130": {"ParentId": 1085, "Score": 2, "Body": "<p>I'd like to point out that every site has a greatest hits page. Ours is at</p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/greatest-hits\">https://ai.stackexchange.com/questions/greatest-hits</a></p>\n\n<p>Ours is currently empty, unfortunately, but I suspect that there will be questions there within a month or so. (An older site, Monero, still doesn't have any questions in this list. On the other hand, the Language Learning  site does, but that site is already three months old.)</p>\n"}, "1132": {"ParentId": 1110, "Score": 0, "Body": "<p>I think there is a bit of a difference between <a href=\"https://ai.stackexchange.com/questions/tagged/games\" class=\"post-tag\" title=\"show questions tagged &#39;games&#39;\" rel=\"tag\">games</a> and <a href=\"https://ai.stackexchange.com/questions/tagged/gaming\" class=\"post-tag\" title=\"show questions tagged &#39;gaming&#39;\" rel=\"tag\">gaming</a>. I wouldn't call playing Go or chess gaming. I might call it, depending on the context, playing a game. </p>\n\n<p>On the other hand, playing a game such as World of Warcraft or Plants vs. Zombies, I would call gaming. (not that I do it...)</p>\n"}, "1134": {"ParentId": 1133, "Score": 2, "Body": "<p>I think most questions about Naive Bayes classifier belong on stats.SE or data.SE. </p>\n\n<p>It is part of data mining and data science, and it is probably on-topic on data.SE. Some examples of posts on data.SE that appear to be similiar to the question you want to ask:</p>\n\n<ul>\n<li><a href=\"https://datascience.stackexchange.com/questions/1197/how-can-i-classify-text-considering-word-order-instead-of-just-using-a-bag-of-w\">How can I classify text considering word order, instead of just using a bag-of-words approach?</a></li>\n<li><a href=\"https://datascience.stackexchange.com/questions/6464/spam-detection-in-social-media/6466#6466\">Spam detection in social media</a>. This question uses another method, but Bayes is suggested in an answer.</li>\n</ul>\n\n<p>A question on stats.SE that is similiar: <a href=\"https://stats.stackexchange.com/questions/50765/simple-text-classifier-classification-taking-forever/50792#50792\">Simple text classifier: classification taking forever?</a></p>\n\n<p>The point is, a theoretical question about the Naive Bayes classifier will probably belong on stats.SE since it involves probability and statistics. An applied question would probably be better on data.SE. </p>\n\n<p>Also, your wiki argument is not a really good one, since anyone can add or remove such sentence. Here is one from an other language that start with such sentence:</p>\n\n<blockquote>\n  <p>En teor\u00eda de la probabilidad y miner\u00eda de datos, un clasificador Bayesiano [...] <br> (In the theory of probability and data mining, a Bayes classifier [...])</p>\n</blockquote>\n"}, "1135": {"ParentId": 1110, "Score": 1, "Body": "<p>I think there should be two tags here:</p>\n\n<p><strong><a href=\"https://ai.stackexchange.com/questions/tagged/gaming\" class=\"post-tag\" title=\"show questions tagged &#39;gaming&#39;\" rel=\"tag\">gaming</a> and <a href=\"https://ai.stackexchange.com/questions/tagged/game-theory\" class=\"post-tag\" title=\"show questions tagged &#39;game-theory&#39;\" rel=\"tag\">game-theory</a>.</strong></p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/tagged/gaming\" class=\"post-tag\" title=\"show questions tagged &#39;gaming&#39;\" rel=\"tag\">gaming</a> is for how AIs are used <em>in games</em>.</p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/tagged/game-theory\" class=\"post-tag\" title=\"show questions tagged &#39;game-theory&#39;\" rel=\"tag\">game-theory</a> should be used for AIs <em>playing games</em>.</p>\n"}, "1137": {"ParentId": 1136, "Score": 1, "Body": "<p>Currently I think it is used when the question is about some specific research or study, or it expects some authoritative study references from the answers.</p>\n<p><a href=\"https://academia.stackexchange.com/questions/tagged/research\">Academia.SE</a> has similar tag and it's described as:</p>\n<blockquote>\n<p>Questions directly focused on performing academic research applicable to any discipline.</p>\n<p>This tag is only for questions that are directly about research. Do not use it for questions tangentially related to research.</p>\n<p>For example, if you are asking about how to best cite something, you are probably doing so because you are publishing your research. Such a question would only be <strong>related</strong> to research, but not about it, and should thus not be tagged <a href=\"https://ai.stackexchange.com/questions/tagged/research\" class=\"post-tag\" title=\"show questions tagged &#39;research&#39;\" rel=\"tag\">research</a>. If you are however asking, e.g., how to best organise your research, the question is actually <strong>about</strong> research and thus should be tagged <a href=\"https://ai.stackexchange.com/questions/tagged/research\" class=\"post-tag\" title=\"show questions tagged &#39;research&#39;\" rel=\"tag\">research</a>.</p>\n</blockquote>\n"}, "1140": {"ParentId": 1085, "Score": -3, "Body": "<p>Upvote <em>only</em> good questions.</p>\n\n<p>Down- and/or close-vote <em>all</em> bad questions.</p>\n"}, "1142": {"ParentId": 1141, "Score": 0, "Body": "<p>Also a friendly reminder that our <a href=\"https://ai.stackexchange.com/tour\">tour page</a> (also <a href=\"http://area51.stackexchange.com/proposals/93481/artificial-intelligence\">proposal</a>) states:</p>\n\n<blockquote>\n  <p>A question and answer site for people interested in <strong>conceptual questions about life and challenges in a world</strong> where \"cognitive\" functions can be mimicked in purely digital environment. It's built and run by you.</p>\n</blockquote>\n\n<p>So I don't see the reason why both kind of questions can be on-topic, conceptual and scientific or similar, otherwise we're limiting without any good reason.</p>\n\n<p>Also please remember that it's run by us, so everybody can decide whether question should be on-topic by voting on it.</p>\n"}, "1143": {"ParentId": 1123, "Score": 3, "Body": "<p>Clearly, <a href=\"https://stats.stackexchange.com/\">Cross Validated</a> is about statistics - it's even in the URL, <code>stats.stackexchange.com</code>. They're a very math-heavy and calculation-oriented site. MathJax is enabled there, and every question I scanned from their front page involves code or mathematical formulae. <a href=\"https://ai.stackexchange.com/questions/tagged/machine-learning\" class=\"post-tag\" title=\"show questions tagged &#39;machine-learning&#39;\" rel=\"tag\">machine-learning</a> is their third most popular tag at the moment, and <a href=\"https://stats.stackexchange.com/questions/tagged/machine-learning\">questions in it</a> are about the stats/math involved in machine learning.</p>\n\n<p>Questions here are not expected to involve that level of detail. MathJax is not enabled here, and that <a href=\"https://ai.meta.stackexchange.com/q/35/75\">might</a> be purposeful. Our questions should be about the <a href=\"https://area51.meta.stackexchange.com/a/24016/136466\">science</a> - not so much the technology or math or implementation of - artificial intelligence. (For machine learning implementation, see <a href=\"https://datascience.stackexchange.com/\">Data Science</a>.)</p>\n"}, "1144": {"ParentId": 1141, "Score": 10, "Body": "<p>I've seen this argument come up <a href=\"https://ai.meta.stackexchange.com/a/1142/95\">here</a> and several times in other discussions about scope:</p>\n\n<blockquote>\n  <p>I don't see why both kinds of questions can't be on-topic</p>\n</blockquote>\n\n<p>It's because the OPPOSITION against creating this site argued (correctly) that we already created sites to handle this subject explicitly. The argument FOR creating this site claimed that we have a missing socio-scientific angle that needed filling. </p>\n\n<p><strong>Private beta tests if that is a valid premise for creating a NEW site.</strong> </p>\n\n<p>If the founding community does not live up to those expectations, it creates a strong argument for \"I told you so\" &mdash; that the initiative has failed. </p>\n\n<p><strong>Stick to the mission.</strong> </p>\n\n<p>Don't give credence to arguments for closure.</p>\n"}, "1146": {"ParentId": 1145, "Score": 5, "Body": "<p>Sure I have an image myself:</p>\n\n<p><a href=\"https://i.stack.imgur.com/awUym.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/awUym.png\" alt=\"enter image description here\"></a></p>\n\n<p>It is fairly easy and with high to recognition value. It has like everything to do with AI and is a discussion topic for <a href=\"https://duckduckgo.com/?q=hal+9000+costume&amp;t=canonical&amp;iax=1&amp;ia=images\" rel=\"nofollow noreferrer\">every party</a> :)</p>\n"}, "1148": {"ParentId": 1147, "Score": 1, "Body": "<p>The first question about HAL9000 I believe is on-topic either on <a href=\"https://movies.stackexchange.com/\">Movies.SE</a>, <a href=\"https://scifi.stackexchange.com/\">Sci-fi.SE</a> or <a href=\"https://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligence\">WorldBuilding.SE</a>, but not in here, where we require some real-world questions, not related to science fiction.</p>\n\n<p>The second one regarding a joke, the quote from the closure reason from that link says it:</p>\n\n<blockquote>\n  <p>is not considered a good, on-topic question for this site</p>\n</blockquote>\n\n<p>this is because opinion-like questions or the one which are asking something from unlimited list of possibilities <a href=\"https://meta.stackexchange.com/a/98366/191655\">'are not a good fit for this type of Q&amp;A site'</a>. As said by <a href=\"https://meta.stackexchange.com/a/98366/191655\">@RCartaino</a>:</p>\n\n<blockquote>\n  <p>Stack Exchange is well-suited to asking very specific questions that represent real problems you encounter in your day-to-day work. A big part of that process is asking very long-tailed questions; the kind where folks with specific expertise in the subject can propose the best possible answer, which is then voted on so the best possible answers rise to the top.</p>\n</blockquote>\n\n<p>There was actually Humor site proposal, but it was <a href=\"https://area51.meta.stackexchange.com/q/24036/61861\">closed</a>, because of above reasons.</p>\n"}, "1149": {"ParentId": 1147, "Score": 7, "Body": "<p>No, they're not. \"Getting to know you\" or fun, minimal-mind questions are not a good fit for Stack Exchange. Notice how the Stack Overflow question you linked is locked. If it hadn't been locked for historical significance, it would definitely have been deleted.</p>\n\n<p>Especially during the private beta, we must focus on producing quality content. For fun, try <a href=\"http://chat.stackexchange.com/rooms/43371/artificial-intelligence\">chat</a>!</p>\n"}, "1152": {"ParentId": 55, "Score": -2, "Body": "<p>If you don't like a question, down-vote it.  That said, I disagree with the premise that there's a problem and \"ZOMG, s0meth1ng mus7 b3 d0ne, won'7 s0mebody th1nk of th3 ch1ldr3n1?!??!???\"   </p>\n\n<p>You can't dictate through top down command and control how a community should behave.  Just because the powers-that-be at StackExchange say \"no subjective questions\" doesn't mean that we need to reflect that and get all up in arms over any question that allows from an element of subjectivity.  The community will be what the community is, quit trying to social-engineer it. </p>\n\n<blockquote>\n  <p>There are already quite a few questions going beyond the original (blurry) boundary of the proposal, notably on implementation issues.</p>\n</blockquote>\n\n<p>Then the original boundary was wrong.</p>\n"}, "1153": {"ParentId": 1151, "Score": 3, "Body": "<p>I was one of the close voters, and let me explain here why I voted to close. </p>\n\n<p>As I, and some other users, have said <em>multiple times</em> before, we should avoid questions that are only related to machine learning. Those questions are already on-topic on both Data Science and Cross Validated. </p>\n\n<p>The point of creating this site was filling a gap that was not already covered by Data Science and Cross Validated. Early stopping is on-topic on both sites (<a href=\"https://stats.stackexchange.com/search?q=early+stopping\">1</a>, <a href=\"https://datascience.stackexchange.com/search?q=early+stopping\">2</a>). Remember that if this site looks to much like Data Science and/or Cross Validated it <em>will most likely <strong>not</strong> get out of private beta</em>.</p>\n"}, "1154": {"ParentId": 1150, "Score": 1, "Body": "<p>If I had voted to close it, I would have done so as \"too broad.\" It's not entirely clear what an answer should contain: a response to \"how <strong>exactly</strong> does it identify people on the street?\" would have to go extremely deep. Notice how the answer, while very interesting, doesn't explain how the car figures out how to highlight what objects. As mentioned in a comment, it's unlikely that anyone without access to the source code will be able to give definitive details.</p>\n"}, "1155": {"ParentId": 1151, "Score": 2, "Body": "<p>Data science and the Stats SE already have a huge overlap (>~80%), and I am worried to have a third SE that also significantly overlaps with them, so that why I VTC. </p>\n\n<p>I think the best solution would be along the lines of this proposal: <a href=\"https://meta.stackexchange.com/q/199989/178179\">build and strengthen the Stack Exchange community with \u201ccrossover questions\u201d between sites</a>.</p>\n"}, "1157": {"ParentId": 1156, "Score": 6, "Body": "<p>I think it's too early to worry about what to do if the site closes. We're different from previous AI sites in a couple important ways, and though we're not completely free of issues, we're making progress. For what it's worth, the target statistics on Area 51 are what you should expect from a site about to fully graduate (not one about to continue into public beta).</p>\n\n<p>Without this site, the topic of artificial intelligence is indeed split across the network. Fortunately, each site's scope is fairly well-defined, so even if finding a good site is tricky, checking whether a question is OK for a given site is quite doable. <a href=\"https://meta.stackexchange.com/\">Meta Stack Exchange</a> can help find a good home for questions - they even have <a href=\"https://meta.stackexchange.com/questions/tagged/site-recommendation\">a tag for such inquiries</a>, and I think a question for routing people to the right AI site would be in order.</p>\n\n<p>Again, don't get too worried. We'll cross that bridge if we come to it.</p>\n"}, "1158": {"ParentId": 1122, "Score": 2, "Body": "<p><em>Have we brought something new to the network?</em></p>\n\n<p>I think so. Yes, there's overlap with other sites, and yes it would be nice to have more deeper / research level questions and answers.  But I posit that getting to that level will happen IF the site is given enough time.  That and if we don't chase too many users away with too much bureaucracy and pedantry.</p>\n\n<p>Remember the old ai.se was actually working well, just at a scale that was - at the time - deemed too small by the se powers-that-be.  If this site is allowed to live post-beta, I expect it to get steadily better. Keep in mind,  AI is difficult because it's such a broad topic.  And even now there's lingering resistance among some people to talking about \"artificial intelligence\" (as opposed to \"machine learning\", etc.) after the various AI Winters of the past.  </p>\n"}, "1160": {"ParentId": 1159, "Score": 5, "Body": "<p>As mentioned in <a href=\"https://meta.stackexchange.com/a/233536/295684\">the MSE question</a> linked in the comments, that indicator isn't calculated just for you. When you gain the \"access moderator tools\" privilege - 10K on graduated sites, 2K in public beta, 1K in private beta - you always see the total number of reviews pending <em>for anyone</em>. That is, even if the queues look empty to you (i.e. you reviewed each item already), that number is how many items are still awaiting consensus from the community.</p>\n\n<p>Users with the edit privilege - 2K on graduated sites, 1K in public beta, 500 in private beta - but not the tools privilege will only see the number of items pending for them in the Suggested Edits queue.</p>\n"}, "1162": {"ParentId": 1161, "Score": 3, "Body": "<p>We are not requiring that every answer is fully supported by sources that you can currently link in the answer. So, if you are really certain that it is in fact true, you can leave it like it is. However, in this case, you aren't really certain anymore that it is true, or at least I wouldn't be. </p>\n\n<p>If you find, such as now, that it might not be true, or that in fact the opposite might be true, you might want to clarify by just adding a paragraph claiming that the opposite is true (\"On the other hand, (source 1) and (source 2) claim [...]\"), instead of in addition to the warning. It might be a good thing to start the other paragraph with something like \"I've read this\", so that it it clear that the other paragraph is properly sourced while the original one is not. You might want to add a small conclusion (i.e. I'm not certain anymore, what it is).</p>\n\n<p>You can also consider asking a question about it (this is not always appropriate) and linking to this question in your answer, at least when you receive a satisfactory answer. Also, please link to the answer in your question. </p>\n"}, "1164": {"ParentId": 1161, "Score": 1, "Body": "<p>If you can't verify the veracity of information, I think the safest thing to do - ethically speaking - is to annotate the information appropriately, as you've done. It's like Wikipedia's \"citation needed\" markers: they call out information that could be helpful, but is in need of further verification.</p>\n\n<p>I agree with wythagoras's answer. In short, cite sources when possible, and make it clear that we might not have the right answer nailed down yet.</p>\n"}, "1166": {"ParentId": 1165, "Score": 23, "Body": "<p><a href=\"https://ai.stackexchange.com/users/42\">\n<img src=\"https://ai.stackexchange.com/users/flair/42.png\"></a>\n<a href=\"https://ai.meta.stackexchange.com/users/42\">\n<img src=\"https://ai.meta.stackexchange.com/users/flair/42.png\"></a>\n\n<img src=\"https://stackexchange.com/users/flair/1448821.png\"></p>\n\n<h3>Notes:</h3>\n\n<p>Currently most voted and dedicated user with the relevant knowledge and skills about AI. In addition, he's working in this research area, so he knows what he's talking about. His skills may help to improve quality of this site.</p>\n\n<p>EDIT by NietzscheanAI (formerly known as user217281728): <br>\nMost kind, thanks. I'm happy to accept this nomination and want to work to make this a informative and useful site. I live in the UK, so tend to be active on the site between 07.00 and 23.00 GMT. My varied career has included games software company owner, generative music developer, software architect, pure mathematician and (for the last 13 years) AI researcher.</p>\n"}, "1167": {"ParentId": 1165, "Score": 14, "Body": "<p><a href=\"https://ai.stackexchange.com/users/75\">\n<img src=\"https://ai.stackexchange.com/users/flair/75.png\"></a>\n<a href=\"https://ai.meta.stackexchange.com/users/75\">\n<img src=\"https://ai.meta.stackexchange.com/users/flair/75.png\"></a>\n<a href=\"https://stackexchange.com/users/3364317/ben-n\">\n<img src=\"https://stackexchange.com/users/flair/3364317.png\"></a></p>\n\n<h3>Notes:</h3>\n\n<p>This nominee would be a good choice because of his active involvement in the community's development during the private beta and his experience on Stack Exchange!</p>\n\n<p>I'll step right up and offer my services to the community as a moderator pro tempore. I confess that I'm just an enthusiast when it comes to artificial intelligence, but I have been highly active here on meta, gaining the community's first silver badge: <a href=\"https://ai.stackexchange.com/help/badges/68/convention\">Convention</a>. I thoroughly enjoy reviewing and I have been working the queues since the site's beginning. I've also spent a large (probably unhealthy, heh) amount of time reading Meta Stack Exchange and the SE blogs, so I'm familiar with the Stack Exchange model, the software, and the expectations for the various roles. I'm also active on <a href=\"https://meta.superuser.com/users/380318/ben-n?tab=topactivity\">Meta Super User</a>, for what it's worth.</p>\n\n<p>I live in Illinois (midwestern United States), so I'm usually awake from UTC 15:00 to 3:00. You can read about the things I've created in my profile. I have a blog <a href=\"https://fleexlab.blogspot.com/2016/08/ai-stack-exchange-site.html\" rel=\"nofollow noreferrer\">on which I mentioned the site a while back</a>.</p>\n\n<p>I've been doing what I can to make sure this site survives, and that has required casting a few close votes. Hopefully I haven't come off as too much of a maniacal ruthless reviewer <code>:)</code>. When asked on meta, in comments, or in <a href=\"http://chat.stackexchange.com/rooms/43371/artificial-intelligence\">chat</a> about why a question is closed, I always write up a helpful, respectful explanation. If I ever do something you think is less than ideal, please feel free to ask me about it! Like all humans (though perhaps not AIs!) I make the occasional mistake, and when I see that's happened, I make it right.</p>\n\n<p>I have my own opinions and judgments, of course, but I would be happy to carry out as moderator pro tempore the consensus of the community, the mod team, and Stack Exchange. We're all in this together.</p>\n\n<p>It's a pleasure building this community with everyone here. I look forward to continuing to the next stage of site growth with y'all!</p>\n"}, "1168": {"ParentId": 1165, "Score": 15, "Body": "<p><a href=\"https://ai.stackexchange.com/users/10\">\n<img src=\"https://ai.stackexchange.com/users/flair/10.png\"></a>\n<a href=\"https://ai.meta.stackexchange.com/users/10\">\n<img src=\"https://ai.meta.stackexchange.com/users/flair/10.png\"></a>\n<a href=\"https://stackexchange.com/users/555192\">\n<img src=\"https://stackexchange.com/users/flair/555192.png\"></a></p>\n\n<h3>Notes:</h3>\n\n<p>The second most voted and active user, data scientist with the right skillset across different AI branches. His answers are reliable and interesting. His skills can be a great asset to improve quality of this site.</p>\n\n<p>EDIT by Matthew Graves: Thanks for the nomination! I'm pleased to accept it. I'm interested in helping this site help people better understand AI and the issues surrounding it, both through direct effort and community building. I've been clearing out review queues here as soon as I got access to them, and that's typically the first thing I check after my comment inbox. </p>\n\n<p>I'm currently in Austin, Texas, and so would typically be online from to about noon to 2am UTC. I've been doing machine-learning related work for, depending on how you count it, about 8 years now, mostly as a student but now also as a data scientist. My research effort has mostly been in numerical optimization, machine reliability, and time series analysis, rounded out by my personal interests in psychology, economics, and philosophy. I've been interested in intelligence for as long as I can remember, and that grew to encompass artificial intelligence as soon as I was introduced to it.</p>\n\n<p>To a large degree I 'grew up on the internet'; forum-posting has been a major hobby for over half of my life at this point. I've consistently had a reputation for being polite, calm, and open-minded; qualities that I hope would serve me well as a moderator.</p>\n"}, "1169": {"ParentId": 1165, "Score": 6, "Body": "<p>I'll volunteer myself.</p>\n\n<p><a href=\"https://ai.stackexchange.com/users/33/\">\n<img src=\"https://ai.stackexchange.com/users/flair/33.png\"></a>\n<a href=\"https://ai.meta.stackexchange.com/users/33/\">\n<img src=\"https://ai.meta.stackexchange.com/users/flair/33.png\"></a>\n<a href=\"https://stackexchange.com/users/48222/\">\n<img src=\"https://stackexchange.com/users/flair/48222.png\"></a></p>\n\n<h3>Notes:</h3>\n\n<p>This nominee would be a good choice because - he is passionate about AI and its potential applications for improving the human condition.  This nominee is also a strong supporter of open exchange of scientific knowledge and technology, as expressed in the Open Source, Open Web, Open Data, Open Science and Open Hardware initiatives.   This nominee has been participating in multiple Stack Exchange communities for many years.   </p>\n\n<p>You could consider this nominee to be the \"ruthless NON closer\" as he believes that closing questions is generally harmful to the community, as it is perceived as an aggressive and hostile act by whoever posted the question.  This nominee believes that \"bad\" questions can simply be down-voted and allowed to die from lack of activity in <em>almost</em> all cases.</p>\n\n<p>This nominee believes we can strike a balance between being \"beginner friendly\" and still keeping things interesting enough to attract experts, but believes that it will take some time to establish our presence in the AI world and attract the high-level researchers and others of that ilk.  </p>\n\n<hr>\n\n<p>Since I volunteered myself, it should go without saying that I accept this nomination.</p>\n\n<p>Hi, I am Phillip. I live in Chapel Hill, NC, so I am generally active on this site from around 10:00am through 1:00am Eastern time. Some other things you may want to know about me are: I am founder / president at <a href=\"https://www.fogbeam.com\" rel=\"nofollow noreferrer\">Fogbeam Labs</a>, an open source software company.  I was a volunteer firefighter for many years and was Assistant Fire Chief of my department for the last couple of years I was there.  </p>\n\n<p>I am the founder/organizer of the Research Triangle Park \"Semantic Web / Artificial Intelligence / Machine Learning\" Meetup here in the Raleigh/Durham area.  I'm also active on <a href=\"http://mindcrime.github.io\" rel=\"nofollow noreferrer\">Github</a> and <a href=\"https://news.ycombinator.com/user?id=mindcrime\" rel=\"nofollow noreferrer\">Hacker News</a>.  </p>\n"}, "1170": {"ParentId": 1165, "Score": 0, "Body": "<p><a href=\"https://ai.stackexchange.com/users/5\">\n<img src=\"https://ai.stackexchange.com/users/flair/5.png\"></a>\n<a href=\"https://ai.meta.stackexchange.com/users/5\">\n<img src=\"https://ai.meta.stackexchange.com/users/flair/5.png\"></a></p>\n\n<hr>\n\n<h3>Notes:</h3>\n\n<p>While I'm not the most knowledgeable about AI, and don't have the highest reputation level, I know a lot about moderating.</p>\n\n<p>In the past three days, every single day, I've cleared all the review ques I have access to. I currently own two organizations, and I moderate, or lead, both of them. I have 2 pending proposals on Area51. I'm active on the Stack Exchange sites almost every single day. I have former experience from moderating as a former FPC from Scratch.</p>\n\n<p>It would be an honor to be a moderator on this site.\nThank you for reading.</p>\n"}, "1171": {"ParentId": 35, "Score": 22, "Body": "<p>Yes, absolutely.  Regardless of your position on the whole \"theory vs. implementation\" thing, math is an essential part of AI and having convenient access to LaTex would be a boon here. </p>\n"}, "1172": {"ParentId": 1165, "Score": 0, "Body": "<p><a href=\"https://ai.stackexchange.com/users/8\">\n<img src=\"https://ai.stackexchange.com/users/flair/8.png\"></a>\n<a href=\"https://ai.meta.stackexchange.com/users/8\">\n<img src=\"https://ai.meta.stackexchange.com/users/flair/8.png\"></a>\n<a href=\"https://stackexchange.com/users/22370\">\n<img src=\"https://stackexchange.com/users/flair/22370.png\"></a></p>\n\n<h3>Notes:</h3>\n\n<p>This nominee would be a good choice because kenorb is a very active user, a person who knows a lot about AI, and, I feel, cares about helping this community grow. kenorb should be one of our moderators - even if his English isn't perfect, I still think he's perfect mod material. :)</p>\n\n<hr>\n\n<p>First of all, I would like to thank you for nomination and I am pleased to take the responsibility of being a pro tempore mod. I believe that this site has a unique opportunity to make a huge impact to global technology market driven by artificial intelligence and our everyday life in the very near future by sharing advanced knowledge accessible for all.</p>\n\n<p>I have been using SE for over 7 years, I am experienced across a variety of fields and I am familiar with moderation tools and I understand their purpose.</p>\n\n<p>I am an experienced software engineer specialising in a variety of information technology stacks with over 18 years experience consulting across a range of sectors and multination companies. One of the recent one is planning to <a href=\"http://www.ft.com/cms/s/0/5ea4c668-1364-11e6-91da-096d89bd2173.html#axzz4HXDwufht\" rel=\"nofollow noreferrer\">'to deploy drone army'</a> worldwide which can expand our scope of understanding of artificial intelligence (e.g. imagine flying drones in the restaurant and delivering your food to your table after pressing a single button). Check also my <a href=\"https://stackoverflow.com/cv/kenorb\">user CV profile</a>.</p>\n\n<p>My first AI program was a chat bot written over 18 years ago in Pascal with custom written assembler libraries in order to make my school mates believing that they are chatting on IRC with real people, while being on the computers without any internet connection, so other can play games on spare computers with the real network. This worked, for the first 15-30 minutes, later on they could find out that something was wrong or get bored. Second project was involved AI bots protecting IRC channels. I did some AI in games. Since then I am interested in practical applications of AI. This is my long term hobby and interest. Further projects required more sophisticated requirements. Currently I am working on integration AI with the financial algorithms and systems.</p>\n\n<p>I am good team player, so I am able to cooperate with other mods, I'm also available on daily basis (GMT/DST time). I hope we can improve this site by keeping it away from chaos, spam and trolls, to provide high quality site. </p>\n"}, "1173": {"ParentId": 1165, "Score": 12, "Body": "<p><a href=\"https://ai.stackexchange.com/users/145\">\n<img src=\"https://ai.stackexchange.com/users/flair/145.png\"></a>\n<a href=\"https://ai.meta.stackexchange.com/users/145\">\n<img src=\"https://ai.meta.stackexchange.com/users/flair/145.png\"></a>\n<a href=\"https://stackexchange.com/users/5129611\">\n<img src=\"https://stackexchange.com/users/flair/5129611.png?theme=dark\" width=\"208\" height=\"58\" alt=\"profile for Mithrandir on Stack Exchange, a network of free, community-driven Q&amp;A sites\" title=\"profile for Mithrandir on Stack Exchange, a network of free, community-driven Q&amp;A sites\">\n</a></p>\n\n<h3>Notes:</h3>\n\n<p>I would like to offer my services as a pro-tem moderator on this site. I have watched been a relatively active member since I joined on Day 0. I have 135 edits (counting tag-only edits), I was the first one to earn the <a href=\"https://ai.stackexchange.com/help/badges/12/strunk-white\">Strunk and White badge</a>, I am the top reviewer for both <a href=\"https://ai.stackexchange.com/review/close/stats\">Close Votes</a> and <a href=\"https://ai.stackexchange.com/review/reopen/stats\">Reopen Votes</a> on the main site, I was the first reviewer of <a href=\"https://ai.stackexchange.com/review/late-answers/stats\">Late Answers</a>,  and I was the first reviewer on Meta. I have watched Meta, and pitched in when I could.<br>I was also one of 25 users to earn the <a href=\"https://ai.stackexchange.com/help/badges/30/beta\">Beta badge</a>, which means that I was an active user in the Private Beta. I now also have the <a href=\"https://ai.stackexchange.com/help/badges/68/convention\">Convention badge</a>, which means that I've been active here on Meta.<br><br> I may not know so much about AI, really, but I do know enough to be able to tell if something answers the question or not, I think. :)</p>\n\n<p>Also, I am one of the only users who has ventured onto <a href=\"http://chat.stackexchange.com/rooms/43371/the-singularity\">chat</a> :P</p>\n\n<p>I am also active on this Meta, the Puzzling Meta, and the main Meta*.</p>\n\n<p>I am fairly well-versed in the content in the Help Center and site policy, as well.</p>\n\n<p><sub>* Okay, I mostly flag things as off-topic. But I have asked/answered some!</sub></p>\n\n<p><strong>About Me</strong></p>\n\n<p>I'm a 14 year-old kid. The only moderation experience I have is being an admin on 3 Wikias. (Not popular ones - little outdated backwater ones. :P) I live in the UTC+2/3 time zone, although I'm often on late.<br>\nI don't go to school; I'm homeschooled.<br>\nI am not a programmer.<br>\nI have been using SE for a year and 11 months, roughly, so I have a pretty good idea about how the site works :P.</p>\n"}, "1175": {"ParentId": 1174, "Score": 1, "Body": "<p>I think a lot of topics about AI/ANN wants to achieve a brain simulation, so maybe we can rename it to: <a href=\"https://ai.stackexchange.com/questions/tagged/brain-simulation\" class=\"post-tag\" title=\"show questions tagged &#39;brain-simulation&#39;\" rel=\"tag\">brain-simulation</a>.</p>\n"}, "1176": {"ParentId": 1174, "Score": 2, "Body": "<p>What would be the difference between brain-simulation and neuromorphic-computing tags?</p>\n"}, "1178": {"ParentId": 1177, "Score": 5, "Body": "<p>Yes, it's pointless to have two tags referring to the same thing. Since <a href=\"https://ai.stackexchange.com/questions/tagged/deepqa\" class=\"post-tag\" title=\"show questions tagged &#39;deepqa&#39;\" rel=\"tag\">deepqa</a> had three questions and <a href=\"https://ai.stackexchange.com/questions/tagged/watson\" class=\"post-tag\" title=\"show questions tagged &#39;watson&#39;\" rel=\"tag\">watson</a> had four (and all but one DeepQA question had the Watson tag already), I manually merged the tags together by removing <a href=\"https://ai.stackexchange.com/questions/tagged/deepqa\" class=\"post-tag\" title=\"show questions tagged &#39;deepqa&#39;\" rel=\"tag\">deepqa</a>.</p>\n\n<p>One could make the argument that DeepQA is the research project while Watson is the product, but all of the questions tagged <a href=\"https://ai.stackexchange.com/questions/tagged/deepqa\" class=\"post-tag\" title=\"show questions tagged &#39;deepqa&#39;\" rel=\"tag\">deepqa</a> were about Watson.</p>\n"}, "1179": {"ParentId": 1177, "Score": 2, "Body": "<p><em>Watson</em> is the name of the computer, and <em>DeepQA</em> is the name of the technology  and software. They both correlated, but <em>Watson</em> sounds like more specific, but on the other hand there are no any known computers which are using <em>DeepQA</em> which aren't called <em>Watson</em>.</p>\n\n<p>We do not know if there are any other computers which uses <em>DeepQA</em> technology, but not related to <em>Watson</em>. There could be some implementation of <em>DeepQA</em> not being called <em>Watson</em>. To simplify things, both terms can be synonyms where <a href=\"https://ai.stackexchange.com/questions/tagged/watson\" class=\"post-tag\" title=\"show questions tagged &#39;watson&#39;\" rel=\"tag\">watson</a> should be the main tag, since it is more popular (it has its own Wikipedia page, where <em>DeepQA</em> does not).</p>\n\n<p>More detailed information about the differences check <a href=\"https://ai.meta.stackexchange.com/a/1180/8\">@Avik post</a> and the following answer:</p>\n\n<ul>\n<li><a href=\"https://ai.stackexchange.com/q/1665/8\">Are there any DeepQA-based computers other than Watson?</a></li>\n</ul>\n"}, "1180": {"ParentId": 1177, "Score": 2, "Body": "<p>I would be careful to merge the two together. <a href=\"https://ai.stackexchange.com/questions/tagged/deepqa\" class=\"post-tag\" title=\"show questions tagged &#39;deepqa&#39;\" rel=\"tag\">deepqa</a> is very much just that - a deep learning approach to questions and answers. This covers NLP, hypothesis formation, candidate answer generation, and answer selection from the candidates. It is fully limited to that domain. </p>\n\n<p>These pages show what I'm getting at: </p>\n\n<p><a href=\"https://www.research.ibm.com/deepqa/deepqa.shtml\" rel=\"nofollow noreferrer\">https://www.research.ibm.com/deepqa/deepqa.shtml</a>\n<a href=\"http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2159\" rel=\"nofollow noreferrer\">http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2159</a>\n<a href=\"http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2162\" rel=\"nofollow noreferrer\">http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2162</a>\n<a href=\"http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2160\" rel=\"nofollow noreferrer\">http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2160</a></p>\n\n<p>On the other hand, <a href=\"https://ai.stackexchange.com/questions/tagged/watson\" class=\"post-tag\" title=\"show questions tagged &#39;watson&#39;\" rel=\"tag\">watson</a> is this titanic over-arching project that dips into culinary arts, healthcare, and more recently education and other topics I'm sure I'm missing. It is the foremost product of IBM's cognitive computing research and has numerous applications and uses, and elements that construct it. It goes well beyond just the QA portion (which is an integral part of Watson, but not the entirety or even nearly a synonym of Watson).</p>\n\n<p>For this reason, I personally think they are certainly different topics, but being new to stack exchange I'm not sure how you would like to handle this.</p>\n"}, "1183": {"ParentId": 1123, "Score": 4, "Body": "<p>AI is broader than Machine Learning and Statistical Learning. Yes, the probabilistic / statistical stuff dominates the conversation these days, but AI includes rule based systems, expert systems, symbolic processing, logic programming and other things that would not be on-topic at Cross Validated (or Data Science).</p>\n\n<p>We've also been saying that we have more of a focus on the philosophy of AI and the humanities related aspects, as opposed to strictly the technology.</p>\n"}, "1184": {"ParentId": 1181, "Score": 2, "Body": "<p>Categorizing things in pictures as certain types of objects definitely sounds like <a href=\"https://ai.stackexchange.com/questions/tagged/image-recognition\" class=\"post-tag\" title=\"show questions tagged &#39;image-recognition&#39;\" rel=\"tag\">image-recognition</a> to me. After all, the computer is supposed to <em>recognize</em> what the thing is and then put them into categories.</p>\n\n<p>Two of the three existing questions in <a href=\"https://ai.stackexchange.com/questions/tagged/computer-vision\" class=\"post-tag\" title=\"show questions tagged &#39;computer-vision&#39;\" rel=\"tag\">computer-vision</a> don't really seem to be related to computerized image comprehension at all. The last - the question you linked - would, in my opinion, be better served by <a href=\"https://ai.stackexchange.com/questions/tagged/image-recognition\" class=\"post-tag\" title=\"show questions tagged &#39;image-recognition&#39;\" rel=\"tag\">image-recognition</a>. <a href=\"https://ai.stackexchange.com/questions/tagged/computer-vision\" class=\"post-tag\" title=\"show questions tagged &#39;computer-vision&#39;\" rel=\"tag\">computer-vision</a> seems more appropriate for questions involving the AI moving around and continually <em>seeing</em> the world and the states of the things in it (like self-driving cars do), which involves more than just figuring out what objects are present.</p>\n\n<p>Since <a href=\"https://ai.stackexchange.com/questions/tagged/visual-search\" class=\"post-tag\" title=\"show questions tagged &#39;visual-search&#39;\" rel=\"tag\">visual-search</a> doesn't exist yet, I think we should wait for a compelling distinction between it and <a href=\"https://ai.stackexchange.com/questions/tagged/image-recognition\" class=\"post-tag\" title=\"show questions tagged &#39;image-recognition&#39;\" rel=\"tag\">image-recognition</a> before creating it.</p>\n"}, "1185": {"ParentId": 1182, "Score": 1, "Body": "<p><strong><a href=\"https://ai.stackexchange.com/questions/tagged/natural-language\" class=\"post-tag\" title=\"show questions tagged &#39;natural-language&#39;\" rel=\"tag\">natural-language</a> should stay. The others - synonymize.</strong></p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/tagged/natural-language\" class=\"post-tag\" title=\"show questions tagged &#39;natural-language&#39;\" rel=\"tag\">natural-language</a> is the most descriptive tag name, as a person who knows fairly close to nothing about AI. If you add the others as synonyms, then everyone will be able to find the right tag. :)</p>\n"}, "1190": {"ParentId": 1188, "Score": 3, "Body": "<p>This is <a href=\"/questions/tagged/status-bydesign\" class=\"post-tag moderator-tag\" title=\"show questions tagged &#39;status-bydesign&#39;\" rel=\"tag\">status-bydesign</a>, although it is not because of the private beta.</p>\n\n<p>From <a href=\"https://meta.stackexchange.com/questions/67397/list-of-all-badges-with-full-descriptions/188732#188732\">List of all badges with full descriptions</a>:</p>\n\n<blockquote>\n  <p>A tag must appear on a minimum of 100 questions to be considered for tag badges.</p>\n</blockquote>\n\n<p>Since we don't have tags with 100 questions or more, we don't yet see tag badges.</p>\n"}, "1198": {"ParentId": 1197, "Score": 1, "Body": "<p>Taking this from the tour and initial Area 51 description:</p>\n\n<blockquote>\n  <p>Artificial Intelligence Stack Exchange is a question and answer site for people interested in conceptual questions about life and challenges in a world where \"cognitive\" functions can be mimicked in a purely digital environment.</p>\n</blockquote>\n"}, "1199": {"ParentId": 1197, "Score": 8, "Body": "<p>I am in the process of writing up the final review of this site. In it, we discuss the difficulties this site is having with scope &mdash; mostly around the <em>popular fallacies</em> of what AI actually is. Artificial intelligence is very different from how it\u2019s portrayed in the movies. Whenever a problem becomes solvable by a computer, people start arguing that it does not require intelligence at all&hellip; and \"as soon as it works, no one calls it AI anymore\" &mdash; <em>John McCarthy</em></p>\n\n<p>As such, this community is having difficulty navigating that narrow gap of what I'd call \"AI relevance\".</p>\n\n<p>The proposal that created this site was intentionally placed in the <em>'scientific'</em> category. If you accept that we are not creating another programming site, I think we stumbled upon in interesting niche that describes the original premise of this site nicely:</p>\n\n<blockquote>\n  <p>Artificial Intelligence Stack Exchange is a site with a social and scientific focus on \"Advanced Computing in Society.\"</p>\n</blockquote>\n\n<p>Think about it. With autonomous cars, smart surveillance, and \"the next big thing\" capturing the headlines, this isn't a terrible idea for a subject. Draping it in the popular AI label gives it a better focus&hellip; and it completely disambiguate that <strong>this is <em>not</em> a technical implementation or programming site.</strong> We already have that.</p>\n"}, "1206": {"ParentId": 1205, "Score": 5, "Body": "<p>It appears that there is at least one question like this on the site:</p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/1461/are-siri-and-cortana-ai-programs\">Are Siri and Cortana AI programs?</a></p>\n\n<p>So I guess it would be okay - as long as you are asking <strong>about one</strong> (or two) <strong>specific thing</strong>(s).</p>\n\n<p>For asking about in general when something is AI, that has already been asked: <a href=\"https://ai.stackexchange.com/questions/1507/what-are-the-minimum-requirements-to-call-something-ai\">What are the minimum requirements to call something AI?</a></p>\n\n<p>The tags... Now that's the problem. That might be worth its own Meta post.</p>\n\n<p>And welcome to AI!</p>\n"}, "1207": {"ParentId": 1139, "Score": 3, "Body": "<p>In general, I think that we should allow questions on neural network architecture in order to attract and retain experts who actually build state of the art systems.</p>\n\n<p>But for that specific question, I'm torn and lean towards keeping it closed. It's a novice instead of an expert architecture question; a good answer to it looks more like an explanation of how the necessary number of training examples scales with rule complexity, and how to ensure that the model depth and breadth is sufficient to encode rules of a certain complexity, and maybe also how to 'cheat' on model size and training requirements with convolution layers.</p>\n\n<p>But if we want a question to expound on that sort of 101 material, it should probably be a set of three specific, easily searchable questions rather than the question that actually exists.</p>\n"}, "1208": {"ParentId": 1139, "Score": -1, "Body": "<p>There are already plenty of questions on programming AI/NN frameworks on Data science and SO: I don't think we need one more place, SE is fragmented enough.</p>\n"}, "1209": {"ParentId": 1205, "Score": 3, "Body": "<p>In addition to what was said by Mithrandir, I would personally say it's best that such a question focus on <strong>only one thing</strong>. In other words, questions that ask about an aspect of each item in a big list of things would be less than ideal. In the case of Siri and Cortana (smart personal assistants, basically), they're very similar products, so it makes sense to have one question for them.</p>\n\n<p>It would be even better if such questions included <strong>specific features</strong> of the objects/products that the question owner suspects may produce AI. That shows research effort, and in discovering the relevant features, the person who asks might stumble upon an interesting insight themselves. It also has the benefit of covering all products that have that feature (having wide applicability yet focused scope tends to mark great questions in my experience), so we might not even need to name Siri and Cortana in the question title.</p>\n"}, "1210": {"ParentId": 1139, "Score": 0, "Body": "<p>Our site was created to hold questions about the scientific and social - not technical or programmatical - aspects of artificial intelligence. That's evidenced by its original section in Area 51, and by several posts by Stack Exchange staff. For example, see <a href=\"https://ai.meta.stackexchange.com/a/1199/75\">this answer</a> on the question about summarizing our scope (relevant part reproduced here):</p>\n\n<p>The proposal that created this site was intentionally placed in the 'scientific' category. If you accept that we are not creating another programming site, I think we stumbled upon in interesting niche that describes the original premise of this site nicely:</p>\n\n<blockquote>\n  <blockquote>\n    <p>Artificial Intelligence Stack Exchange is a site with a social and scientific focus on \"Advanced Computing in Society.\"</p>\n  </blockquote>\n  \n  <p>Think about it. With autonomous cars, smart surveillance, and \"the next big thing\" capturing the headlines, this isn't a terrible idea for a subject. Draping it in the popular AI label gives it a better focus\u2026 and it completely disambiguate [sic] that <strong>this is <em>not</em> a technical implementation or programming site.</strong> We already have that.</p>\n</blockquote>\n\n<p>The emphasis was in the original.</p>\n\n<p>Especially when we actually have a pretty cool scope draft (as summarized there), I don't think we should add an extra place in the network for AI-related programming questions.</p>\n"}, "1211": {"ParentId": 1141, "Score": 10, "Body": "<blockquote>\n  <p>Data Science is an applied site</p>\n</blockquote>\n\n<p>Yeah, for <em>data science</em>.  Data science is not artificial intelligence.  There is overlap around the statistical techniques for machine learning, but they just are not identical. </p>\n\n<blockquote>\n  <p>Please do close questions that are highly technological or asking for applications.</p>\n</blockquote>\n\n<p>I'm sorry, but I think this is very misguided.  Ignoring all aspects of implementation and technology on a se like this, is like a football team fielding an offense, but no defense (or vice versa).  Or maybe I should say, it's like a Reese's Peanut Butter Cup without the chocolate.</p>\n\n<p>The simple truth is, you can say \"programming questions belong on xx.se (or so)\" but there are programming questions which - in principle - would be best suited for this site.  If somebody is asking about an AI specific technique or something highly specialized like rule induction using OPS5, this community is probably a better resource than datascience.se, stats.se, or possibly even so. </p>\n"}, "1214": {"ParentId": 1139, "Score": 2, "Body": "<p>As far as I'm concerned, programming questions should be on-topic IF they are highly specific to AI.  That is, if somebody asks \"How do I add an item to a collection in Java\", that would be off-topic even if they were building an AI application.  But if somebody is doing something very specialized like Answer Set Programming in Prolog, etc., then I think this community would be best suited to answer that and, as such, the question should be considered on-topic.</p>\n"}, "1217": {"ParentId": 1197, "Score": -1, "Body": "<blockquote>\n  <p>Artificial Intelligence Stack Exchange is a question and answer site <strong>for people interested in conceptual questions about non-biological agents</strong>. Join them; it only takes a minute</p>\n</blockquote>\n"}, "1218": {"ParentId": 1215, "Score": 2, "Body": "<p>When I think of \"implementation\", things like math and code come to mind, while the larger components of AI construction don't fall under that category. Selecting features to build an AI for a certain purpose would therefore be on-topic, though they could easily be too broad. <a href=\"https://ai.stackexchange.com/q/1784/75\">Your first example</a> approaches \"how do I solve this important problem with AI?\", which possibly requires a deep knowledge of that field.</p>\n\n<p>Questions tangentially related to programming, but not actually about the coding of the AI itself, are also OK. <a href=\"https://ai.stackexchange.com/q/1783/75\">Your second example</a> asks how to represent part of an AI's state for debugging visualization. It's a pretty neat question in my opinion, landing squarely in the science part of artificial intelligence.</p>\n\n<p>I would be a little wary of allowing questions about the fine details (i.e. the mathematical/statistical mechanics) of yet-to-be-solved research problems, as those are likely to be much better served at one of the math-heavy sites. Conceptual questions about what kinds of things they work on are interesting and well-suited to our site.</p>\n\n<p>Executive summary: if a question has mathematical formulae or computer code as critical elements, the best home for it is <em>possibly</em> a different site. This answer contains a lot of weasel words to emphasize that's it's not at all a rulebook that applies everywhere. Such an answer would be a tome.</p>\n"}, "1219": {"ParentId": 1215, "Score": 4, "Body": "<p>I would say that it's a judgment call on a case by case basis.  I don't think there's a simple rule you can implement that can capture all of the nuance involved here.  My feeling is, unless you say with pretty close to <strong>absolute certainty</strong> that a question which includes code would get a better answer somewhere else, it's better to err on the side of leaving it alone.</p>\n\n<p>That a question might contain math is, to me, nearly completely irrelevant to whether a question belongs here or not.  Irrelevant in that it's orthogonal to the issue of whether something is \"conceptual\" or \"implementation\".  After all, math <strong>is</strong> the language of science.  </p>\n"}, "1220": {"ParentId": 1, "Score": 3, "Body": "<p>Here's one idea:  Search Meetup.com for meetups which are related to artificial intelligence, and post this link to their message boards and / or mailing lists, with a brief note saying \"you may find this of interest\".</p>\n"}, "1222": {"ParentId": 1221, "Score": 10, "Body": "<p>Yes. </p>\n\n<p>If we send away everyone asking about philosophy; send everyone asking about feature selection for ANNs to data science and send everyone asking about AI research institutes to chat then there's really not so much left to talk about.</p>\n"}, "1224": {"ParentId": 1223, "Score": 4, "Body": "<p>Unfortunately, <strong>no.</strong> This has been decided that it is off-topic here. See <a href=\"https://ai.meta.stackexchange.com/questions/1141/a-friendly-reminder-that-this-site-comes-from-the-science-category\">this meta post</a>.</p>\n"}, "1226": {"ParentId": 1225, "Score": 6, "Body": "<p>Don't worry! We've passed the private beta mark, while the sites you mentioned were closed during that stage. That indicates that Stack Exchange reviewed our progress and determined that we're doing well enough to continue into <em>public</em> beta, which is <a href=\"https://ai.meta.stackexchange.com/q/1202/75\">where we are now</a>.</p>\n\n<p>Regarding the Area 51 stats: those goals are what you should expect from a site that's about to graduate fully. In days of old, it was expected that graduation would happen at 90 days in or else the site would indeed be closed. Now, sites can stay in beta as long as necessary. For more information, see <a href=\"https://meta.stackexchange.com/q/257614/295684\">Graduation, site closure, and a clearer outlook on the health of SE sites</a>.</p>\n\n<p>All that said, we should be promoting this site and growing the community. Asking quality questions and providing great answers is an excellent way to improve the site. We're collecting ideas for site promotion here: <a href=\"https://ai.meta.stackexchange.com/q/1/75\">How do we promote this site?</a></p>\n"}, "1228": {"ParentId": 1, "Score": 0, "Body": "<p>I think that we could try to promote the site with people from a broad range of disciplines. I remember seeing on Area51 what other people committed to, and there were mostly engineering or computer-related sites. Perhaps we need some philosophers, some psychologists, some neuroscientists and linguists here. </p>\n\n<p>Maybe encouraging questions on other sites of the SX-network?</p>\n\n<p>Or social networks posts?</p>\n\n<hr>\n\n<p>I also wanted to add another site which has overlapping topics: <a href=\"https://cogsci.stackexchange.com/\">Cognitive Sciences</a></p>\n"}, "1230": {"ParentId": 1227, "Score": 3, "Body": "<blockquote>\n  <p>Or we just get new answers to questions with an accepted answer and switch (the checkmark) if the new is better?</p>\n</blockquote>\n\n<p><strong>Yes.</strong> That's <em>exactly</em> what we'll do. It makes no sense to do it any other way.</p>\n\n<p>If we have community-wiki answers to everything, than that complicates the reputation system, also - not enough people will reach new privilege levels.</p>\n\n<p>As the field grows and changes, so too the site - we'll have new questions, and new answers to old questions.</p>\n"}, "1231": {"ParentId": 1227, "Score": 2, "Body": "<p>This is something to consider even on very technical sites like Stack Overflow. New developments (e.g. new language features) allow new and better solutions to problems. That's yet another reason why questions should allow new answers even after one is accepted. The accept mark indicates that the answer is the best for the question poster at the time. In some cases, the question poster vanishes, never to be seen again on the site. Fortunately, we have something else to measure answer usefulness:</p>\n\n<p><strong>Votes.</strong> Posts accept votes forever (in most cases), and new answers (among other events) push the question back onto the site front page so it can be examined anew. Community members should definitely read new posts and vote on their quality. In an ideal world, better answers would always overtake old decent answers in score, but that doesn't always happen. If you see a really awesome answer going unnoticed, you might consider <a href=\"https://ai.stackexchange.com/help/bounty\">placing a bounty</a>!</p>\n\n<p>As Mithrandir mentioned, community wiki isn't ideal for this scenario, since it has the undesired effect of disabling reputation changes. Newer users should add new takes on the issue via new answers (or possibly comments, if the changes are tiny).</p>\n"}, "1232": {"ParentId": 1225, "Score": 3, "Body": "<p>Recently we've gone through very critical private stage where 3 attempts since the last 6 years failed to success. See: <a href=\"https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/\">No AI in Area51</a>.</p>\n\n<p>Since we've successfully passed the final review process, we've now more time to improve and expand our site to match the healthy state, before graduating to full site (it can take months or even years to achieve that stage).</p>\n\n<p>If you check <a href=\"http://stackexchange.com/sites#questionsperday\">All sites statistics</a> and compare to other sites and take into the account that we've just entered the public beta, so it's not so bad as it looks (>30 sites with less questions asked per day). It just takes time for new people to join and starting using the site, not everybody knows about it yet.</p>\n\n<p>As <a href=\"https://ai.meta.stackexchange.com/a/1199/8\">@Robert</a> mentioned few weeks ago:</p>\n\n<blockquote>\n  <p>we stumbled upon in interesting niche that describes the original premise of this site</p>\n</blockquote>\n\n<p>Currently we are in stage of clarifying the scope as per: <a href=\"https://ai.meta.stackexchange.com/q/1197/8\">How can we quickly describe our site?</a></p>\n\n<p>Instead of worrying about it, we should ask ourselves: <a href=\"https://ai.meta.stackexchange.com/q/1/8\">How do we promote this site?</a></p>\n"}, "1233": {"ParentId": 1, "Score": 0, "Body": "<p>I think Stack Exchange A.I. site is self-promoted and it does not need promotion. We just need a bit more time, that's all. I think this site has enough active experts so far, so our <em>answer ratio</em> is fine (1.8 at the time of writing).</p>\n\n<p>Secondly given Stack Exchange higher ranked <a href=\"https://en.wikipedia.org/wiki/Search_engine_optimization\" rel=\"nofollow noreferrer\">SEO</a> abilities, people looking for A.I. answers will quickly find this place. Especially having in mind that A.I. is more likely to be the next big boom for this century, I believe next year we'll hit the <a href=\"https://ai.meta.stackexchange.com/q/1225/8\">site healthy stats</a> without even promoting it.</p>\n\n<p>Although if we decide to promote it, we need to be careful, as promoting this site to the wrong communities, this can result in lot of people asking the broad and opinion based posts.</p>\n\n<p>Artificial promotion isn't a good one, but sharing the AI links to the good answers on relevant forum posts or reddit-like sites is a great start.</p>\n"}, "1234": {"ParentId": 1221, "Score": 3, "Body": "<p>Yes, but I think many philosophical questions would be better off on Philosophy SE. It depends on the type of question. Questions that AI experts have mostly thought about (like <a href=\"https://ai.stackexchange.com/q/1824/8\">\"Why would an AI need to 'wipe out the human race'?\"</a>) are better suited here, while questions that are tangentially related to AI but are really referring to \"philosophical concepts\" (<a href=\"https://philosophy.stackexchange.com/questions/37442/are-robot-rebellions-even-possible\">robotic free will</a> and <a href=\"https://philosophy.stackexchange.com/questions/11450/can-computers-be-programmed-to-be-creative/15617#15617\">AI creativity</a>) are better left to the philosophy experts.</p>\n"}, "1235": {"ParentId": 1078, "Score": 6, "Body": "<p>I'm sorry, but we can't just go with a simple, blanket statement like \"Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in other SE, such as Stats and Data Science.\"  Why? Because not <em>all</em> questions about \"programming, algorithms, modeling...\", vis-a-vis Artificial Intelligence, are on-topic at those other sites!  But they are here.</p>\n\n<p>And what's the distinction that should be in play?  Well, simply, \"programming, algorithms, modeling, math, etc. that are *specific to AI\" are on-topic here.  It really can't be any other way.</p>\n\n<p>I mean, think about it... we claim to be a \"science\" site, but then try to say that \"math\" is off-topic? That's absurd.  Science <em>is</em> math and math <em>is</em> science.  Or to put it another way \"math is the language of science\".  </p>\n\n<p>If we keep pushing this idea that all hard technical questions are off-topic, all we're going to get are vague questions about speculative aspects of AI, with answers that are nothing to speculation and hand-waving.  </p>\n\n<p>What should be on-topic?  Questions about Artificial Intelligence, full-stop. It's right there in the name on the marquee sign, as they say.  </p>\n"}, "1236": {"ParentId": 1197, "Score": 4, "Body": "<p>I think that science without mathematics is usually impossible, science without technology is very difficult (otherwise how to talk about computers for example) but science without programming/implementations is possible.</p>\n\n<p>The emphasis would then be on the concepts and/or abstractions.</p>\n\n<p>So kind of:</p>\n\n<ul>\n<li>pseudocode is okay, real code not</li>\n<li>algorithms are okay, implementations not</li>\n<li>Math is okay as long as the concepts remain abstract.</li>\n</ul>\n\n<p>How to put that into a single line? </p>\n\n<blockquote>\n  <p>Artificial Intelligence Stack Exchange is a site <strong>for people\n  interested in social, conceptual and scientific questions about Advanced\n  Computing</strong>. Join them; it only takes a minute</p>\n</blockquote>\n\n<p>I feel this tries most to keep away from any implementations. But I also feel the limit should only be implementations, not higher level programming, algorithms, maths or statistics.</p>\n"}, "1237": {"ParentId": 1078, "Score": 3, "Body": "<p>A for loop is not the same as gradient decent.  Gradient decent is not the same as NN convergence, or generalization.  You cannot do the latter without the former.</p>\n\n<p>Biology is really Chemistry.  Chemistry is really Physics.  Physics is really math.  If we required doctors to work through the math, then the quantum physics and molecular electronics, then the chemistry before they could do medicine they would die of old age first.</p>\n\n<p>I think that we are trying to separate the fields of computer programming, data science, and such into layers of abstractions.  Each layer has to be thick - to stand on its own and properly envelope its content.</p>\n\n<p>Right now, Machine Learning and Artificial intelligence are \"young\" so there is going to be nuts and bolts.  If we don't give clean bridges there then this area gets to be a philosophical wasteland - no engineering allowed.  If we have some courtesy and we are willing to realize that the divisions are not clean yet, then we can make better mileage toward building a richer community.</p>\n"}, "1239": {"ParentId": 1221, "Score": 3, "Body": "<ol>\n<li><p>The <a href=\"http://area51.stackexchange.com/proposals/93481/artificial-intelligence\">site proposal</a> on the Area51:</p>\n\n<blockquote>\n  <p>\"For conceptual questions about life and challenges in a world where\n  \"cognitive\" functions can be mimicked in purely digital environment.\"</p>\n</blockquote>\n\n<p>This very clearly includes the border to the phylosophy.</p></li>\n<li><p><em>Don't narrow the site topics.</em></p>\n\n<p>It results only a mass of people leaving the site disappointed after the closure of their first questions. With them, we lose not only their content, but also the content they could have made if their first experiences had been better.</p>\n\n<p>There is a so-named \"common sense\", what belongs to AI. It is what an ordinary people, who doesn't even know that a meta site exists, thinks what is AI. In my opinion, <em>the topic of the site shouldn't ever be narrowed significantly below this \"common sense\"</em>.</p></li>\n<li><p>Pragmatical reasons.</p>\n\n<p>Currently we are absolutely not in the position where we could have the luxury to close questions. Later it may be better, but (1) and (2) will stay even then.</p></li>\n</ol>\n\n<hr>\n\n<p>Note, I don't really like philosophical questions. I think the AI is more like on the engineering/science border as philosophical thing. If the site would seem to sink in the mess of endless philosophical debates, I would suggest to make a <em>little</em> limit (for example, to use the VtC as duplicate votes more rigorously), but this is not the case (now).</p>\n"}, "1241": {"ParentId": 1240, "Score": 6, "Body": "<p>I don't think you need 10K on Area 51 to see the data dumps; they seem to work even if you're not signed in. At the top, there's a little banner that says this, with the appropriate link where I have bold:</p>\n\n<blockquote>\n  <p>The AI site didn't have enough activity during the beta, and has been closed. You can download the <strong>data dump of all questions here</strong>.</p>\n</blockquote>\n\n<p>Here are the links to the two previous AI proposals that I know of:</p>\n\n<ul>\n<li><a href=\"http://area51.stackexchange.com/proposals/6607/artificial-intelligence\">The original</a>, the subject of <a href=\"https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/\">this SE blog post</a>. Possibly <a href=\"https://meta.stackexchange.com/questions/279893/include-the-child-metas-of-closed-sites-in-their-data-dump#comment907488_279910\">the first closed SE site</a>, and only the main site's data (not the meta) is available. <strong><a href=\"http://sstatic.net/area51/datadumps/122010%20Artificial%20Intelligence.zip\" rel=\"nofollow noreferrer\">Direct download.</a></strong></li>\n<li><a href=\"http://area51.stackexchange.com/proposals/57719/artificial-intelligence\">The second try</a>. This one has both meta and main in the data dump. <strong><a href=\"http://sstatic.net/area51/datadumps/022014%20Artificial%20Intelligence.zip\" rel=\"nofollow noreferrer\">Direct download.</a></strong></li>\n</ul>\n\n<p>Also, there was a <a href=\"http://area51.stackexchange.com/proposals/41738/machine-learning\">closed Machine Learning proposal</a>, <strong><a href=\"http://sstatic.net/area51/datadumps/082013%20Machine%20Learning.zip\" rel=\"nofollow noreferrer\">direct data dump download here</a></strong>. <a href=\"http://area51.stackexchange.com/proposals/26434/machine-learning\">Another one</a>, slightly older, is indeed missing the data dump, and unfortunately it <a href=\"https://area51.meta.stackexchange.com/q/25354/136466\">probably doesn't exist</a>.</p>\n"}, "1242": {"ParentId": 1078, "Score": 1, "Body": "<p>Practical applications should be on topic here, at least at some extend to keep proportion between philosophy and implementations.</p>\n\n<p>This is important in therms of building community. It is hard to change course later, and if you will this place to be one of fantasy-futurology-imaginary world building site of SE then strike out practical application.</p>\n\n<p>this question could be asked on WB as well <a href=\"https://ai.stackexchange.com/questions/1897/is-consciousness-necessary-for-any-ai-task\">Is consciousness necessary for any AI task?</a> people there are very exited in discussing consciousness.</p>\n\n<p>This question is definitely low quality <a href=\"https://ai.stackexchange.com/questions/1869/deep-neural-network-for-not-so-popular-board-game\">https://ai.stackexchange.com/questions/1869/deep-neural-network-for-not-so-popular-board-game</a> , for obvious reasons, fresh enthusiastic member with practical question - holding it discourages people who where fresh attracted, attracted by super title <em>Artificial Intelligence</em>, not boring <em>Data Science</em> where you do not know what to expect as Science of Data is big field. But there is short and clear AI, yes I wish one, give me two.</p>\n\n<p>At the moment there is no implementations of AI(in movie sense)(known, for me, not a expert)\nFor that reason to keep track on the ground, practical application should be even if this site is intended to be subset of philosophy about AI.\nMaybe change name then to reflect that - based on AI.SE I had expectation to see there useful stuff. From PAI.SE I expect nothing, not interested to know will AI kill humanity or not, how it will change perception of humanity about world, whatever.</p>\n\n<p>At least amateur level implementation should be, at <em>least</em> it is bare minimum what you need.\nProbably even that is not enough and will not work out. You should decide is that philosophy site or is that site about AI, if second then everything about AI(creation, theory, implementation, consequences) should be on topic here - all or nothing, have balls people, it is important for mankind, for our future.</p>\n\n<p>You should discuss more which promises name promises - Artificial Intelligence - and whom it attracts.</p>\n"}, "1244": {"ParentId": 1243, "Score": 1, "Body": "<p>One decent option that already exists is <a href=\"https://ai.stackexchange.com/questions/tagged/human-like\" class=\"post-tag\" title=\"show questions tagged &#39;human-like&#39;\" rel=\"tag\">human-like</a>. It currently only has two questions: one comparing human brains with neural networks, and one about AIs lying to humans. This question is about whether AIs' personalities can be distinguished into categories like those used for humans'. Since personalities are a human-like thing to have*, it would seem to fit in that tag as it's used so far. I suggested an edit that replaced the incorrect tag with this one, and it was approved by the post owner.</p>\n\n<p>In my understanding, that specific question only applies to general AIs (as opposed to something like an image recognizer). Therefore, <a href=\"https://ai.stackexchange.com/questions/tagged/agi\" class=\"post-tag\" title=\"show questions tagged &#39;agi&#39;\" rel=\"tag\">agi</a> could also be relevant.</p>\n\n<p><sup>*Yes, animals can have personalities too. Animals can also <a href=\"https://en.wikipedia.org/wiki/Deception_in_animals\" rel=\"nofollow noreferrer\">deceive</a>.</sup></p>\n"}, "1250": {"ParentId": 1249, "Score": 9, "Body": "<p>More questions certainly would be great, but a low-activity period (the length of which varies from site to site) after the public beta start is normal. For more information, see <a href=\"https://meta.stackexchange.com/q/227007/295684\">What is the typical growth pattern of a new beta site in the first few weeks?</a> </p>\n\n<p>If I perceive correctly, we did get something of an extra boost from \"can a paradox kill an AI?\" being in Hot Network Questions for a few days. It would be great if we could produce more content that's both high-quality and interesting to a lot of people. </p>\n\n<p>So yes, if anyone has additional well-thought-out questions in mind, we would be happy to have them!</p>\n"}, "1251": {"ParentId": 1249, "Score": 1, "Body": "<p>There's definitely been a fall-off, but as others have said, it will take time for people to find the site and become engaged.  I feel like one of the most important thing to do in the meantime is keep asking <em>some</em> quality questions, and/or get additional answers to existing questions, such that first time visitors won't perceive the site as dormant.  From a network science POV, we want a \"preferential attachment\" sort of scenario, where new nodes attach themselves to this node and grow our network.  </p>\n"}, "1253": {"ParentId": 1252, "Score": 3, "Body": "<p>Drawing on these existing discussions:</p>\n\n<ul>\n<li><a href=\"https://ai.meta.stackexchange.com/q/1197/75\">How can we quickly describe our site?</a></li>\n<li><a href=\"https://ai.meta.stackexchange.com/q/1221/75\">Should philosophical questions related to AI be on-topic?</a></li>\n<li><a href=\"https://ai.meta.stackexchange.com/q/1141/75\">A friendly reminder that this site comes from the Science category</a></li>\n<li><a href=\"https://ai.meta.stackexchange.com/q/1123/75\">How this site is different from Cross Validated?</a></li>\n</ul>\n\n<p>Also taking some inspiration from <a href=\"https://superuser.com/help/on-topic\">the Super User \"on topic\" page</a>, here's my first stab at it:</p>\n\n<blockquote>\n  <p>If you have a question about...</p>\n  \n  <ul>\n  <li>social issues in a world where artificial intelligence is common,</li>\n  <li>conceptual aspects of AI, or</li>\n  <li>human factors in AI development</li>\n  </ul>\n  \n  <p>...and it is <em>not</em> about...</p>\n  \n  <ul>\n  <li>the <a href=\"https://ai.meta.stackexchange.com/q/1215/75\">implementation</a> of machine learning, or</li>\n  <li>asking for a development tool or career path recommendation</li>\n  </ul>\n  \n  <p>...then you're in the right place to ask your question!</p>\n</blockquote>\n\n<p>This is only a draft, but it seems like a good starting point. Please suggest improvements if you see anything that needs adjustment! Specifically, I'm not sure how specific we need to be about what constitutes \"implementation\" in this blurb. If there are other commonly asked kinds of off-topic questions, those could be worth mentioning too.</p>\n"}, "1255": {"ParentId": 1254, "Score": 2, "Body": "<p>I don't know if the question you linked is suitably tagged, but I don't think a <code>technology</code> tag will help better categorize content. </p>\n\n<p>\"Technology\" is one of those <em>broad</em> terms that can be applied to many many things. I think  a <code>technology</code> tag would be applied inconsistently at best, and it will <em>likely</em> attract a lot of unrelated questions without adding any clarity to what they are about.</p>\n"}, "1257": {"ParentId": 1256, "Score": 5, "Body": "<p>Congratulations! I am fully confident that our new moderators will be a great team. They have shown themselves to be good users as regular users, and I'm sure that that will carry over to their moderation.</p>\n"}, "1259": {"ParentId": 1258, "Score": 1, "Body": "<p>Such question usually tend to draw a lot of low quality answers which are speculating without giving any backup to their claims. And at the end it's just one person opinion on that topic.</p>\n\n<p>Therefore if the question isn't going to generate any constructive answers, which doesn't have any reliable references or there are no existing research studies in that area (because the topic isn't great or too localized), and question is just asking people to speculate based on their gut instinct, we should vote to close.</p>\n\n<p>Although this particular question about <a href=\"https://ai.stackexchange.com/q/2048/8\">automatic human jobs</a> isn't actually bad, since it's possible to assess such probability based on the available employment data and in <a href=\"http://www.oxfordmartin.ox.ac.uk/downloads/academic/The_Future_of_Employment.pdf\" rel=\"nofollow noreferrer\">2013 Oxford study</a> they managed to estimate it using computer models. So I believe it's actually answerable.</p>\n"}, "1260": {"ParentId": 1258, "Score": 0, "Body": "<p>Some questions about the future will fall squarely under the scope of AI. AI seems to be a sponge that attaches its salience to everything, from depression to eschatology. It's hard for us to say declaratively what parts of life AI will or won't impact.</p>\n\n<p>But I agree that some questions have been inadequately specified. If a given question is so obtuse that we think we will lack sufficient evidence to determine an answer within a decade or two... would some criteria like that be sufficient reason to close the question?</p>\n\n<p>On the other hand, sometimes it may be better to actually explain to a questioner why a particular question is apparently naive, since other people out there may be suffering the same prejudices or misconceptions.</p>\n"}, "1261": {"ParentId": 1258, "Score": 2, "Body": "<p>We already close most of the more concrete questions, with some bullshit verbiage about how they're too \"implementation\" based.  This only leaves room for the science-fiction style questions.  If we start closing the science-fiction questions, there won't be anything left to do.  Might as well close the site.</p>\n\n<p>What we need to do is go back to what I suggested before - close the <strong><em>blatantly</em></strong> off-topic questions (eg, \"How do I rebuild the carburetor on my 1973 Ford Pinto?\") and obvious spam, and rely on the upvote/downvote mechanism for the grey-area stuff, and let the site evolve into what the users want it to become.  The top-down, command-and-control model already isn't working and no amount of doubling-down on that is going to make it a good idea. </p>\n"}, "1262": {"ParentId": 1252, "Score": 5, "Body": "<p>We should drop any reference to implementation specifically being on or off topic.  That's really orthogonal to the issue and it makes it too easy for people to justify arbitrarily closing good questions.  And as this eliminates so many of the more concrete questions, it makes the site appear as though it's only for science-fiction'ish questions.  </p>\n"}, "1264": {"ParentId": 1263, "Score": 4, "Body": "<p>I think that specific question is off topic, and migrated it to Cross Validated. (As I understood it, had two parts--first, does Matlab's learner do bootstrapping, and second, is there a problem with doing bootstrapping twice, neither of which strike me as deeply relevant for AI.)</p>\n\n<p>For machine learning questions, I'm mostly looking at whether the question is 1) well-understood and 2) relevant to the conceptual, social, or philosophical aspects of AI. The closer it is to a statistical issue, the more likely it is to go to Cross Validated, and the closer it is to a data or programming issue, the more likely it is to go to Data Science or Stack Overflow.</p>\n\n<p>I don't think that the question is about Matlab is relevant except that questions that hinge on a particular language are likely to end up as being too close to programming to fit here.</p>\n"}, "1266": {"ParentId": 1265, "Score": 4, "Body": "<p>As mentioned by Rory Alsop, you've run into <a href=\"https://meta.stackexchange.com/q/135178/295684\">this Stack Exchange bug</a> or something related. You can manually fix your profile by <a href=\"https://ai.stackexchange.com/users/edit/current\">editing it on this site</a>, or by opening your profile settings on a different site and choosing <em>Save and copy changes to all Stack Exchange communities</em>.</p>\n"}, "1270": {"ParentId": 1269, "Score": 5, "Body": "<h1>No, no, no.</h1>\n<p>We have a <em>close reason</em> for opinion-based questions. They are explicitly off-topic on Stack Exchange sites.</p>\n<p>When you click on 'Close'<sup>1</sup> (you gain close vote privileges at 500 rep on public Beta sites, 3,000 on graduated sites (1 rep during private beta)), you see something like this:</p>\n<p><a href=\"https://i.stack.imgur.com/FoMWn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/FoMWn.png\" alt=\"vtc\" /></a></p>\n<p>See that 'primarily opinion-based' down there? That's one of the close reasons. (That blue '1' means that someone has already voted to close it for that reason. It takes 5 votes to close it.)</p>\n<hr />\n<p><sup>1</sup>If you don't yet have closing privileges, you can <em>flag</em> it as needing to be closed. Click on 'flag', then click on 'should be closed because...' and you'll see something like this:</p>\n<p><a href=\"https://i.stack.imgur.com/3AkLB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/3AkLB.png\" alt=\"ftc\" /></a></p>\n<p>See '<a href=\"https://ai.stackexchange.com/help/dont-ask\">What should I not ask about here?</a>' in the Help Center.</p>\n"}, "1273": {"ParentId": 1272, "Score": 5, "Body": "<p>Yes, I agree that this is a concerning trend. Though we <a href=\"https://ai.meta.stackexchange.com/q/1252/75\">have an on-topic page</a> that categorizes such questions as off-topic, there is not a direct link to that help center article on the asking form. <a href=\"https://meta.stackexchange.com/q/213935/295684\">Relevant MSE.</a></p>\n\n<p>Though we put together an on-topic page, the <a href=\"https://ai.stackexchange.com/tour\">tour page</a> was neglected. People are encouraged to take the tour when they first sign up; for some, it might be the only topicality-related document they read. Just now, I changed the \"ask\" and \"don't ask\" bulleted lists away from the default generic stuff to something that summarizes our help center guidelines. <strong>Suggestions for improvements are welcome!</strong> Hopefully this change will help our problem; if it doesn't, we can consider more conspicuous help text.</p>\n\n<p>In regard to the examples you brought up (thank you for bringing specifics!):</p>\n\n<ol>\n<li>This question was voluntarily removed by its author after receiving some comments about topicality.</li>\n<li>This seems interesting to me; I think one could argue that it's asking about ways of thinking as opposed to asking for some code.</li>\n<li>This is indeed a question about programming. It is <a href=\"https://ai.stackexchange.com/review/close/1135\">in the Close Votes queue</a> at the moment pending review. As you said, it would be very good to have more people reviewing. There are currently 16 non-moderator users with <a href=\"https://ai.stackexchange.com/help/privileges/close-questions\">the close/reopen vote privilege</a>; I encourage all such users to <a href=\"https://ai.stackexchange.com/review/close/\">have a look at that queue</a>.</li>\n</ol>\n"}, "1274": {"ParentId": 1271, "Score": 2, "Body": "<p>It is December 12 now, and since there have been no objections... hats! Everyone enjoy your hats! The Winter Bash 2016 features will appear on <strong>December 19</strong>.</p>\n"}, "1276": {"ParentId": 1275, "Score": 2, "Body": "<p>This applies site-wide.</p>\n\n<p>If you have asked a question <em>anywhere on the Stack Exchange network</em> in the past 40 minutes, you have to wait before asking a question on <em>any site</em>.</p>\n\n<p>See this answer: <a href=\"https://meta.stackoverflow.com/questions/322157/arent-new-users-throttled-asking-questions-anymore/322265#322265\">https://meta.stackoverflow.com/questions/322157/arent-new-users-throttled-asking-questions-anymore/322265#322265</a></p>\n"}, "1277": {"ParentId": 1275, "Score": 3, "Body": "<p>As mentioned by Mithrandir, this is a network-wide measure that applies to all users with less than 125 reputation. Source: <a href=\"https://meta.stackexchange.com/a/164900/295684\">The Complete Rate-Limiting Guide</a>. It's designed to slow down spammers. Once the 40-minute window elapses, you'll be able to post another question anywhere on the network. I see that you have <a href=\"https://ai.stackexchange.com/q/2471/75\">already done so</a>.</p>\n\n<p>Please note that resource recommendations are off-topic here for two reasons. First, this site is for social and conceptual questions about artificial intelligence. Also (and this applies to most sites on Stack Exchange), collections of off-site resources tend to go out of date very quickly; it takes <a href=\"https://ai.meta.stackexchange.com/q/1267/75\">a community effort</a> to keep such a resource up to date. If the <a href=\"https://ai.stackexchange.com/help/on-topic\">scope of the site</a> is unclear, please bring up your concern here on meta so we can get it clarified.</p>\n"}, "1278": {"ParentId": 1267, "Score": 7, "Body": "<h1>Place something like what <a href=\"https://android.stackexchange.com/tour\">Android</a> has in the tour.</h1>\n<p>Android Enthusiasts has a line in their tour:</p>\n<blockquote>\n<p>Have a programming question? Visit our sister site, <a href=\"https://stackoverflow.com/questions/tagged/artificial-intelligence\">Stack Overflow</a>.</p>\n</blockquote>\n<p>We could put something like that in <em>our</em> tour.</p>\n"}, "1280": {"ParentId": 1279, "Score": 2, "Body": "<p>Good. There has never been any actual consensus that all \"technical\" questions are off-topic.  And at the end of the day, the community decides what is on-topic, not a bunch of ivory-tower navel-gazers here on meta.  Personally I like where we're at with this.  There are some technical questions, yes, but quite often they're <em>different</em> technical questions than the ones you see on stats or datascience or whatever. That tells me we're providing real value to the world, and that makes me happy.</p>\n\n<p>If anything, I say the only action we might need to ramp us, is migrating some questions to other *.se sites, if they are clearly more suited for a different site (say, stats.se or datascience.se). I'm not entirely sure how migration works though.. can anybody nominate a question to be migrated, or what? Does that come in at a certain karma level, or is that something that only the StackExchange employees can do, or what? </p>\n"}, "1281": {"ParentId": 1272, "Score": 1, "Body": "<p>There's nothing concerning about it.  It's just the community speaking in regards to what they want to talk about.  Let's quit trying to fight a rising tide and accept that AI is an inherently technical topic, and enthusiasts are going to want to ask technical questions.  </p>\n"}, "1282": {"ParentId": 1279, "Score": 3, "Body": "<p>I don't think it's not possible to force people to not ask the technical questions. Once it's asked, community decides whether it's on-topic or not. Closing only because it's a technical question isn't enough. More things needs to be taken into the account before deciding.</p>\n\n<p>To be clear, this <a href=\"https://ai.meta.stackexchange.com/q/1141/8\">proposal comes from the Science category</a>, so scientific questions are clearly on-topic (especially <a href=\"https://ai.meta.stackexchange.com/a/1144/8\">socio-scientific angle</a>), but some overlap in scope is expected.</p>\n\n<p>Please note that there are over 10 sites across Stack Exchange network where Artificial Intelligence related questions can be also on-topic (such as <a href=\"https://stats.stackexchange.com/questions/tagged/artificial-intelligence\">Cross Validated</a>, <a href=\"https://datascience.stackexchange.com/questions/tagged/machine-learning\">Data Science</a>, <a href=\"https://cs.stackexchange.com/questions/tagged/artificial-intelligence\">Computer Science</a>, <a href=\"https://cstheory.stackexchange.com/questions/tagged/ai.artificial-intel\">CSTheory</a>, <a href=\"https://cogsci.stackexchange.com/questions/tagged/artificial-intelligence\">Cognitive Sciences</a>, <a href=\"https://philosophy.stackexchange.com/questions/tagged/artificial-intelligence\">Philosophy</a>, <a href=\"https://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligence\">Worldbuilding</a>, <a href=\"https://stackoverflow.com/questions/tagged/artificial-intelligence\">Stack Overflow</a>, <a href=\"https://hsm.stackexchange.com/questions/tagged/artificial-intelligence\">History of Science</a>, <a href=\"https://robotics.stackexchange.com/questions/tagged/artificial-intelligence\">Robotics</a>, <a href=\"https://gamedev.stackexchange.com/questions/tagged/ai\">GameDev</a> and so on), so once the question is asked, it's a matter of speculation where it exactly should belong, unless it's very clear where it belongs. Otherwise claiming the ownership of some question related to AI on other non-AI site which has been asked specifically here or only because it's a technical one, it would be unwise. The point is, that this site is fully dedicated to AI, <em>Cross Validated</em> site has only few tags related to <a href=\"https://stats.stackexchange.com/questions/tagged/artificial-intelligence\">AI</a> and <a href=\"https://stats.stackexchange.com/questions/tagged/machine-learning\">machine learning</a> and it focuses only on statistical techniques where the questions asked there doesn't have to be related to AI.</p>\n\n<p>Therefore if the question is asking about statistical techniques, then sure, it's more on-topic at <a href=\"https://stats.stackexchange.com/\">Cross Validated</a>. Especially if you think it's off-topic here (e.g. nothing to do with AI), and on-topic there, vote to close, so after the closure it can be migrated by the moderators to another site. Similar with question specifically about <a href=\"https://datascience.stackexchange.com/\">data science</a> or <a href=\"https://stackoverflow.com/questions/tagged/artificial-intelligence\">programming</a>.</p>\n\n<p>In summary, the level of technicality is a matter of speculation. For me as far as it doesn't consist math, asking for formulas, technical implementation or modelling, programming code, it's not a technical question. We should rather ask ourselves, whether it's off-topic here (non-AI), and on-topic somewhere else.</p>\n\n<p>Related discussion: <a href=\"https://ai.meta.stackexchange.com/a/1235/8\">What should be on-topic, modelling or implementation, or anything else?</a></p>\n"}, "1284": {"ParentId": 1283, "Score": 4, "Body": "<p>I am also concerned about low-effort speculation questions (especially those that are very broad), and even more concerned when they manage to gather several upvotes. To help stop questions you deem low-quality from proliferating, you can exercise your voting rights: <strong>cast downvotes when appropriate</strong>, and optimally leave a comment to help the author improve. Conversely, <strong>upvote good questions</strong>, the kind you want to see more of. Note that close votes and downvotes are different things with different purposes: a question can be on-topic but poorly expressed or unresearched. If a question is in a useful/interesting topic but doesn't yet adhere to our expectations, <strong>edit it into shape</strong>. Try to preserve the original meaning as much as possible.</p>\n\n<p>Our site is by design a little more subjective than, say, Data Science. That said, we don't allow pure speculation; a question that is <em>primarily</em> opinion-based should be closed as such. A somewhat squishy question that can invite facts instead of personal beliefs and wild speculation would be allowed. If an answer is only speculation with no reasoning or sources provided, please downvote.</p>\n\n<p>\"You get the site you build,\" said some MSE or blog post, if I remember the quote correctly. New users will take the most salient existing content as precedent, so we want our best content to be the highest-voted. If you're feeling particularly generous, you can add a bounty to reward excellent answers. Alas, there's not a way to give a big reward for an awesome question. You can, however, reward authors of good questions by putting effort into <strong>writing an answer to them</strong>. It's tougher to put together something based in fact than to write up a personal opinion, but it's what we collectively need.</p>\n"}, "1286": {"ParentId": 1285, "Score": 5, "Body": "<p>Here's my proposal. I've tried to have this take into account our quality needs and also the good of the answer OP. This is essentially the same as your last idea.</p>\n<ol>\n<li><p>Comment and ask for them to provide sources to back up their claims, or stick that moderator notice on.</p>\n<p>This tells them that there's something wrong with how they're doing their answers, and gives them an opportunity to improve them.</p>\n</li>\n<li><p>If they update with the sources, then great - problem solved. If they refuse, or haven't after a period of time, then delete them - they're not reliable or good answers.</p>\n</li>\n</ol>\n<p>As to what the amount of time that we should give them, I don't know at the moment - people can provide suggestions.</p>\n"}, "1290": {"ParentId": 1289, "Score": 8, "Body": "<p>You are correct; conceptual aspects of AI are on-topic and <a href=\"https://ai.stackexchange.com/q/3329/75\">your question</a> does indeed qualify. I hit Leave Open on it in the review queue, so it should survive. People have somewhat different ideas of what the scope is, and especially what the scope should be, so there will be some spurious scope-related admonishments.</p>\n\n<p>The help center's on-topic page is also subject to revision, and I am always happy to adjust it if it needs clarification. Allow me to expound a bit on the current text:</p>\n\n<ul>\n<li>Social issues: while Worldbuilding does indeed explore hypothetical worlds, this site requires that answers to these questions <a href=\"https://ai.meta.stackexchange.com/q/1285/75\">have basis in reality</a>. Sci-fi writing is not acceptable here.</li>\n<li>Human factors: this line was my attempt to describe questions about humans' role in creating or guiding AIs. It was originally inspired by one interesting question about displaying an AI's configuration/state for human inspection (which I can't find at the moment, sorry). I'll think about how best to express this.</li>\n<li>Conceptual aspects: while non-mathematical concepts are definitely on topic, more concrete implementation issues are already better handled by <a href=\"https://stats.stackexchange.com/\">Cross Validated</a> or <a href=\"http://datascience.stackexchange.com/\">Data Science</a>; diffusing those questions across more Stack Exchange sites would add more confusion and duplication.</li>\n</ul>\n\n<p>One thing that isn't captured currently is the academic/humanities arena, as set forth for us <a href=\"https://area51.meta.stackexchange.com/a/24016/136466\">back when the site was being considered for private beta</a>. Those questions are definitely also on-topic.</p>\n\n<p>I think our current scope is unique and interesting, though you are right: we could use more experts. Specific proposals for policy changes or wordsmithing are welcome!</p>\n"}, "1292": {"ParentId": 1291, "Score": 3, "Body": "<p>If the site description is confusing, you can always propose a new one:</p>\n\n<ul>\n<li><a href=\"https://ai.meta.stackexchange.com/q/1197/8\">How can we quickly describe our site?</a></li>\n</ul>\n\n<p>so it can be voted.</p>\n\n<p>This site comes from the <a href=\"https://ai.meta.stackexchange.com/q/1141/8\">'scientific' category</a>, so both conceptual and scientific question are allowed, exempt the technical questions such as <a href=\"https://ai.meta.stackexchange.com/q/1078/8\">modelling</a> and <a href=\"https://ai.meta.stackexchange.com/q/1081/8\">implementation</a> (e.g. how to do X in the framework Y), where we've dedicated sites for such questions. It's still difficult to draw a line between <a href=\"https://ai.meta.stackexchange.com/q/1279/8\">technical vs non-technical</a> , or <a href=\"https://ai.stackexchange.com/q/1297/8\">modelling vs implementation</a> questions. However if you've any suggestions which can help, please share.</p>\n\n<p>I think <a href=\"https://ai.meta.stackexchange.com/a/1236/8\">this post</a> describes the site in better words:</p>\n\n<blockquote>\n  <p>Artificial Intelligence Stack Exchange is a site for people interested in <strong>social, conceptual and scientific questions</strong> about Advanced Computing.</p>\n</blockquote>\n"}, "1294": {"ParentId": 1293, "Score": 5, "Body": "<p>I take on this responsibility with the assumption I a probably wasn't the first choice, and the awareness that I certainly can't fill NietzscheanAI's shoes.  </p>\n\n<p>That said, I'll do my best to fulfill my duties a <em>pro tem</em> mod <em>(emphasis on pro tem;)</em> taking my lead from the senior mods and our power-user experts, and will try to add value to the forum per my experience on the Humanities side of the AI equation.</p>\n"}, "1295": {"ParentId": 1293, "Score": 2, "Body": "<p>Goodbye, @Niet! I voted for you on the original pro tem nominations, and I was sorry to hear that you were unhappy with what was considered on topic and decided to step down - I hope you decide to still be generally active, even without the diamond.</p>\n\n<p>To @DukeZhou: I've seen you around, here and over on Literature. You weren't active in the private beta, but that's excusable ;). I'm sure that you'll be able to take on your new duties and do them well. Thank you for volunteering for the position!</p>\n"}, "1298": {"ParentId": 1297, "Score": 3, "Body": "<p>This site <a href=\"https://area51.meta.stackexchange.com/a/24016/136466\">was created</a> to be a space for the academic and conceptual and generally not-super-mathy questions that didn't previously have a good home. I think the architecting aspect of \"how do I actually do a real-life thing with AI?\" (as opposed to \"how do I tune this number cruncher?\") is worthy of a space, and that it fits here. Conveniently, there isn't a lot of overlap with older sites. <a href=\"https://stats.stackexchange.com/help/on-topic\">Stats.SE</a> is about statistics (surprise!), and while it looks like the setup of systems to solve problems might on-topic at <a href=\"https://datascience.stackexchange.com/help/on-topic\">Data Science</a>, that site also seems to focus on the lower-level details.</p>\n\n<p>I would agree that \"architecture\" seems to describe this aspect well. Architects don't do the manual work of constructing the building, and they certainly don't mix the concrete, rather they make the higher-level plans so the client winds up with a nice house, which is the goal of the whole process.</p>\n\n<p>So, should we expand the scope to include these questions? Personally, I would vote yes.</p>\n"}, "1300": {"ParentId": 1299, "Score": 1, "Body": "<p>I definitely understand the concerns about the overlap between CrossValidated, Data Science, and this site. What we need to do, to help the site get more traction, is to define that boundary in a useful way. At a high level, it wouldn't make sense to reject a site about statistics because a perfectly good mathematics site already existed. Statistics has different goals, conventions, notation, and concerns--even though it's almost all mathematics.</p>\n\n<p>I'd argue that the failures of the previous sites were more a question of timing than content. Serious interest in AI is on the horizon again, very recently, precisely because of advances in ML. That doesn't mean, however, that AI proper is the same thing as ML, or needs to be focused on implementation issues. There's a large amount of theory that isn't necessarily data science, either.</p>\n\n<p>We went through some of the same growing pains on Signal Processing. The approach we took there (and I'm not saying it's the right approach for AI), was to concentrate mostly on theory, and avoid implementation details. It's something that didn't exist, and it gave us a way to attract experts who weren't programmers.</p>\n\n<p>Explicitly making the history of AI on-topic, however technical, might be a good starting point to help clarify what a site dedicated to AI can add to the SE network. I'm not saying that it's necessarily off-topic now, but given that MathJax isn't even enabled yet, there's currently a strong bias toward strictly non-technical questions.</p>\n\n<p>I think the <a href=\"https://en.wikipedia.org/wiki/AIXI\" rel=\"nofollow noreferrer\">AIXI agent</a> is a good example to begin discussing these issues. It's heavily mathematical, based on reinforcement learning, inspired by statistical reasoning (ala. <a href=\"https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference\" rel=\"nofollow noreferrer\">Solomonoff's Universal Prior</a>), and uses non-computable concepts (i.e. <a href=\"https://en.wikipedia.org/wiki/Kolmogorov_complexity\" rel=\"nofollow noreferrer\">Kolomogorov Complexity</a>). So, there's a potential overlap with any number of fields, but really it's proper <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\" rel=\"nofollow noreferrer\">AGI</a>. It's a much more practical definition of intelligence than, say, the Turing Test--precisely because it's defined mathematically. At the very least, it seems like definitions of intelligence should be on-topic, and we need math for those.</p>\n\n<p>It might warrant a completely separate meta question, but I'll offer one thought on how to help clarify the scope of the site (in addition to including AI history). Let's start with <a href=\"https://en.wikipedia.org/wiki/Peter_Norvig\" rel=\"nofollow noreferrer\">Peter Norvig's</a> definition of AI (from <a href=\"https://ai.meta.stackexchange.com/users/4/franck-dernoncourt\">Frank Dernoncort's</a> <a href=\"http://www.francky.me/doc/20120530%20-%20AI%20and%20Business%20-%20CCSF%20Paris.pdf\" rel=\"nofollow noreferrer\">slides</a>):</p>\n\n<blockquote>\n  <p>We think of AI as understanding the world and deciding how to  make \n  good  decisions. Dealing with uncertainty  but  still  being  able  to\n  make  good  decisions  is  what  separates  AI  from  the  rest  of \n  computer science.</p>\n</blockquote>\n\n<p>Any discussion of decision making under uncertainty will almost necessarily involve probability and statistics. However, the challenges involved in <em>automating</em> those decisions effectively, in my opinion, are the domain of Artificial Intelligence, whether general or specialized. That definition also includes all of the potential social issues.</p>\n"}, "1301": {"ParentId": 1299, "Score": 3, "Body": "<p>I was under the impression that history and theory were already on-topic. Social issues is one new topic we bring to the SE table, but academic questions (about AI as a discipline/science) are also ours to present. Key quote from a community manager <a href=\"https://area51.meta.stackexchange.com/a/24016/136466\">in the Area 51 Discussion Zone</a>, emphasis original:</p>\n\n<blockquote>\n  <p>Notice that this proposal is in the 'Science' category; <em>not</em> 'Technology'. Despite the creation of a Data Science site to cover this topic, the community made a sufficiently compelling case that there is a swath of <strong>questions in the academic humanities arena</strong> that are not covered by our current sites.</p>\n</blockquote>\n\n<p>I realize now that when <a href=\"https://ai.meta.stackexchange.com/q/1252/75\">drafting</a> the <a href=\"https://ai.stackexchange.com/help/on-topic\">on-topic page</a> I forgot to include a bullet point to cover these questions. I apologize for the oversight and have corrected it. As always, suggestions for improvement to that page's contents are welcome!</p>\n"}, "1304": {"ParentId": 1302, "Score": 1, "Body": "<p>Done - a <a href=\"https://ai.stackexchange.com/tags/synonyms\">tag synonym</a> has been created and <a href=\"https://ai.stackexchange.com/questions/tagged/conv-neural-network\" class=\"post-tag\" title=\"show questions tagged &#39;conv-neural-network&#39;\" rel=\"tag\">conv-neural-network</a> has been merged into <a href=\"https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks\" class=\"post-tag\" title=\"show questions tagged &#39;convolutional-neural-networks&#39;\" rel=\"tag\">convolutional-neural-networks</a>, thereby updating all existing questions. This has the added benefit of making the tag name consistent with all the other pluralized ones.</p>\n"}, "1305": {"ParentId": 1296, "Score": 4, "Body": "<blockquote>\n  <p>I made the point that the question seems to fit into the \"conceptual aspects of AI\" covered by this stack, but T.C. countered that Machine Learning questions, in particular, are already quite fractured across several sites.</p>\n</blockquote>\n\n<p>I believe most ML questions are on CV. Then DS got created, which has a huge overlap with CV, and a more trendy name. So one way to avoid fracture is not creating new Stacks with huge overlaps (<a href=\"https://ai.meta.stackexchange.com/q/4/4\">Are all questions asked on stats and data science SE also on topic here?</a>).</p>\n\n<blockquote>\n  <p>How can we reconcile this so that the related Stacks support and add value to each other?</p>\n</blockquote>\n\n<p><a href=\"https://meta.stackexchange.com/q/199989/178179\">Build and strengthen the Stack Exchange community with \"crossover questions\" between sites</a></p>\n\n<blockquote>\n  <p>Part of my inclination may derive from having been in an interdisciplinary studies program as an undergraduate. In that program, we did not learn Science independently of History, Philosophy, Psychology, Art and Literature. Rather, these subjects were taught in tandem.</p>\n</blockquote>\n\n<p>In practice, the development of AI models doesn't care much about History, Philosophy, Art and Literature. Most AI experts focus on the models, which tend to be statistical, therefore on-topic on CV. </p>\n"}, "1308": {"ParentId": 1307, "Score": 4, "Body": "<h1>Yes.</h1>\n<p>They both mean the same thing, so we should have only one tag. They should be synonymized, because if you type <code>cnn</code> the tag <a href=\"https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks\" class=\"post-tag\" title=\"show questions tagged &#39;convolutional-neural-networks&#39;\" rel=\"tag\">convolutional-neural-networks</a> does not come up as a suggestion, and vice versa.</p>\n"}, "1310": {"ParentId": 1307, "Score": 4, "Body": "<p>Yes, tags with the same meaning should indeed be synonyms. The requested synonym is now in place; <a href=\"https://ai.stackexchange.com/questions/tagged/cnn\" class=\"post-tag\" title=\"show questions tagged &#39;cnn&#39;\" rel=\"tag\">cnn</a> was also merged into <a href=\"https://ai.stackexchange.com/questions/tagged/convolutional-neural-networks\" class=\"post-tag\" title=\"show questions tagged &#39;convolutional-neural-networks&#39;\" rel=\"tag\">convolutional-neural-networks</a> to update the eight existing <a href=\"https://ai.stackexchange.com/questions/tagged/cnn\" class=\"post-tag\" title=\"show questions tagged &#39;cnn&#39;\" rel=\"tag\">cnn</a> questions and deduplicate the tags on the two questions that had both tags.</p>\n"}, "1314": {"ParentId": 1313, "Score": 9, "Body": "<p>It is indeed a shame when a user comes in, asks a decent question, and gets silently downvoted. Even though the downvote mechanism itself isn't hostile - we vote on content, not people - people will feel frustrated when their posts receive negative feedback for reasons unclear. At the same time, downvotes are critical to quality control and we cannot control users' voting behavior (except in abusive situations like targeted voting).</p>\n\n<p>Fortunately, even though we might not get an explanation from downvoters themselves, we can help new users understand what's going on. The <a href=\"https://ai.stackexchange.com/review/first-posts\">First Posts</a> review queue gives you the chance to provide users' first experience on our site. You can also monitor <a href=\"https://ai.stackexchange.com/search?tab=newest&amp;q=score%3a..-1%20closed%3a0\">a list of new downvoted questions</a> to check that the downvotes are justified and take all appropriate actions. Specifically, it's very helpful to edit and comment with a welcome and an explanation of how your adjustment will help their post's reception.</p>\n\n<p>Side note for what it's worth: the Area 51 statistics are no longer as critical as their central position advertises them. The Area 51 system <a href=\"https://meta.stackexchange.com/a/263506/295684\">is pretty old and pending a reworking</a>, even though it still gets the job done. The comments on <a href=\"https://meta.stackexchange.com/a/257720/295684\">this MSE answer</a> are relevant, especially <a href=\"https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites/257639#comment840478_257720\">this one</a> (excerpt: \"The A51 metrics are spectacularly ill-suited for giving an accurate picture of a site's overall health\") and <a href=\"https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites/257639#comment841019_257720\">this other one</a>. It would still be nice to have higher stats, though.</p>\n\n<p>In summary, quality control and welcomingness needn't be mutually exclusive. If we guide users and help adjust their posts, we can be inviting and high-quality at the same time!</p>\n"}, "1315": {"ParentId": 1313, "Score": 1, "Body": "<p>This could easily be solved by requiring a comment for downvotes on new stacks or on new user questions.</p>\n"}, "1316": {"ParentId": 1309, "Score": 2, "Body": "<p>I agree with making this change.  As far as can tell, to a first approximation, nobody uses the term \"ultra-intelligence\".  \"Super intelligence\" or \"Artificial super intelligence\" are the terms I see.</p>\n"}, "1318": {"ParentId": 1317, "Score": 2, "Body": "<p>Sites like SuperUser.SE and Physics.SE deal with this by having a set of \u201ccanonical\u201d questions. These are usually specific questions/answers that are very specific but very well explained. </p>\n\n<p>I imagine that approach could very well apply here too, and the SE system already provides support for it. </p>\n\n<p><strong>Update</strong></p>\n\n<p>I think this link provides a lot more information. <a href=\"https://meta.stackoverflow.com/q/291992/147507\">https://meta.stackoverflow.com/q/291992/147507</a></p>\n\n<p>To sum it up: there's currently thing \"special\" about the canonical questions and answers, aside from being asked and answered very thoroughly, and sometimes with varying levels of detail, so that it handles most users questions.</p>\n\n<p>Into how they are suggested to users: they go through the same process as every other question, by appearing on the sidebar or searches. (See notes <a href=\"https://meta.stackexchange.com/a/112438/335458\">here</a>). If the question is properly redacted and the answers are detailed enough, it should pop up among suggested answers, and users should find it relevant to their search/question.</p>\n\n<p>How to generate them? As simple as it sounds: once identified, start a new question, write the hell out of it, which will get it upvoted, and let it sit around. Maybe save the link if we're thinking in closing questions as duplicates to it.</p>\n"}, "1319": {"ParentId": 35, "Score": 14, "Body": "<p>Here are several questions and answers that would benefit from MathJax support on this website. These are just a few examples I've found in a 5 minutes search. Nevertheless, I think this number is enough to justify a MathJax support on this website.</p>\n<h3>Questions</h3>\n<ul>\n<li><p><s>https://ai.stackexchange.com/a/4710/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/2994/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/4085/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/3758/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/4740/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/4296/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/4140/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/2226/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/2865/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/3458/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/113/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/5580/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/13577/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/5075/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/8240/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/3226/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/5527/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/6009/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/5825/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/9226/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/5638/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/5606/2444</s></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/5332/2444\">How to implement exploration function and learning rate in Q Learning</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/6366/2444\">Genetic Algorithm - creatures in 2d world are not learning</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/20053/2444\">How to perform back propagation with different sized layers?</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/2462/2444\">How to determine the probability of an &quot;existence&quot; question</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/2863/2444\">How do I translate these English sentences into first-order logic without quantifiers?</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/3040/2444\">GA rule discovery fitness function</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/6789/2444\">Is random initialization of the weights the only choice to break the symmetry?</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/6990/2444\">Matrix Dimension for Linear regression coefficients</a></p>\n</li>\n</ul>\n<h3>Answers</h3>\n<ul>\n<li><p><s>https://ai.stackexchange.com/a/1927/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/4227/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/2292/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/4185/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/4388/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/3906/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/267/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/3162/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/6280/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/5620/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/5079/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/2300/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/4479/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/5597/2444</s> (post deleted)</p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/6983/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/13216/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/3507/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/13681/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/27411/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/5334/2444</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/a/6172/2444</s> (post deleted)</p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/22731/2444\">https://ai.stackexchange.com/a/22731/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/17651/2444\">https://ai.stackexchange.com/a/17651/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/6323/2444\">https://ai.stackexchange.com/a/6323/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/6628/2444\">https://ai.stackexchange.com/a/6628/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/5607/2444\">https://ai.stackexchange.com/a/5607/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/20899/2444\">https://ai.stackexchange.com/a/20899/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/3510/2444\">https://ai.stackexchange.com/a/3510/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/2546/2444\">https://ai.stackexchange.com/a/2546/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/6017/2444\">https://ai.stackexchange.com/a/6017/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/6093/2444\">https://ai.stackexchange.com/a/6093/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/16127/2444\">https://ai.stackexchange.com/a/16127/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/6999/2444\">https://ai.stackexchange.com/a/6999/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/6991/2444\">https://ai.stackexchange.com/a/6991/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/9993/2444\">https://ai.stackexchange.com/a/9993/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/6794/2444\">https://ai.stackexchange.com/a/6794/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/10995/2444\">https://ai.stackexchange.com/a/10995/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/6639/2444\">https://ai.stackexchange.com/a/6639/2444</a></p>\n</li>\n</ul>\n"}, "1321": {"ParentId": 1320, "Score": 2, "Body": "<p>Though we get a lot of (off-topic) questions about data manipulation and implementation issues in general, this site was created to serve questions that aren't so quantitative. For some more info on our scope, see the <a href=\"https://ai.stackexchange.com/help/on-topic\">help center</a>. Admittedly, we are currently doing an incomplete job of making the scope clear to new users and handling off-topic questions. Nevertheless, it is clear from <a href=\"https://area51.meta.stackexchange.com/a/24016/136466\">this Area 51 Discussion Zone post</a> by a Stack Exchange community manager that this site is for AI as a science, not as a technology to be implemented:</p>\n\n<blockquote>\n  <p>Notice that this proposal is in the 'Science' category; <em>not</em> 'Technology'.  Despite the creation of a Data Science site to cover this topic, the community made a sufficiently compelling case that there is a swath of <strong>questions in the academic humanities arena</strong> that are <em>not</em> covered by our current sites.</p>\n</blockquote>\n\n<p>Social, conceptual, and philosophical aspects of AI are on-topic here, but not on Data Science, which is a more technical site. There is some overlap in architectural questions, but there is much precedent for sites' topics not being fully disjoint &mdash; Stack Overflow and Super User on PowerShell questions, for example. Combining our slightly subjective questions with Data Science's technicality would be mixing two different types of questions (and two different communities).</p>\n\n<p>In short, this site and Data Science are looking at different aspects of artificial intelligence. Both sites are valuable, each with its own knowledgeable people, and it would be good to preserve the distinction.</p>\n\n<p>Relevant MSE: <a href=\"https://meta.stackexchange.com/q/68214/295684\">Can Stack Exchange follow a more generic approach?</a></p>\n"}, "1322": {"ParentId": 35, "Score": 5, "Body": "<p>I, for one, would love its inclusion. I do not believe it is possible to divorce AI from mathematics on many levels. For instance, I wanted to ask a question regarding the use of backpropagation with regards to the ANFIS model but had to do so in a clumsy way as I was not able to include the proper notation for partial derivatives. It would surprise me to think that this site is just for \"high level\" philosophical discussions on AI.</p>\n"}, "1324": {"ParentId": 1320, "Score": -1, "Body": "<p>My first opinion has been \"nooo!\". However, skipping points as if this site must include applied AI or only strong AI, what is AI and what is data processing, ... my opinion is now \"yes, just find a good name for the combined site\". </p>\n\n<p>The reason: this site has a low volume of questions and answers (if all off-topic was directly closed, activity will be epsilon), low number views per day, and,  sorry to say that, low quality of questions and answers. Join two sites will increase the activity and the number of experts, improving all these aspects.</p>\n\n<p>A good usage of tags in the new site will solve all practical aspects.</p>\n"}, "1325": {"ParentId": 1320, "Score": 0, "Body": "<p>Hellz No!  Where would people ask philosophical questions related to AI, or discuss theoretical topics?  What about the Mythology of AI?  (Off-topic at Stack:Mythology, but is the predominant influence re the public's perception of AI.)</p>\n\n<p><strong>Morality of AI applications is a critical issue, only increasing, as are social impacts of AI.  This Stack is the forum to discuss them.</strong></p>\n\n<p><strong>This is also the Stack for Game Theory as it relates to AI, and combinatorial games, which are inextricably related to AI, in that they are still used for AI proving.</strong></p>\n\n<p>I'd propose, as the Cross Validated community has, that Data Science should probably be rolled into that Stack, and CV should probably adopt the name \"Data Science\" so people know where to go for those questions.  (i.e. \"CV\" is cool, but it's insider-ey, and noobs don't know that's the place to ask Data Science questions related to AI, and come to SE:AI.)</p>\n\n<p>Do I don't think the problem is with the AI Stack at all.  The humanities size of the equation, which is the core of this stack, should not be handled on a Data Science forum.</p>\n\n<p>I think the solution would be to revise our \"Community Guidelines\" to be very clear about which questions should go to CV/DS, reposting their guidelines as a sub-section to AI's guidelines, and try to get some involvement from the CV/DS forums on which questions to migrate, so we don't accidentally migrate questions they don't want. </p>\n"}, "1327": {"ParentId": 1326, "Score": 4, "Body": "<h1>No.</h1>\n<p>If a question is on topic, then it should stay here. Migrating is for <em>high-quality, but off topic</em> questions. This is why migrating a question involves closing as &quot;off-topic&quot;. In this case, they're <em>not</em> off topic - they just haven't gotten an answer.</p>\n<p>Now, <em>why</em> don't they have an answer? Probably because there's nobody on the site who knows how to answer it... or the right person just hasn't seen it. If nobody on the site knows how to answer a question, then the best thing to do would be to <strong>attract users who <em>do</em> know how to answer the questions</strong>, namely, &quot;experts&quot;.</p>\n<p>How do these &quot;experts&quot; find the site, though? Usually through <em>content already on the site</em> - it'll come up in a Google search or something. So to attract the experts, you need content, and if you send all the content away, then AI.SE won't get new users and the site will stagnate.</p>\n<p>There's nothing wrong with having some unanswered questions around, as long as not <em>all</em> questions are unanswered. And if that happens, the site's got a big problem.</p>\n<p>See also <a href=\"https://meta.stackexchange.com/a/212271/294691\">Meta.SE guidance on migrations</a>.</p>\n"}, "1330": {"ParentId": 1303, "Score": 1, "Body": "<p>This is done now, sorry for the delay.</p>\n\n<p>We still have <a href=\"https://ai.stackexchange.com/questions/tagged/natural-language\" class=\"post-tag\" title=\"show questions tagged &#39;natural-language&#39;\" rel=\"tag\">natural-language</a> and <a href=\"https://ai.stackexchange.com/questions/tagged/language-processing\" class=\"post-tag\" title=\"show questions tagged &#39;language-processing&#39;\" rel=\"tag\">language-processing</a>, which sound pretty similar to <a href=\"https://ai.stackexchange.com/questions/tagged/natural-language-processing\" class=\"post-tag\" title=\"show questions tagged &#39;natural-language-processing&#39;\" rel=\"tag\">natural-language-processing</a> &mdash; it might be worth revisiting <a href=\"https://ai.meta.stackexchange.com/q/1182/75\">this NLP tag discussion</a>.</p>\n"}, "1331": {"ParentId": 1329, "Score": 1, "Body": "<p>Simple:</p>\n\n<p>Ask more questions on the biological side of AI</p>\n\n<p>That is pretty much it. </p>\n"}, "1333": {"ParentId": 1332, "Score": 0, "Body": "<p>Re: The 3 NLP tags</p>\n\n<p>This has been on my radar for a little while.  I've just briefly re-reviewed the questions for these three tags and see no reason not to merge.</p>\n\n<p><strong>If anyone has any reason these tags should not be merged, speak now or forever hold your peace</strong></p>\n\n<hr>\n\n<p>Re: \"spanish-language\" tag</p>\n\n<p>This is one I decided to test out, related to a question asking for both English and Spanish language resources.  Spanish is the #2 language in the US, so it might be worthwhile to see if this tag gets any additional use.  (If not, we can always delete.)</p>\n\n<hr>\n\n<p>Re: \"time\" tag</p>\n\n<p>I've replaced the \"time\" tag with a new \"time-complexity\" tag on this question: <a href=\"https://ai.stackexchange.com/questions/2874/neural-networks-efficiently-solve-traveling-salesmen-problems\">Neural networks efficiently solve traveling salesmen problems?</a></p>\n\n<p><a href=\"https://ai.stackexchange.com/q/184/1671\">This question</a>, however, seems to be about automata learning the concept of time.  Based on a linked research paper, I've tentatively updated the \"time\" tag to refer to perceptual time.</p>\n"}, "1336": {"ParentId": 1335, "Score": 1, "Body": "<p>This site is currently in beta. Beta sites do not normally have custom design elements. </p>\n\n<p>Furthermore, <a href=\"https://meta.stackexchange.com/questions/307862/ch-ch-ch-changes-left-nav-responsive-design-themes\">Stack Exchange are ch-ch-ch-changing</a> their approach to site design, and as a part of that, badges will be standardized: one badge design to rule them all. </p>\n\n<blockquote>\n  <p>Standardized items will include:</p>\n  \n  <ul>\n  <li>Navigation  </li>\n  <li>Fonts  </li>\n  <li>Buttons/Icons  </li>\n  <li>Badges  </li>\n  <li>Tags  </li>\n  <li>Newsletter ads  </li>\n  </ul>\n</blockquote>\n"}, "1337": {"ParentId": 1329, "Score": 1, "Body": "<p>I guess this is my field. I'm researching the evolutionary development of human intelligence from non-intelligent roundworms. This is one part within the broader research on developing a general theory of intelligence and duplicating it non-biologically. This work seems to be unusual here since everyone else I've come across seems to assume that human reasoning is definable within Church-Turing.</p>\n\n<p>I can't provide a lot of technical detail because it is unpublished and because it would take entire chapters to explain, but I can give general answers about what I know.</p>\n"}, "1338": {"ParentId": 1285, "Score": 0, "Body": "<p>I have some information that is not publically available based on research that I've been doing for the past several years. I can't cite it since it isn't published. Yet it is considerably more advanced and in agreement with observed evidence than theories that usually get mentioned like Integrated Information Theory or Global Workspace (both of which can be disproved). It won't be published until it is completed and no earlier than 2021. So, I can either withhold what I know (which would be quite odd considering that proton decay was talked about for years before it was disproved), or I can answer without citations.</p>\n"}, "1342": {"ParentId": 1341, "Score": 2, "Body": "<p>That sounds good to me. </p>\n\n<p>A couple things to keep in mind: Especially when submitting suggested edits, please make sure to fix <em>all</em> problems with the post &mdash; this saves reviewer time and minimizes bumps. I'm not entirely certain what you mean by \"moving links to inline when they only appear once,\" but if you're referring to the Markdown inline link style (as opposed to footnote style), please submit only edits that make improvements to the rendered post. Cleaning up the Markdown in the process of making helpful visual changes is good, though. Starting from the oldest posts and proceeding to the newest is a good idea because it keeps newer content nearer the top of the front page.</p>\n\n<p>Thanks for helping improve AI.SE!</p>\n"}, "1343": {"ParentId": 1340, "Score": 0, "Body": "<p>I am thinking this could be in part of the variety of computers we could be on, the variety of the computing powers of said computers, and the variety of computation power required for various types of Neural Nets and such.</p>\n\n<p>Say a specific piece of code works just fine on your Chromebook. This piece of code would also work just fine on any other device that can do parallel computations. This piece of code may still work on a RaspPi 3, but take 15-times longer to set up, train, test, etc.</p>\n\n<p>What gets even worse is when the Library you use only supports a specific set of OS. You don't know what anyone seeing your question/answer uses. </p>\n\n<p>So the main issue is the variety of computers out today, the variety of computation power supplied by those computers, and the variety of computation power required by various implementations of AI.</p>\n\n<p>Therefore, not much can be done but test a piece of code on every device possible, and <em>then and only</em> then post the code. This becomes an issue when newcomers do not know about this. They may post a piece of code that works just fine on their computer, but results in disaster on others.</p>\n"}, "1344": {"ParentId": 1328, "Score": 3, "Body": "<p>When AI.SE was about to be created, there was a divide. A few wanted ML and implementation details to be part of the site; most wanted to exclude them. The final agreement was to exclude---so the current topic list excluding explicitly implementation details and so on.</p>\n\n<p>The reasoning back then was that popular frameworks like Tensorflow, etc. were explicitly asking to question on SO. Questions about Data Science were perceived as much better fits for Cross Validated, etc. So no need to duplicate them here, and take the risk of killing AI.SE before it gets momentum. That was an interesting thinking, and I think the result is okay.</p>\n\n<p>Now it seems that many AI.SE questions are about ANN, including popular subcategories like CNN, DNN, RNN, etc. The community here seems to expect xNN Q&amp;A, so the description and topic list do seem like a mismatch---I concur (and that is how I found your question, searching for such a discussion). Another way to put it: How can we \"make a mind\u2122\" without talking about techniques and tools we have at present?</p>\n\n<p>IMHO it may be time to update description and topic list, to define <em>a posteriori</em> the scope of AI.SE.</p>\n\n<hr>\n\n<p>Note:</p>\n\n<ul>\n<li>The current description does include AGI, though. Terminology is quite vague, but an AGI could be a \"set\" of \"cognitive functions [...] mimicked in purely digital environment.\" As for theory, models, notions, concepts, the current scope has been carefuly thought through, IMO.</li>\n<li>Let's keep in mind that AI.SE is the 3rd attempt to create an AI-related SE site, and the most successfull so far (the previous attempts topped at 6 months before closing). This AI.SE is on something (and the current \"market\" makes it easier with the DL wave).</li>\n</ul>\n\n<hr>\n\n<p>Disclaimer: I was part of the first group, so I am biased in my agreement. However the sheer volume of xNN questions might be a data-backed confirmation the site needs an update (I did not go beyond lazily listing and eye-balling unanswered questions).</p>\n"}, "1346": {"ParentId": 1345, "Score": 3, "Body": "<p>Edits don't cause things to head to the close vote queue. Edits on a closed question will sometimes push a question into the <em>reopen</em> queue, but never the close vote queue.</p>\n\n<p>So for some reason, someone must have gone through and manually cast close votes/flags, pushing it into the queue.</p>\n\n<p>Votes shouldn't affect the action you take on the post - if it was highly voted but then determined to be off topic, close it. If it's not close-worthy, leave it open. Each question should be judged on its own - if the standing policy on a specific type of question is that it should be closed, review it and pick the appropriate close reason. If you don't, pick Leave Open.</p>\n\n<p>Unless someone is flooding the Close Votes queue with a mass of on topic questions, I don't think that any moderator action is necessary. There's nothing wrong with going through old questions that should be closed (although some would consider it a waste of time).</p>\n"}, "1347": {"ParentId": 1326, "Score": 1, "Body": "<p><a href=\"https://meta.stackexchange.com/q/151890/295684\">Questions older than 60 days cannot be migrated</a>, even by moderators. I don't think we can expect questions to always be answered in two months &mdash; from my experience on Super User, it's not at all unusual for months to pass before the right expert stumbles upon the question and solves it. We therefore have a bit of a catch-22 here. Even if we could ship out old unanswered questions, that's probably less than ideal for site growth; see <a href=\"https://ai.meta.stackexchange.com/a/1327/75\">Mithrandir's answer</a> for more on that.</p>\n"}, "1348": {"ParentId": 1345, "Score": 1, "Body": "<p>There is definitely an uncommon surge in close votes in the queue at present.  (Typically we see serial downvoting, but no so many close vote.)</p>\n\n<p>It's useful information, in the sense of getting user opinions re: what's in scope, but we tend not to actually close unless the question is egregiously off-topic, unsuitable, or unsalvagable.</p>\n\n<p>It's possible it is due to all the edits, bringing buried questions to light...</p>\n"}, "1350": {"ParentId": 1349, "Score": 3, "Body": "<p>I think I have found a solution to this. </p>\n\n<p>Until I attain edit privileges, I am only going to do a few posts a week - Making sure that everything on them is as it should be (Taking critical issues into consideration first). As much as this is going to slow the progress down, the quality will go up greatly. As a plus, I will have more practice and a lot more time for feedback per capita per post.</p>\n\n<p>I hope the majority of you stand with me, but regardless, I am going to do this. Please note, I have not drawn into the shell of seclusion, but merely been scolded and found a corner for myself to sit in for a while.</p>\n\n<h3>TL;DR</h3>\n\n<p>I am going to be cutting back on the number of time per post and increasing the time spent on each post. In other words, keeping the impact down.</p>\n"}, "1351": {"ParentId": 1349, "Score": 2, "Body": "<p>For years, users have asked Stack Exchange to add an option not to bump a question/answer when it gets edited. Until this gets implemented, there will be some awkward balance between keeping imperfect content that could be edited and not burying new questions.</p>\n"}, "1353": {"ParentId": 1352, "Score": 1, "Body": "<p>I worry about the confusion between StackExchange AI and Stackoverflow. But as the code refers to Artificial Intelligence and these languages are becoming the tool of Data Scientists, I believe it is quite valid.</p>\n"}, "1355": {"ParentId": 1354, "Score": 5, "Body": "<p>This is a known issue with all Stack Exchange sites currently: <a href=\"https://meta.stackexchange.com/questions/308966/traffic-views-visits-isnt-correctly-registered-on-site-analytics-or-area-51\">Traffic (views, visits) isn&#39;t correctly registered on Site Analytics or Area 51</a>. SE employees are aware of it, but apparently it takes some time to fix the analytics.</p>\n"}, "1357": {"ParentId": 1356, "Score": 3, "Body": "<p>This site is about Artificial Intelligence (AI) which generalizes Machine Learning and Deep Learning:</p>\n\n<p><a href=\"https://i.stack.imgur.com/1scCQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1scCQ.png\" alt=\"enter image description here\"></a></p>\n\n<p>Hence, I think, the site should embrace and be the home questions about any of those. Both practical and theoretical, science and engineering.<br>\nIn order to do so and bring this great audience we should:</p>\n\n<ol>\n<li>Change the name of the community into <strong>Artificial Intelligence and Machine Learning</strong>.</li>\n<li>Write explicitly in the site description that it deals with those subjects and welcome questions about them.</li>\n</ol>\n\n<p>Doing so, I believe, will fill the void in the SE communities which doesn't dedicate any community to gather people which are experts on those.</p>\n\n<p><strong>Remark</strong><br>\nImage taken from the book <a href=\"https://rads.stackoverflow.com/amzn/click/1617294438\" rel=\"nofollow noreferrer\">Francois Chollet - Deep Learning with Python</a>.</p>\n"}, "1358": {"ParentId": 1313, "Score": 1, "Body": "<p>Well, I just got downvoted because I tried to make sense of a question that was somewhat unclear. And the person doing it left a comment saying that an answer to a bad question was still a wrong answer. This is exactly the kind of attitude that makes people leave this site.</p>\n\n<p>There are a lot of questions from people who haven't got a clue about AI, and often express themselves not very clearly, as English is obviously not their first language. I am really taken aback by how unfriendly the community on here is, as most of these questions immediately get downvoted.</p>\n\n<p>I don't know what the solution is, as even requiring a comment is not really solving this issue.</p>\n"}, "1360": {"ParentId": 1359, "Score": 4, "Body": "<p>This is a good idea. We'll need to wait, though, until our site graduates &mdash; a site generally <a href=\"https://meta.stackexchange.com/a/178463/295684\">doesn't become available</a> as a migration source (except to its own meta) or target until the beta label is removed.</p>\n\n<p>Moderators can migrate questions to any site, but I would guess that most off-topic questions are not suitable for migration because they don't yet meet the standards of the most relevant site. Such questions should instead be closed here with a helpful comment about the other site and a suggestion to review that site's guidance before posting.</p>\n"}, "1361": {"ParentId": 1356, "Score": 3, "Body": "<p>Similar questions come back on Meta, but no convergence.</p>\n\n<p>I am a proponent of technical questions since before the exchange creation. The hairy issue is to clearly define the boundary.</p>\n\n<p>Any kind of technical question will lead to an overflow of simple programming questions on how to do something with Tensorflow or Pytorch. Such questions are (in my opinion) better answered on StackOverflow. These frameworks are still complex enough so as many questions are really about syntax and framework-specific understanding (e.g. I concieve it is hard to use TensorFlow if you have never used graphs or data flows).</p>\n\n<p>Technical questions like \"how many layers to do something?\", \"what architecture is best for mushroom recognition?\", or \"why SVM here and ANN there?\" seem fine to me.</p>\n\n<p>All in all, I expect the community manages to still attract questions about consciousness, AGI, ethics, etc. A tsunami of small technical questions is good for traffic, but causes a low signal/noise ratio.</p>\n"}, "1362": {"ParentId": 1356, "Score": 0, "Body": "<p>The Data Science site already covers such topics. It is in my opinion that the Artificial Intelligence site and the Data Science site should be merged where the scope would include</p>\n\n<ul>\n<li>The humanities of artificial intelligence (ethics, morality, etc.)</li>\n<li>The humanities of data collection and privacy (ethics, morality, etc.)</li>\n<li>The discussion of state-of-the art research in the field of artificial intelligence, machine learning and data science.</li>\n<li>Questions pertaining to the implementation of techniques and methods that can be used to achieve artificial intelligence (there are very few of these).</li>\n<li>Questions pertaining to the implementation of machine learning techniques and methods (Bayesian models, trees, neural networks, deep learning, etc.).</li>\n</ul>\n\n<hr>\n\n<p>A site which combines both Artificial Intelligence and Data Science would have many <strong>benefits</strong>:</p>\n\n<ul>\n<li><p>A wider audience of potential answerers such that individuals may have a higher probability of find resolutions to their queries. For example a deep learning question asked on either of the sites only, will not reach as many answerers, this hurts the questioner's chances of getting the best possible answer.</p></li>\n<li><p>The possibility of people with a strong implementation background whom are more likely to peruse Data Science, to also be involved in discussions regarding the ethics and morality of artificial intelligence. </p></li>\n<li><p>The possibility of those more interested in the humanities of artificial intelligence to see the kinds of problems that machine learning algorithms are capable of solving and forging stronger arguments about the ethical use and morality of artificial intelligence.</p></li>\n</ul>\n\n<hr>\n\n<p>In my opinion, artificial intelligence does not yet exist, very fancy computational models which are essentially hyper-plane separators are not intelligent. However, due to the misnomer used in the medias for machine learning, artificial intelligence is used to describe these techniques. </p>\n\n<p>As a result, many questions on the Artificial Intelligence site do not match the intended guidelines of the site. Most questions on any particular day do not belong on this site and should be migrated to Data Science. I propose the sites be merged into a single site.</p>\n\n<p>I really do like the questions asked on the Artificial Intelligence site and I would love to partake in them. However reading through Stack Overflow and Data Science usually occupies most of the time I want to spend on my couch. Furthermore, I often see questions in Artificial Intelligence that are almost mirrors of those that have already been answered in great lengths in Data Science. Specifically those relating to neural networks, backpropagtion or gradient descent.</p>\n\n<p>I would ask kindly for the mods of this site to consider that in unity we are all stronger, in division we fall.</p>\n"}, "1363": {"ParentId": 1356, "Score": 1, "Body": "<p>I'd personally like to expand the guidelines to formally include:</p>\n\n<ul>\n<li>a specific <strong>AI</strong> programming problem, or <br></li>\n<li>an <strong>AI</strong> software algorithm, or <br></li>\n<li><strong>AI</strong> software tools commonly used by programmers; and is <br></li>\n<li>a practical, answerable problem that is unique to <strong>AI</strong> software development <br></li>\n</ul>\n\n<p>which is basically Overflow with \"AI\" added to each line.</p>\n\n<p><strong>WHY?</strong></p>\n\n<p>My main competency is in the humanities side of the AI equation, but I don't think it's possible we'd going to be able to sustain the level of activity to graduate from Beta on philosophical and conceptual questions alone.  And, I'm inclined to believe that AI is a field where the humanities and sciences intersect.  </p>\n\n<p>When I first came on as mod, there was a flood of Python question related to AI development.  It seemed clear that these endeavors constitute a relatively new sub-field.  So while I'd point someone with a general Python question to Overflow of Computer Science, if that question relates to AI, I think it belongs here. That's just one example.</p>\n"}, "1364": {"ParentId": 1356, "Score": 1, "Body": "<p>I preemptively modified the guidelines just now to make it clear that <strong>reference requests</strong> are on-topic.  (We have a tag for it, and reference requests have utility and traffic-drawing value.)  The idea is that experienced contributors can suggest reference materials with some vetting and, ideally, context and synopsis.</p>\n\n<p>We also have <strong>software evaluation</strong> and <strong>hardware evaluation</strong> tags, and I'd like to add these officially as well because here there can be a great deal of objectivity.  (i.e. processor performance can be precisely quantified, and functions related to AI development explained.  Likewise, with software utilities, functions and capabilities can be accurately listed and broken down.)</p>\n\n<p><strong>AI Career Advice</strong>\nI strongly feel this should be on-topic.  While it's typically the type of thing one undertakes on chat, most chat participation is low, and good luck finding someone who can give you advice in any given span.  But AI has never been more burgeoning as a field, with opportunities for the average programmer in addition to PhD's.  A lot of people want to get into the field, and advice from professionals and scholars would be salient, beneficial, and potentially boost activity/engagement with answerable questions.</p>\n"}, "1366": {"ParentId": 1365, "Score": 3, "Body": "<p>If the example questions are not on-topic here, then I do not think any of them are unique, interesting and high enough quality to be worth migrating to Data Science stack exchange as they stand now.</p>\n\n<p>As a long-term contributor to Data Science, my thoughts on the questions are:</p>\n\n<ul>\n<li><p><a href=\"https://ai.stackexchange.com/questions/6050/performance-evaluation-metrics-used-in-training-validation-and-testing\">Performance Evaluation Metrics used in Training, Validation and Testing</a> is too vague and broad. Comments attempting to clarify with OP have not really resolved it. IMO, this <em>might</em> get answered on Data Science, but equally could be left abandoned as it is here, or closed as \"Too broad\" or \"Unclear\".</p></li>\n<li><p><a href=\"https://ai.stackexchange.com/questions/4291/forecasting-and-predict-using-matlab-artificial-neural-network\">Forecasting and predict using matlab Artificial Neural Network</a> looks like OP is trying to apply a regression model to a classification problem. However, there is nowhere near enough detail in the question to answer it well. Unless the OP was willing to get involved in clarifying how they are using the data set, this would likely get closed with \"Unclear\" on Data Science.</p></li>\n<li><p><a href=\"https://ai.stackexchange.com/questions/5448/deep-nn-architecture-for-predicting-a-matrix-from-two-matrices\">Deep NN architecture for predicting a matrix from two matrices</a> could potentially be answered (I suggest a possible work around for OP in comments), and might be OK on Data Science if clarifying comments by OP were included. Data Science does get a lot of \"I have a data set with this special trait, and I'm stuck about what to try\" questions. Some are good, many are not clear, most just need the OP to go ahead and try stuff*. IMO, the question here is borderline - not quite enough information to make a good answer, but it can probably be answered. As such though, I'm not sure of the value of migrating it so long after it was asked. I think migrating a similar question in future would be well received.</p></li>\n</ul>\n\n<hr>\n\n<p>* This is an ongoing issue on Data Science and I <a href=\"https://datascience.meta.stackexchange.com/questions/2267/what-to-do-about-are-my-model-ideas-for-this-problem-good-or-what-is-best-mo\">suggested we need to do something about it</a> on Data Science meta a while ago. Maybe Data Science needs a help advice similar to Stack Overflow's excellent <a href=\"https://stackoverflow.com/help/mcve\">https://stackoverflow.com/help/mcve</a></p>\n"}, "1368": {"ParentId": 1367, "Score": 2, "Body": "<p>The closest thing that currently exists is the main Stack Exchange site's <a href=\"https://stackexchange.com/filters/\">filter/subscription feature</a>. It doesn't do top bar push notifications as far as I know, but it can send new questions on a site to your e-mail as fast as every 15 minutes. You can also include multiple sites and filter by tags, if you like.</p>\n"}, "1369": {"ParentId": 35, "Score": 4, "Body": "<p><strong>Starting a new list of math questions to expand on <a href=\"https://ai.meta.stackexchange.com/a/1319/1671\">nbro's list</a>:</strong></p>\n<ul>\n<li><p><s>https://ai.stackexchange.com/questions/6633/back-propagation-in-nn-with-sigmoid-activation-function-division-by-0</s> (post deleted)</p>\n</li>\n<li><p><s>https://ai.stackexchange.com/questions/5057/k-armed-bandit-and-reinforcement-learning</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/q/7032/1671</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/questions/7147/gradient-of-boltzmann-policy-over-reward-function</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/questions/7182/small-multinomial-naive-bayes-text-classification-probabilities</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/questions/7207/mathematical-modelling-of-a-i-algorithms</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/questions/6308/linucb-with-hybrid-linear-models</s></p>\n</li>\n<li><p><s>https://ai.stackexchange.com/questions/1925/are-ffnn-mlp-lipschitz-functions</s></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/questions/6914/how-does-this-sigma-workharris-algorithm\">How does this sigma work?(Harris algorithm)</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/questions/6640/defining-formula-for-fuzzy-equation\">Defining formula for fuzzy equation</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/questions/6030/how-to-calculate-gradient-of-filter-in-convolution-network\">How to calculate gradient of filter in convolution network</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/5380/2444\">https://ai.stackexchange.com/a/5380/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/5179/2444\">https://ai.stackexchange.com/a/5179/2444</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/questions/6995/simple-question-about-hs-algorithms-formuloptical-flow\">Simple question about HS algorithm&#39;s formul(Optical flow)</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/7034/1671\">https://ai.stackexchange.com/a/7034/1671</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/q/7003/1671\">Why do we have to solve MDP in each iteration of Maximum Entropy Inverse Reinforcement Learning?</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/questions/6990/matrix-dimension-for-linear-regression-coefficients\">Matrix Dimension for Linear regression coefficients</a></p>\n</li>\n<li><p><a href=\"https://ai.stackexchange.com/a/7103/2444\">https://ai.stackexchange.com/a/7103/2444</a></p>\n</li>\n</ul>\n"}, "1371": {"ParentId": 1370, "Score": 3, "Body": "<p>The problems with generic external resource requests don't really change due to the size of the site.</p>\n\n<ul>\n<li><p>Links can fail, or go out of date. An answer that is mostly links could degrade so that it is not usable, unless it was actively maintained. This is also why link-only answers are discouraged. </p></li>\n<li><p>A \"correct\" answer is hard to assess.</p></li>\n<li><p>There is a strong element of opinion on what to include or exclude when compiling \"comprehensive\" lists. There is an implied \"and the list should be reviewed for relevance and curated\" which is hard to objectify, but if it wasn't present then clearly just Googling e.g. \"Reinforcement Learning tutorials and MOOCs\" would be enough for the OP.</p></li>\n<li><p>No-one will actually read or use a comprehensive list of introductory material. It becomes like a restaurant menu where a reader has to attempt to pick out the 2 or 3 items from the answer that would be most useful to them.</p></li>\n<li><p>I don't think that technical avoidance of actual hyperlinks, and use of ISBNs, course codes etc changes the nature of this at all. <em>Some</em> external references have a long shelf life. E.g. \"Origin of Species\" is still relevant today. But this does not apply to all books, just because they are books.</p></li>\n</ul>\n\n<blockquote>\n  <p>Just to be clear, what I means for resources isn't links to external sites that could easily expire.</p>\n</blockquote>\n\n<p>Perhaps if you made it clear what the nature of these non-link resources would look like in an answer, it could help move it out of being a request for generic resources, and become a more focused question. E.g. \"What are the must have introductory books in <em>subject area</em>, and what prior knowledge do they assume?\" is a lot more focused than \"I'm looking for a comprehensive list of MOOCs, books, tutorial and good resources\" which is essentially asking for anything and everything that <em>might</em> be useful, without bounds.</p>\n"}, "1372": {"ParentId": 1370, "Score": 0, "Body": "<p>After a week and after reading your comments and answers I still think that ai.SE could benefit from resource request questions. However, I think that my original question on main ai.SE is badly posed.</p>\n\n<p>Some reasons why ai.SE could benefit from resource request questions are:</p>\n\n<ul>\n<li>They attract visitors. This type of questions have usually a lot of views and could attract new visitors from web search engines.</li>\n<li>They could prevent some users to post dumb questions. This could be only a personal thought but one of the main reasons why I choose to join this community is that, as a self-thought beginner, I don't know which sources I should consider trustworthy.</li>\n<li>They could be helpful even for non-beginners. Even at the semi-professional level, one could find new resources interesting.</li>\n<li>They could condense a lot of similar questions that ask for resources about some topic.</li>\n</ul>\n\n<p>Of course, there are some disadvantages to this type of question. One of them is how to choose which answer should be accepted. I think that we could have one answer for each resource suggested and one accepted community answer that keeps track of the top resources linked. The community answer could be edit by anyone that has a certain reputation. </p>\n"}, "1373": {"ParentId": 1370, "Score": 2, "Body": "<p>When I think about this question in the context of research papers, for instance, I can't see a real issue.  </p>\n\n<p>Ideally, when posting research papers links, the title of the paper will be used in addition to the link, so if the link goes bad, people can still search for the paper. </p>\n\n<p>Russel &amp; Norvig's <em><a href=\"https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach\" rel=\"nofollow noreferrer\">Artificial Intelligence: A Modern Approach</a></em> is heavily cited on SE:AI, and the text was originally published in 1995.  The book is in its 3rd edition now, (which is not always noted when cited,) but even the 3rd edition dates from 2009, earlier than the recent Machine Learning milestones (~2016) yet the textbook is still relevant and heavily utilized.</p>\n\n<p>List questions do have some issues (see <a href=\"https://ai.meta.stackexchange.com/a/1371/1671\">Neil Slater's answer</a>) and seem to be off-topic in general across Stack exchange. </p>\n\n<p>However, I'd still think lists of research papers on a given topic, ideally peer-reviewed, would provide utility and carry archival value.  In the same way, lists of well-regarded textbooks could be useful. </p>\n\n<hr>\n\n<p>Second Consideration: Contemporary Hacker Culture and Youtube</p>\n\n<p>In some sense we're the \"General AI\" site, covering the full scope of the field, as opposed to focusing on any given specific aspect (distinct from stacks like Data Science.)  </p>\n\n<p>We seem to be the stack where beginners typically come to first.  I created a <a href=\"https://ai.stackexchange.com/questions/tagged/getting-started\">getting-started</a> tag because there are so many of these questions. </p>\n\n<p>Many people today are learning the basics today via youtube videos. Where the videos are solid, they seem to provide benefit, but they tend to be more ephemeral, especially when they come from non-academic sources.  (Erik Demaine's lectures on <a href=\"https://www.youtube.com/watch?v=moPtwq_cVH8\" rel=\"nofollow noreferrer\">Time Complexity</a> will likely be available for a very long time indeed, where a random youtuber using click-baitey titles subject matter to generate ad-revenues may not be.)</p>\n\n<p>My feeling is, re: videos, is that anything commercial should be avoided, but anything coming from accredited academic institutions is reliable and suitable.</p>\n"}, "1375": {"ParentId": 1374, "Score": 2, "Body": "<p>I do agree that the impact of shenanigans on a small site is greater because of the smaller size of our rep economy and the lower beta privilege thresholds.  This is partially balanced out by there being fewer users to keep track of, but as you said, that can also make it difficult to tell organic interaction apart from problematic behavior.</p>\n\n<p>The \"contact us\" link goes to Stack Exchange the company; moderators never see those requests. I imagine the Stack Exchange community management team is pretty busy (they oversee all 174 SE sites), so it might take a while for them to get to your request. In many cases, though, site moderators can do the job. In a sense, this site can respond with more agility than larger ones because the mod workload is far lighter. </p>\n\n<p>To reach a moderator about suspicious patterns, <strong>cast a custom flag on any post</strong>. If you need more space than the flag box affords, I can create a private chatroom for you to share your findings with the mods. Thank you for your vigilance.</p>\n"}, "1377": {"ParentId": 1376, "Score": 1, "Body": "<p>The question has been addressed (see comments to the question). We now have a <a href=\"https://ai.stackexchange.com/questions/tagged/monte-carlo-tree-search\">monte-carlo-tree-search tag</a>.</p>\n"}, "1382": {"ParentId": 1381, "Score": 1, "Body": "<blockquote>\n  <p><strong>Is the current out-facing description of the AI meta descriptive of what it is?</strong></p>\n</blockquote>\n\n<p>I think the answer to this is a fairly obvious \"no\" at this point in time.</p>\n\n<blockquote>\n  <p>The co-question is this.</p>\n  \n  <p><strong>Is discussion about life in a changing world really what is relevant to most people who would search for Artificial Intelligence in the search field of SE? And if not, shouldn't we adapt to the real interests of our membership?</strong></p>\n</blockquote>\n\n<p>This is in my opinion the much more important question. Again, I think the answer is \"no\". Those topics may be interesting and relevant for some, and it's fine to allow them, but I suspect that much more detailed questions about specific little things in AI are more relevant to more people that happen to find their way onto this site. In my opinion, the description should indeed be adapted to allow more \"technical\" questions... basically, allow the kinds of questions we see many of. Not necessarily technical in the sense of \"why doesn't this snippet of code work\", but technical in the sense of \"how/why/in what cases should this part of an algorithm work?\"</p>\n\n<hr>\n\n<p>A few minor nitpickings from me:</p>\n\n<blockquote>\n  <p>Many of the current AI beta Q&amp;A are lacking in scientific rigor even though the AI beta is in the Science SE category. The use of mathematics is a quality factor in a science site as much as inclusion of academic references or narrowness of the problems set forth in the questions.</p>\n</blockquote>\n\n<p>I don't agree that this is a problem. StackExchange as a whole (all sites across the entire network) tends to be primarily about \"quick\" questions and answers, about building a site that people can easily reach through google searches, quickly see a question relevant to their search terms, and quickly find an answer that addresses their needs. </p>\n\n<p>Most questions really don't need answers with a thorough literature review, like a scientific paper would. Some do, sometimes there'll a really great question that is best addressed with a great answer containing interesting references to literature, etc... kind of like how, on StackOverflow, you'll sometimes find great answers with lots of different possible solutions, a lot of work put into timing the different implementations, explaining observed performance differences, etc. </p>\n\n<p>That's certainly not necessary for the majority of questions though. Many more questions are asked by non-experts, or first-year or second-year students for example. They might use slightly incorrect terminology, not be aware of all kinds of other potential solutions, etc. But when they have a clear question about an algorithm they're learning about, they just need an answer to that, they don't need a thorough literature review.</p>\n\n<blockquote>\n  <p>I think it is correct to assemble AI under Science and not Technology because <strong>the technology side is covered under SE sites such as Arduino and Data Science</strong>, which are properly placed in the Technology category.</p>\n</blockquote>\n\n<p>I don't agree with the bolded part there. I've personally never heard of Arduino, but a quick google search does not tell me how that covers a major part of AI at all, it seems really specific and niche. AI is also much much more than just Data Science. AI includes things like search algorithms, planning, pathfinding, and probably much more stuff that is not Data Science. People need a place to ask questions about all that, and it's not covered by any other StackExchange site.</p>\n"}, "1383": {"ParentId": 35, "Score": 4, "Body": "<p>I would like to add to the calls for LaTeX support with a specific topic. </p>\n\n<p>In my opinion, the AI Stack Exchange should be <strong>the</strong> home for questions about <em>Reinforcement Learning</em>.</p>\n\n<p>RL questions actually appear in larger numbers on Data Science and Cross Validated Stack Exchange sites. That makes little sense to me, when AI, robotics and other better homes in a conceptual sense exist for this topic.</p>\n\n<p>RL is a technical subject requiring solid understanding of underlying maths, especially for anyone wanting to engage in algorithm design. I would like to be able to write equations and maths-based pseudo code when writing questions or answers about RL. It is a shame that this site presents a barrier to doing that. Along with the larger audience for other Stack Exchange sites, this one is losing out IMO on a current hot topic that could provide much traffic. And in part that is due to barriers when writing content.</p>\n"}, "1385": {"ParentId": 1384, "Score": 0, "Body": "<p><em>Disclaimer: NNs are not my area, and I only have a general grasp of General Topology.  I come to AI via combinatorics and combinatorial games which influences my perspective.</em></p>\n\n<ul>\n<li>Wondering if we should mention/emphasize \"<a href=\"https://en.wikipedia.org/wiki/Network_topology\" rel=\"nofollow noreferrer\">network topology</a>\" </li>\n</ul>\n\n<p>When researching the field of topology, I noticed it did not deal with certain aspects of geometrical game boards, which are more in line with the \"proto-topology\" pioneered by Euler with the <a href=\"https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg\" rel=\"nofollow noreferrer\">Bridges of K\u00f6nigsberg</a>.  (For instance, you can add or remove playable cells from a Chess or Go board, which alters the structure in terms of number of connections <em>(the network topology. From this standpoint, topological alterations to game boards potentially break game solutions, which may have an impact on AI performance/strength.)</em></p>\n\n<p>Also wondering how similar the network topology usage is re: NNs</p>\n"}, "1386": {"ParentId": 1384, "Score": 2, "Body": "<p>I <strong>strongly recommend against</strong> using this tag info, for the following reasons:</p>\n\n<ol>\n<li>Tag info should be <strong>easily understandable</strong>, provide <strong>clear information</strong> that tells a user whether or not to use that tag / whether or not it's relevant for their question. </li>\n<li>Tag info should be <strong>unambiguous</strong>, <strong>correct</strong>, and <strong>not be up for debate</strong>. The information in there should be \"generally agreed upon\" by people familiar with the relevant field(s) to be true.</li>\n</ol>\n\n<p>I don't think either of these points are satisfied here.</p>\n\n<hr>\n\n<p>For the <strong>first point</strong>, try reading through that text once, from top to bottom. Do you feel like you're now well aware of when the tag is or isn't applicable, what it's about? I certainly don't. I have the following concerns here:</p>\n\n<ul>\n<li>Usage guidance doesn't really tell us for which questions it should or shouldn't be used. It starts out with a bunch of fancy words that don't tell me anything about its relation to AI. It ends by telling us that \"topology\" is supposedly \"closely related\" to something, but still don't know <strong>what it is</strong>.</li>\n<li>Again, the main text / tag wiki doesn't provide clear information either. Again, lots of fancy words, but not much real information (definitely not <strong>clear</strong> information).</li>\n<li>The tag wiki gives some examples of things that are \"features of topology\" or are \"topological\", but we still don't have a clear description of what it's supposed to be.</li>\n</ul>\n\n<hr>\n\n<p>For the <strong>second point</strong>, I have the following concern:</p>\n\n<ul>\n<li>It dives straight into \"Correct Use\" and \"Misuse\" headers, which is already hinting at the definition being up for debate, having multiple uses, being potentially ambiguous or not generally agreed upon. More importantly, <strong>as someone familiar with Neural Networks this might be plain incorrect according to my experiences</strong>. I say \"might be\" rather than \"is\" because the text is so incomprehensibly complicated that I can't tell for sure what it's actually saying.</li>\n</ul>\n\n<p>In general, in AI, when people are talking about \"topology\" in the context of Neural Networks, it's used to describe the \"architecture\" of the Network; how many layers, what types of layers, how large is each layer, what activation functions do we put in between, where are the connections (typically a feature of layer type). That's basically it, and that can be explained very clearly in language that can be understood easily. Some sources:</p>\n\n<ul>\n<li><a href=\"https://www.quora.com/What-is-the-difference-between-neural-network-architecture-and-topology\" rel=\"nofollow noreferrer\">A quora question</a></li>\n<li><a href=\"http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf\" rel=\"nofollow noreferrer\">A well-known paper on using evolutionary search to optimize a Neural Network's topology</a> (indeed, it's evolving the \"structure\" of the neural network).</li>\n</ul>\n\n<p>Many more similar sources can be found through a google search for \"Neural Network topology\".</p>\n\n<p>That is specifically in the <strong>context of Neural Networks</strong>. This will likely be the most common natural usage of the tag on this site. However, as also mentioned in the proposed tag wiki, <strong>topology is also a completely different field of mathematics</strong>. And <a href=\"https://www.quora.com/What-has-topology-got-to-do-with-machine-learning\" rel=\"nofollow noreferrer\">that field of mathematics may sometimes be relevant in a completely different manner in the field of AI</a>. So, \"topology\" can be <strong>ambiguous</strong>, and <strong>probably should not be restricted only to the usage in the context of Neural Networks</strong>.</p>\n\n<hr>\n\n<p>As a final concern, I am wondering what a header saying <strong>\"Only Possible Logical Conclusion\"</strong> is doing in a tag wiki. That's a header I'd expect in an opinion piece, or maybe as an overly-sensationalized header after a mathematical proof. This is not a header that belongs in a neutral, informative Tag Wiki.</p>\n\n<hr>\n\n<p>Now, given the use of language, I know immediately precisely which person proposed that tag wiki edit. For context, I think it's important to note that <strong>I've previously had a long discussion with this user concerning terminology</strong>, <a href=\"https://chat.stackexchange.com/transcript/81180\">which can be read here</a>.</p>\n\n<p>Note that, in that discussion, it becomes very clear that this particular user is knowingly and <strong>actively trying to push the usage of new terminology that he personally believes to be \"better\" than commonly-used terminology across the entire field</strong>. That is fine, he can do that if he likes, even on this site by e.g. asking questions like \"Wouldn't X be a better term instead of Y because reasons Z?\" But this should not be done through tag wikis. <strong>Tag wikis should be consistent with language used commonly across the field</strong>, otherwise every single non-expert user visiting the site (and maybe even expert users) is going to be confused.</p>\n"}, "1387": {"ParentId": 1381, "Score": 2, "Body": "<blockquote>\n  <p>The evidence for the below reasons is clearly evident not only in the\n  titles and bodies of the most popular questions and answers but also\n  in tag usage, the top ten being these.</p>\n  \n  <ul>\n  <li>Neural networks</li>\n  <li>Machine learning</li>\n  <li>Deep learning</li>\n  <li>CNNs</li>\n  <li>Reinforcement</li>\n  <li>AI design</li>\n  <li>Image recognition</li>\n  <li>Algorithm</li>\n  <li>Classification</li>\n  <li>Training</li>\n  </ul>\n</blockquote>\n\n<p>All these topics are on-topic on <a href=\"http://stats.stackexchange.com\">http://stats.stackexchange.com</a> and <a href=\"https://datascience.stackexchange.com\">https://datascience.stackexchange.com</a>. I don't see any point in having <a href=\"https://ai.stackexchange.com\">https://ai.stackexchange.com</a> covering them as well.</p>\n"}, "1389": {"ParentId": 1388, "Score": 4, "Body": "<p>Our <a href=\"https://ai.meta.stackexchange.com/q/1285/75\">justification policy</a> requires that speculative answers give some justification or reasoning for their assertions. I originally intended it for things like this hypothetical (and somewhat hyperbolic) exchange:</p>\n\n<blockquote>\n  <p>Q: What is the risk from widespread deployment of self-driving cars?</p>\n  \n  <p>A: Self-driving cars will work fine for a while, gain sentience, turn malevolent, wait for a perfect opportunity, and kill us all. This sequence of events is 100% certain.</p>\n</blockquote>\n\n<p>Wild speculation requires some sort of justification. It still might not be correct (votes can indicate accuracy/reasonableness), but there must be some explanation of how the answer author arrived at their conclusion. Citing sources is a great way, but not the only way, to provide that. It seems to me like drawing on philosophy/religion is a decent method to explain one's position.</p>\n\n<p>Regarding the specific answer you discuss: I deleted it not for lack of explanation but because &mdash; despite its considerable length &mdash; it didn't actually address artificial intelligence.</p>\n"}, "1391": {"ParentId": 1390, "Score": 1, "Body": "<p>Depending on individual inclination, however</p>\n\n<ul>\n<li>Restricting edits to just a few per day would be optimal</li>\n</ul>\n"}, "1393": {"ParentId": 1392, "Score": 4, "Body": "<p>I personally feel like most Data Science questions would be just fine on AI too, Data Science and AI simply are very closely related. The only argument against having Data Science questions on AI.se that I'm aware of basically boils down to trying to avoid as much overlap as possible.</p>\n\n<p>From my point of view, that kind of overlap really isn't too much of a problem. The topic in the question (entity recognition from text) is certainly a topic that could be described as being a part of \"Artificial Intelligence\", and it would be just as correct as saying it's a \"Data Science\" topic. So I personally really wouldn't mind if it's allowed on either site, I can see it fitting in either just fine. I understand that StackExchange as a complete network might find it more problematic if there's too much overlap, and if that's the case their opinion is probably more important than mine, I just don't experience it as problematic personally.</p>\n\n<p>The only sentence in the question you linked to that is maybe a bit questionable in my opinion is the following:</p>\n\n<blockquote>\n  <p>I have tried Spacy and NLTK for entity extraction but that doesn't suffice above requirements.</p>\n</blockquote>\n\n<p>That sentence is describing specific tools/frameworks, and implies the question-asker might be looking for more names of similarly specific tools/frameworks. I do feel those kinds of questions would be a better fit for Data Science. </p>\n\n<p>But the same question, especially if you ignore that one sentence, can easily be interpreted as being of a more conceptual nature, asking more generally about techniques/algorithms that would be applicable. It looks to me like both of the current answers also interpret the question in that way. Such \"conceptual\" questions would be just fine here in my opinion.</p>\n"}, "1396": {"ParentId": 1395, "Score": 1, "Body": "<p>I agree with this because <a href=\"https://en.wikipedia.org/wiki/Neuromorphic_engineering\" rel=\"nofollow noreferrer\">it is consistent with the wiki article</a> for the field.</p>\n"}, "1398": {"ParentId": 1392, "Score": 2, "Body": "<p>To second Dennis Soemers' answer:</p>\n\n<p>Much, but not all, of Data Science relies on AI tools. When the question relates to AI, we should answer it.</p>\n\n<p>Some examples of Data Science topics that are <em>not</em> about AI, and which we should migrate are:</p>\n\n<ul>\n<li>Questions about scraping data from the web.</li>\n<li>Questions about hypothesis testing or other conventional techniques from statistics (unless about the evaluation of ML methods).</li>\n<li>Questions about programming languages or toolkits within those languages, that focus on syntax or programming rather than AI/ML algorithms.</li>\n</ul>\n"}, "1399": {"ParentId": 1356, "Score": 1, "Body": "<p>I don't see a discussion of what constitutes a good \"Soft Question\", but @DukeZhou's suggestions make sense:</p>\n\n<ul>\n<li>Questions should be rooted in existing AI research, or research by serious philosophers on AI related topics, not in popular non-fiction books. (i.e. favour Moshe Verdi or Nick Bostrom over Ray Kurzweil). \n\n<ul>\n<li>Rationale: Popular non-fiction tends to exaggerate AI's capabilities, and tends to be written by people with little actual knowledge of the field, despite reaching a broad audience. Questions rooted in this material will tend to elicit wildly speculative answers, or to be unanswerable. </li>\n</ul></li>\n<li>Soft questions and their answers should include supporting citations to scholarly works, and should be rooted in empirically supported facts whenever possible. \n\n<ul>\n<li>Rationale: A good example was a recent question on automation. It's easy to speculate, but there's actually lots of good data, both about what financial markets think will be automated, and what AI experts as a whole think can be automated. These estimates are likely to be far more reliable than an individual user's opinions, or even any philosopher's opinions.</li>\n</ul></li>\n</ul>\n"}, "1400": {"ParentId": 1397, "Score": 2, "Body": "<p>If a question is unanswerable, it should be closed, be it old or new. This is more or less what closing is for. </p>\n\n<p>But don't do it for the sake of Area 51 statistics. Those statistics outlived their usefulness, as did Area 51 itself. The post <a href=\"https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites\">Graduation, site closure, and a clearer outlook on the health of SE sites</a> explains that already in 2015, those stats did not really matter for site graduation or closure.</p>\n"}, "1401": {"ParentId": 1397, "Score": 1, "Body": "<p>Speaking as a pro tem mod, we see a lot of single close votes, but tend to give the OP the benefit of the doubt, and err on the side of caution.</p>\n\n<p>My feeling is the best method to increase closure of these \"grey area\" questions is to keep attracting knowledgeable contributors, and supporting those contributors by upvoting good questions and answers, so that more users have informal moderator privileges.  (i.e. I'm personally more comfortable with closures being consensus-based because, as JD notes, it can be a difficult determination, even for qualified individuals.)</p>\n\n<p>That said, I'd like to prune away as much of the noise and dead-weight as possible to improve our stats.  I'm wondering if we might start a chat thread to address questions in limbo, so that if contributors make a strong case for closure, the moderators can more confidently take action.</p>\n"}, "1405": {"ParentId": 1404, "Score": 9, "Body": "<p>This is great news.  We may still be in Beta, but hopefully not for much longer!  I'm taking it as a good omen that a foundational company in the field of AI wants to be associated with our dynamic and growing Artificial Intelligence stack!</p>\n"}, "1406": {"ParentId": 1404, "Score": 3, "Body": "<p>I do appreciate the IBM work!\nHowever; <em>How do this newly sponsored AI site differ from the other sites that have been parterned with SE,like AskUbuntu</em></p>\n\n<p>Is creating a new site only in this case, as a proof of concept? And then if it works, in the future existing sites will be sponsored? Otherwise I don't think I understand how sponsorship equates to \"bringing resources back\"; creating more sites sounds like spreading resources out or else this is more of a \"we want to advance knowledge in our field for altruistic reasons\" thing for companies, or is this supposed to give them a profit eventually. </p>\n\n<p>According to my analysis,basing on the snapshot of the site in the question body,A sponsorship generally entails enabling ads relevant to the subject and affixing a small \"sponsored by...\" logo in the upper-right corner, and i do think  that's why <em>ibm</em>  is here!</p>\n\n<p><strong>Anyways,appreciated approximately.</strong></p>\n"}, "1407": {"ParentId": 1397, "Score": 1, "Body": "<p>I make a point of visiting the unanswered queue on all sites that I am active on. It's possible to earn an <a href=\"https://ai.stackexchange.com/help/badges/90/explainer\">Explainer</a>, <a href=\"https://ai.stackexchange.com/help/badges/64/revival\">Revival</a>, <a href=\"https://ai.stackexchange.com/help/badges/17/necromancer\">Necromancer</a> or other badge available to new questions.</p>\n<p>We should run through the queue when we visit here.</p>\n<p>The site <a href=\"https://interpersonal.stackexchange.com/questions?sort=unanswered\">Interpersonal.SE</a> has an unanswered queue style similar to ours (single tab), while <a href=\"https://lifehacks.stackexchange.com/unanswered/tagged/?tab=noanswers\">LifeHacks.SE</a> has the advantage of a multi-level Unanswered Questions queue; with additional tabs for &quot;my tags&quot;, &quot;newest&quot;, &quot;votes&quot; and &quot;no answers&quot; permitting better differentiation. Both those sites have a similar total number of questions as we do, yet the number of unanswered questions is near zero.</p>\n<p>The remaining question is do we want a multi-level queue like LifeHacks has? I'm new to AI.SE, so I'd prefer a senior member put in a feature request over at <a href=\"https://meta.stackexchange.com/search?q=unanswered%20questions\">meta.SE</a>.</p>\n<p>Be certain to improve and better these similar requests that became ignored or status-declined:</p>\n<ul>\n<li><p><a href=\"https://meta.stackexchange.com/questions/8506/improving-navigation-around-unanswered-questions\">Improving navigation around unanswered questions</a></p>\n</li>\n<li><p><a href=\"https://meta.stackexchange.com/questions/16542/how-to-search-unanswered-questions\">How to search unanswered questions</a></p>\n</li>\n<li><p><a href=\"https://meta.stackexchange.com/questions/11563/tab-for-questions-that-are-labeled-with-favorite-tags\">Tab for questions that are labeled with favorite tags</a></p>\n</li>\n<li><p><a href=\"https://meta.stackexchange.com/questions/143113/are-unanswered-questions-a-problem-yet\">Are unanswered questions a problem yet?</a></p>\n</li>\n<li><p><a href=\"https://meta.stackexchange.com/questions/159964/how-should-users-handle-unanswered-questions\">How should users handle unanswered questions?</a></p>\n</li>\n</ul>\n<p>Fortunately, <a href=\"https://meta.stackexchange.com/a/92006/282094\">automatic deletions</a> are performed on old questions:</p>\n<blockquote>\n<p>If the question is more than 365 days old, and ...</p>\n<ul>\n<li><p>has a score of 0 or less, or a score of 1 or less in case the owner's account is deleted</p>\n</li>\n<li><p>has no answers</p>\n</li>\n<li><p>is not locked</p>\n</li>\n<li><p>has view count &lt;= the age of the question in days times 1.5</p>\n</li>\n<li><p>has 1 or 0 comments</p>\n</li>\n<li><p>isn't on a meta site</p>\n</li>\n</ul>\n<p>... it will be automatically deleted.</p>\n</blockquote>\n"}, "1408": {"ParentId": 1404, "Score": 1, "Body": "<p>Slight concern: Does this mean that a new moderator will be appointed in AI.SE? Some of us here are beginners and may ask apparently stupid questions and answers. The new moderator might close or delete such questions and answers. </p>\n\n<p>The current moderators understand these concerns and have a very good moderating policy on such type of questions and answers.</p>\n\n<p>Thought I would add some links:</p>\n\n<p><a href=\"https://ai.meta.stackexchange.com/questions/1313/are-we-too-fast-downvoting-questions-especially-for-newcomers\">Are we too fast downvoting questions, especially for newcomers?</a></p>\n\n<p><a href=\"https://ai.meta.stackexchange.com/questions/1289/13-out-of-the-15-questions-on-the-front-page-right-now-are-1-or-lower-score-th\">13 out of the 15 questions on the front page right now are -1 or lower score: This site needs a broader scope or it's doomed</a></p>\n"}, "1412": {"ParentId": 1411, "Score": 6, "Body": "<p>I like <strong>theory</strong>.</p>\n\n<p>I recently <a href=\"https://ai.stackexchange.com/questions/7861/what-does-hard-for-ai-look-like\">made a post</a> and was highly surprised to find out that \"theory\" wasn't a tag option. I have never heard of the word \"theorics\" before in my life and only found it by looking at the list of tags. <strong>Edit:</strong> I didn\u2019t even realize it was \u201ctheorics,\u201d I thought it was \u201ctheoretics\u201d which sounds more like a word to me.</p>\n\n<p>Speaking as a native English speaker whose degrees are in <em>math</em> and <em>philosophy</em> I feel quite inclined to say that a word for \u201ctheory\u201d that I\u2019ve never heard in my life is unlikely to be widely known :P</p>\n"}, "1413": {"ParentId": 1409, "Score": 1, "Body": "<p>This would indeed seem to be problematic.  Although the icon is unique, it does appear to be a muddy blob of color at the smaller size.  Aside from the aesthetic, it's difficult to make an association to a stack when the image is not clear. </p>\n"}, "1415": {"ParentId": 1410, "Score": 4, "Body": "<p>I'd personally hesitate to declare questions off-topic just because the \"correct\" answers to them are highly likely to change over time. Indeed, this is going to be the case for \"state-of-the-art\" questions, especially considering how rapidly research in the field is moving and how rapidly the state of the art changes. I personally still feel like such questions aren't overly problematic because:</p>\n\n<ol>\n<li><p>They are likely a class of questions that is the most interesting for some people. In a field that moves this rapidly, and where young people are newly entering the field also at increasing rates, there is a lot of interest in knowing \"what is the state of the art right now?\". If there is a lot of demand for such questions, it makes sense to have a place where they can be asked to me.</p></li>\n<li><p>The web interface of the site already puts timestamps (dates) on questions and answers. Future visitors will be able to see (if they pay attention) if an answer they've run into is rather old.</p></li>\n<li><p>In the future, if the state of the art has significantly changed, people are free to provide new answers or add comments to existing (outdated) answers. If the people who wrote the original outdated answers are still around, they can also edit them. See, for example, <a href=\"https://stackoverflow.com/q/6542274/6735980\">this old question on stackoverflow</a>. It was originally asked 7 years ago, and was about the feasibility of training an Artificial Neural Network to play a complex video game like Diablo 2. At the time, this was highly unlikely to be feasible. However, we see some answers being written a few years later, and also see many edits in the question itself and in older answers, to reflect progress in the field.</p></li>\n</ol>\n"}, "1417": {"ParentId": 1411, "Score": 2, "Body": "<p>Yeah, changing it to \"theory\" sounds good to me.</p>\n"}, "1418": {"ParentId": 1410, "Score": 1, "Body": "<p>There is a difference between disproven and out of vogue.  What is proven false, if the proof stands up to thorough scrutiny is unlikely to have any future value other than to demonstrate how some things that were once widely believed may be later disproven.  These are some examples.</p>\n\n<ul>\n<li>The sun travels around the earth.</li>\n<li>Air, earth, water, and fire are the four elements.</li>\n<li>All propositions within a mathematical system can be proven or disproven.</li>\n<li>All natural phenomena can be placed in algebraic closed form.</li>\n</ul>\n\n<p>Many things that were thought absurd have been proven.</p>\n\n<ul>\n<li>Mercury is travelling too fast for its orbital path to be predicted by Newton's laws.</li>\n<li>Humans can survive in space and return alive.</li>\n<li>Computers can accurately and reliably sort mail with handwritten addresses.</li>\n<li>Computers can be trained to generate pictures of interior designs.</li>\n</ul>\n\n<p>However, very little in a Q&amp;A community are theorem that can be proven or disproven though.  Much of what is discussed is technique (in the Jaques Ellul sense of the word) that may fall into voge and then out of vogue more than once.  Something that is thought to be obsolete (but not formally disproven) may rise back to common use or may return slowly from obsolescence over decades.  Here are just a few examples of this toggling evident today.</p>\n\n<ul>\n<li>Earth is round -> earth is flat -> earth is round</li>\n<li>Vector graphics -> raster graphics -> vector graphics</li>\n<li>Ether -> no ether -> ether</li>\n<li>Turmeric -> chemotherapy -> turmeric</li>\n<li>AI via imitating biology -> AI via logic -> AI via imitating biology</li>\n</ul>\n\n<p>Given the history of science and technology, unless we can flat out disprove an answer we cannot, solely on the basis of its current apparent obsolescence, assert that it will never return to the forefront.  It is rather highly probable that some thing we now consider obsolete will become a key element in the furtherance of one of the sub-fields of Artificial Intelligence.</p>\n\n<p>Others in the future may look back and consider us ignorant for our current belief that some solution or approach is obsolete.</p>\n"}, "1423": {"ParentId": 1422, "Score": 2, "Body": "<p>I just looked around a bit and it turns out that moderators can edit that tour text. Our scope has changed and widened markedly from two years ago - those discussions were held before we even had our own moderators - so I think it'd be good to get fresh eyes and new thoughts on the tour blurb. Once we reach a consensus, I (and I'm sure my fellow mods too) would be happy to replace the current outdated text. As for the site description that appears in <a href=\"https://stackexchange.com/sites#name\">the sites list</a>, we'll need to poke Stack Exchange staff to get that adjusted once we've decided on a replacement.</p>\n"}, "1426": {"ParentId": 1425, "Score": 2, "Body": "<p>MathJax <a href=\"https://github.com/mathjax/MathJax-docs/wiki/LaTeX-Tabular-environment\" rel=\"nofollow noreferrer\">does not implement tabular</a>. One can <a href=\"https://math.meta.stackexchange.com/a/6737\">use <code>array</code> instead</a>:\n\\begin{array}{ l c r }\n  1 &amp; 2 &amp; 3 \\\\\n  4 &amp; 5 &amp; 6 \\\\\n  7 &amp; 8 &amp; 9 \\\\\n\\end{array}</p>\n\n<p>But I usually prefer <a href=\"https://senseful.github.io/text-table/\" rel=\"nofollow noreferrer\">text to table</a> tool by Senseful, to avoid relying on JavaScript for rendering. </p>\n\n<pre><code>+---+---+---+\n| 1 | 2 | 3 |\n| 4 | 5 | 6 |\n| 7 | 8 | 9 |\n+---+---+---+\n</code></pre>\n"}, "1429": {"ParentId": 1427, "Score": 5, "Body": "<p>I and many others would be very happy if people explained their downvotes more often. Essentially this request has been <a href=\"https://meta.stackexchange.com/q/135/295684\">already been discussed on Meta Stack Exchange</a>. As a result, the \"please consider adding a comment if you think this post can be improved\" pop-up was added. However, adding an impact on reputation to commenting would damage anonymity and/or produce a spew of useless comments:</p>\n\n<blockquote>\n  <p>I enjoy being able to down-vote posts I don't care for without worrying about retaliation. And I really enjoy being able to leave honest comments without worrying that they'll be justifiably interpreted as evidence that I've down-voted. I would not like to see the two systems linked.</p>\n</blockquote>\n\n<p>&mdash;<a href=\"https://meta.stackexchange.com/questions/135/encouraging-people-to-explain-downvotes/2373#comment313_135\">Shog9</a></p>\n\n<blockquote>\n  <p>The so-far-insurmountable problem is preventing users from just keyboard bashing \"aassdgfd\" if forced to type something.</p>\n</blockquote>\n\n<p>&mdash;<a href=\"https://meta.stackexchange.com/questions/135/encouraging-people-to-explain-downvotes/2373#comment1384_135\">bananakata</a></p>\n\n<p>Therefore, Stack Exchange seems to have decided not to implement further changes, and will probably not do so in the future.</p>\n\n<p>Anonymity is important to allow people to vote as they believe without fear of retaliation (in the form of revenge downvoting). Stack Exchange's model has always been that people can vote however they like as long as they're not targeting specific users. A single user's votes might not be very illuminating, wisely cast, or <a href=\"https://meta.stackexchange.com/a/215397/295684\">explicable at all</a>, but at scale votes usually average out to good rankings.</p>\n"}, "1432": {"ParentId": 1430, "Score": 3, "Body": "<p>Artificial Intelligence Stack Exchange is a question and answer site for ...</p>\n\n<blockquote>\n  <p>people interested in artificial intelligence theory, design,\n  development, <strong>practice</strong>, <strong>research</strong>, and policy.</p>\n</blockquote>\n\n<p>I like @DouglasDaseeco's answer, but I'm among the users who think that practice, <em>and even code</em>, have a place here. Presently users post questions containing code, and I and others answer them, so I think this description is more accurate.</p>\n\n<p>While the founding moderators' intent was to exclude questions that overlapped with other sites (notably Data Science &amp; Programmers.SE), the boundaries are quite porous in practice, and if we want to claim to be a useful place for AI related Q&amp;A on the web, I think we need to accept practical questions as well.</p>\n\n<p>Some examples of coding questions with no other place to go include:</p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/7555/keeping-track-of-visited-states-in-breadth-first-search/7560#7560\">Keeping track of visited states in Breadth-first Search</a>, which is about the proper data structures to use in a search algorithm. It doesn't belong in Data Science, since it is related to GOFAI and not machine learning. It doesn't really belong in Programmers.SE, because it isn't a generic question about programming, it's related to understanding the algorithm. It seems to clearly belong on this site, and yet it includes code and is about practice.</p>\n\n<p><a href=\"https://ai.stackexchange.com/questions/7940/snake-game-snake-converges-to-going-in-the-same-direction-every-time/7941#7941\">Snake game: snake converges to going in the same direction every time</a> This question was about the implementation of a reinforcement learning algorithm. The question again has nothing to do with Data Science. It involves programming, but the users' problems were not related to understanding how to program, but to understanding the algorithm (and, as it turned out, the exact behaviour of a particular algorithm for training neural networks). This user is not likely to get useful answers on Programmers.SE. It seems to clearly belong on this site, and yet it also includes code and is about practice.</p>\n"}, "1435": {"ParentId": 1427, "Score": 2, "Body": "<p>I think the number of votes is also a factor.  Right now, on SE:AI, we have relatively low voting participation.  This makes us a tough stack to build rep on, but it also makes the solo downvotes stick out.  </p>\n\n<p>Compare to a stack where there questions and answers receive a large number of votes quickly. When voting activity is high, the random downvotes have less of an impact.</p>\n\n<p>So, in some sense, the solution is to keep working to attract users, and boost the voting levels.</p>\n\n<hr>\n\n<p>I have seen what I believe to be pro forma, serial downvoting in the past on SE:AI.  My remedy for that has been to look at all new questions every day <em>(been slacking lately, admittedly,)</em> and make a point of upvoting questions I think have been unfairly downvoted.</p>\n\n<p>With answers, it's a little tougher b/c one doesn't want to up or downvote without a high degree of confidence.  </p>\n"}, "1437": {"ParentId": 1430, "Score": 3, "Body": "<p>I think we should also provide guidance to users about which questions may be more suitable for Data Science, Overflow, etc.  </p>\n"}, "1441": {"ParentId": 1440, "Score": 2, "Body": "<p>It looks to me like they are both used for similar questions, and based on the current Tag Info for the two tags they don't really appear to be different either. So, based on current tag usage, I'd argue that they should be combined into a single tag (which, in my opinion, should be <code>natural-language-processing</code> because that's the full term that everyone in the field uses in my experience).</p>\n\n<p>I suppose that, in theory, <code>natural-language</code> could refer to something else than NLP... like, it could be for questions about language itself, rather than questions about processing (generating and/or understanding) language. I have a very difficult time imagining any such questions would actually be on-topic for AI though.</p>\n"}, "1442": {"ParentId": 1440, "Score": -1, "Body": "<p>There is a key difference between the two terms.  Whether this finer level of granularity is useful in the tags, I have no opinion.</p>\n\n<p>Natural language is concerned with the general idea of conveying ideas via vocalization and the comprehension of the idea by a listener.</p>\n\n<p>Natural language processing sounds more well defined, but it is actually poorly defined and the definitions in the literature are scattered between these two extremes:</p>\n\n<ol>\n<li>Parsing text into linguistic structures.</li>\n<li>Linguistic processing components in chat-bots designed to replace human experts.</li>\n</ol>\n\n<p>What is included in NLP?</p>\n\n<ul>\n<li>Talking?</li>\n<li>Generating text?</li>\n<li>Generating linguistic associations?</li>\n<li>Parsing text?</li>\n<li>Hearing?</li>\n<li>Listening?</li>\n<li>Dialog?</li>\n<li>Topic detection?</li>\n<li>Cognition?</li>\n<li>Story invocation? &mdash; See Schank.</li>\n<li>Translation?</li>\n</ul>\n\n<p>Depends on who is teaching and when.  I don't even see any consistency between the same person's view of NLP over time.</p>\n\n<p>If addressing the terms literally, natural language is simply the field of linguistics minus the addition of formal languages.  NLP would then become the action that occurs when some system deals with natural language at either its input, its output, or both.</p>\n\n<p>I saw those two tags earlier today.  I don't have a recommendation as to whether to combine them or leave them alone.</p>\n"}, "1443": {"ParentId": 1430, "Score": 1, "Body": "<p>The two leaders are ...</p>\n\n<blockquote>\n  <p>people interested in artificial intelligence theory, design, development, practice, research, and policy.</p>\n</blockquote>\n\n<p>... and ...</p>\n\n<blockquote>\n  <p>people interested in embedded, mathematical, cognitive, and discovery centered artificial intelligence research and development.</p>\n</blockquote>\n\n<p>... so I propose the union.</p>\n\n<blockquote>\n  <p><strong>people interested in AI theory, mathematics, research, discovery, design, development, practice, embedded uses, cognition, policy, and impact.</strong></p>\n</blockquote>\n\n<hr>\n\n<p>This one is inclusive and dodges the terms <em>statistics</em> and <em>data science</em> which are the explicit domains of established SE siblings.</p>\n"}, "1447": {"ParentId": 1296, "Score": 1, "Body": "<p>The condition is related to the beta process definition and incentives built into the back end rules and user interface rules.  These are created and maintained based on the analysis of trends and the projections of that analysis by the owners of the system upon which the domains stackexchange.com and stackoverflow.com sit.</p>\n\n<p>Members, especially moderators and even more so diamond moderators, can mitigate the inevitable chaos that forms in any large account based network by choosing names and definitions that are likely to disambiguate options that users have.  People can also request features and enhancements that may modify incentives in positive ways.</p>\n\n<p>To meaningfully do any of these things it is important to understand that knowledge is segmented in some ways and homogeneous in other ways.  Forcing questions into clean compartments is not even done at universities with curricula.  In fact, trends toward interdisciplinary work are usually found at the most progressive universities and offered to the highest performing students.</p>\n\n<p>The natural overlap of human discovery and achievement cannot be changed by any web site incentives system.  Even the extreme measures of totalitarianism, jihad, or martial law are unlikely to bring about compartmentalized knowledge, mostly because smart people won't put up with it and will literally shoot back if pushed too far.</p>\n\n<p>Artificial intelligence was born of interdisciplinary thinking, and is bound only by two things.</p>\n\n<ul>\n<li>It concerns primarily what can be artificially created</li>\n<li>It concerns primarily how to make choices that produce better results than arbitrary selection</li>\n</ul>\n\n<p>Some may argue this.  I won't because I've heard all the arguments otherwise, and they lack merit to the degree that further response is ... .</p>\n\n<p>Regarding the current machine learning trend, it is primarily social and economic phenomenon that may or may not sustain.  Recognizing that what goes up often comes down is another key to making choices today that we don't regret later.</p>\n\n<p>At one time, stone work was a technology that bled into every topic.  In 100 years,  one may not be able to find the phrase, \"Machine learning,\" in a recent piece of media.  Perhaps nanotech-genetic portals might have become the craze, where people are id-based swallowed by their cars and homes instead of unlocking doors and keying alarm codes.  Or not.</p>\n\n<p>It could go the other way where people write ML algorithms that write poems instead of writing poems.  People might go to art museums and plug their mind into the Salvador Dali machine and their friends might laugh at their Dali-ized creative thoughts seen on a 4 dimensional canvas.</p>\n\n<p>In today's SE/SO reality, the best we can do is to consider naming and defining sites and tags based on a balance between currently common use of terms, the literal meaning of the words that comprise the term, and the overarching pattern of academics, publication, and terminology in those two places and on the web.</p>\n\n<p>My gut feel is that excessive control will do the exact opposite of balance and push everyone with a brain away from the entire SE/SO engagement model and other sites with more incentive and less control will capture those emigrants.</p>\n"}, "1450": {"ParentId": 1448, "Score": 4, "Body": "<p>The migration of this question to datascience seems <strong>really strange</strong> to me. Like you said, RL really is pretty much <strong>the furthest removed from data science out of all Machine Learning topics</strong>, even if it were off-topic on AI for whatever reason, it certainly wouldn't be on-topic on Data Science.</p>\n\n<p>To address specifically the question in the title, the I'd say pretty much any Reinforcement Learning question is on-topic on AI.se (AI certainly seems a better fit for RL questions than either stats.se or datascience.se), <strong>except maybe</strong> questions that are 100% clearly about programming issues/bugs. For example, a question like \"My RL algorithm is crashing, here is the stack trace, what's wrong?\" Such questions might be a better fit on StackOverflow (still <strong>not</strong> datascience).</p>\n\n<p>This particular question that got migrated <strong>might</strong> fit that description... but it's not certain. The question-asker is not certain if it's a bug in their code, or if there is some issue in choice of algorithm for this particular environment or something along those lines. In my opinion, whenever there is that level of uncertainty, the question is likely to require expertise in AI (specifically, in RL), not just programming expertise because it might not be just a programming issue. That makes, in my opinion, AI.se a better fit than StackOverflow.se (or any other site).</p>\n"}, "1456": {"ParentId": 1455, "Score": 6, "Body": "<p>I don't think the problem here is specific to open source authors. In fact I think that is a dangerous starting point: When it comes to free software resources, we will get a split opinion base - engineers that create free software are volunteers creating value for all in the real world, much like site contributors here. In many ways they are heroes that should be celebrated.</p>\n\n<p>The trouble with focusing on the value equation is that it puts the site voters into position of voting based on judging the worthiness of the product. I would fully expect a question placed by a Google employee about pre-trained image classifiers and answered with links to inception networks would get shut down as spam. So what is the difference?</p>\n\n<p>The linked question is the example of what can go wrong with allowing <strong>resource request</strong> questions on a Stack Exchange site. Most new sites struggle with what to allow when someone has a problem to solve but all they want is a link to something off-site that solves the problem directly. It is very useful to have links to the site subject's introductory material. However, such questions can quickly bring in contributions to the site that have agendas to promote some product or idea. Even when the product is free, the promotion typically has an agenda to increase reputation of the contributor off site - converting Stack Exchange answers into incoming links to the product.</p>\n\n<p>The nature of the question should set the scope for an acceptable answer - if the most appropriate answer is just a list of properties of the project plus a link and disclaimer, then <em>the problem is with the question</em>.</p>\n\n<p>We should start getting stricter about resource requests on AI Stack Exchange:</p>\n\n<ul>\n<li><p>Vote to close questions that ask for links to completed AI services, software products or projects, in order to just use them (as opposed to understand how they work)</p></li>\n<li><p>Downvote \"Gimme an AI that does X\" questions.</p></li>\n</ul>\n\n<p>I think we can still accept questions about papers on subjects as there is no real history of academic paper writers self-promoting via Stack Exchange. But  other resource requests need to be accepted more cautiously.</p>\n\n<p>The OP of <a href=\"https://ai.stackexchange.com/questions/8408/is-there-any-pretrained-model-for-emotion-detection/8409#8409\">the question</a> should look for <em>existing</em> questions about emotion classification in video, and answer accordingly. That would be a valuable contribution. A basic but good question about emotion recognition on AI could be asking whether neural networks are the only high-performing model, or whether NN models represent anything interpretable, whether they can be reversed to generate images that show \"archetype\" emotional faces, what the loss function should be to <em>discover</em> emotional responses instead of classifying them using supervised learning etc. All those questions would require more than just a link to a project - a brief link (with the disclaimer, but without listing traits unrelated to the question) would be appropriate if the project could be used as an example. </p>\n"}, "1459": {"ParentId": 1458, "Score": 3, "Body": "<p>They're both core topics that are important to understand well, very important basics, before people can move on to a plethora of more advanced topics in AI. So yes, they absolutely should be tags in AI.se.</p>\n"}, "1462": {"ParentId": 1454, "Score": 2, "Body": "<p>I don't see why AI should be different to SO in this respect. Updates to questions should be limited to clarifying, improving layout, spelling and grammar. They should not add new insights from or progress of the questioner, once answers to the original have been written.</p>\n\n<p>In general, this process needs to be more friendly to question answerers that askers. It is more expedient to get the OP of the question to take the extra effort to frame their problem as multiple separate questions, instead of having volunteers answering questions track changes and try to follow a conversation (and in the meantime often dilute the purpose of the original question).</p>\n\n<p>If someone tries to alter their question or ask lots of extensions in comments, then in my experience, a gentle/friendly push back and suggestion to ask a separate question is often all that is required. It is more helpful to show what the question OP <em>should do</em> as opposed to telling them that they are doing something wrong. </p>\n\n<p>If the OP of the question ignores such a suggestion, then the best next step is to walk away. There is no point arguing with them if they think they know better how the site should work. Just let their extensions to the question go unanswered. If that is disappointing to you (because you found the question a really good fit to the site, and were excited to answer it), then perhaps help the OP further by opening the new question yourself and pointing them at it - although I personally would not go that far, there are always other good questions.</p>\n\n<p>Regarding this scenario:</p>\n\n<blockquote>\n  <p>it may not be popular with a Q author and A author that are essentially collaborating on a small project together and are fully engaged in an extended helping process</p>\n</blockquote>\n\n<p>It's not really what the site is for. I would either:</p>\n\n<ul>\n<li><p>Downvote or close the question, if it was clearly too long/confusing and broad to meet site guidelines.</p></li>\n<li><p>Ignore the question if it kept changing, as it would be a waste of time to get involved, and it is only one question. This is not common behaviour.</p></li>\n</ul>\n\n<p>Given how little rep both the asker and answerer would get for their efforts, as the content becomes too dense for anyone else to work with, it is in some ways self-limiting. I note that as it stands today, the OP questioner got 10 rep in your linked question <a href=\"https://ai.stackexchange.com/questions/8128/difficulty-in-understanding-identifiability-in-dueling-network-paper\">difficulty in understanding identifiability in Dueling Network paper</a> and the four answers got a total of -2 rep between them. The resulting content is all but incomprehensible to me.</p>\n\n<p>In this case I notice you are one of the affected answerers. I don't think there is much you can do at this stage but chalk it up to experience. There is no way to force <em>collaborating</em> site users to behave according to above - the only tools SE has for moderation at that level are too heavy-handed to apply when the discussion is still technical, on-topic and polite. If you spot the behaviour early enough you can comment that you prefer it another way (and IMO the \"correct\" Stack Exchange way would be separate questions as you suggest), but if the whole thing has momentum with updates to both questions and answers, just leave the others involved in their discussion. </p>\n\n<hr>\n\n<p>Some clarifications <em>might</em> still make significant changes, if to answer a question accurately (as opposed to answers with general advice that might apply), the OP needs to add details about their specific situation, including code, data etc. Sometimes this unfortunately can invalidate answers that attack the question in a general sense. This is a tricky area to judge correctly. I think the line is most clearly drawn when the OP unilaterally adds new data, or is obviously changing their question in response to an answer which has already helped them.</p>\n"}, "1463": {"ParentId": 1461, "Score": 4, "Body": "<p>OK, this is partially done now, sorry for the delay. <a href=\"https://ai.meta.stackexchange.com/a/1443/75\">This proposal</a> (lightly edited for length) has now been used to update the blurb at the top of our <a href=\"https://ai.stackexchange.com/tour\">tour page</a>! To get various other instances of the text updated, we'll need to contact Stack Exchange. They're pretty busy at the moment, but hopefully something will happen here within a couple weeks.</p>\n"}, "1467": {"ParentId": 1465, "Score": 2, "Body": "<p>I agree that such questions are low-quality. I think the current options take care of these cases pretty well:</p>\n\n<blockquote>\n  <p>They usually show no effort in asking the question</p>\n</blockquote>\n\n<p>Downvoting is appropriate for such questions. In fact, the first part of the downvote arrow's tooltip is \"this question does not show any research effort.\" Note that it's possible for a question to be entirely on-topic and well-phrased (therefore not being a good candidate for closure) but still be of poor quality.</p>\n\n<blockquote>\n  <p>They [...] are hard to answer because it is not totally clear which variant of the algorithm / which facts about the algorithm the OP knows.</p>\n</blockquote>\n\n<p>These are a perfect application for the \"unclear what you're asking\" close reason, which asks the author to clarify. Note that it's possible for a question to be on-topic but still unclear or overly broad.</p>\n"}, "1471": {"ParentId": 1470, "Score": 3, "Body": "<p>The question becomes whether that information and the context it provides might be relevant in understanding the source of confusion or how the question might be answered (i.e. write for your audience).</p>\n<p>Certainly, someone saying:</p>\n<blockquote>\n<p>&quot;I am an {x} year student who is/is not familar with {x}; can you explain this to me in a way that others like me will understand?&quot;* \u2190 <em>USEFUL CONTEXT</em></p>\n</blockquote>\n<p>Of course, that doesn't necessarily forgive a question exhibiting insufficient understanding of the problem to bring it to a site like this (&quot;too soon, where are you  stuck specifically? what have you tried?&quot;).</p>\n<p>But where &quot;needless introductions&quot; can be stripped away is where it becomes chatty filler not really relevant to the post:</p>\n<blockquote>\n<p>&quot;Hi, guys. I love this site and y'all are great and I've been here for 3 years and now I have a question and I hope you all can help me yada yada ...</p>\n<p>&lt;actual question&gt;</p>\n<p>Thank you so much. I really appreciate your help. Important, important. Hopefully I can get an answer soon.</p>\n<p>signed &lt;username&gt; &lt;smiley emoji&gt;<br />\n&lt;list of credentials&gt;<br />\n&lt;list of favorite tomes&gt;<br />\n&lt;meme cartoon&gt;</p>\n</blockquote>\n<p>Of course, you don't have to become overly head-strong and vigilant in stripping away <em>every</em> incidental nicety. The overall goal is to make the content <em>demonstrably</em> more clear for those who come after. Use your judgement with those goals in mind and most of those leave-it/remove-it questions should become a bit more self-evident.</p>\n"}, "1480": {"ParentId": 1479, "Score": 3, "Body": "<p>Likely it's going to be a while.  I emailed the \"powers that be\", noting that we're starting to get traction and that we have a prestigious sponsor, but no reply as yet.  I'll ping them again after the New Year and update my answer as I get more information.</p>\n"}, "1486": {"ParentId": 1481, "Score": 1, "Body": "<p>Speaking as a mod, I tend to use a light touch in regard to migrating many of these potentially out-of-scope questions.  (Similar to avoiding closing questions by fiat, in all but the most egregious, preferring to follow the will of the community.)</p>\n"}, "1489": {"ParentId": 1483, "Score": -1, "Body": "<p>Community self-regulation is not new with SO/SE's model. It is in accordance with the same theoretical objectives of economic growth through legislative and judicial constraint in combination with enlightened creation of healthy economic incentives. We're really not talking about automated moderation as much as an e-republic within a fixed scope of public activities that include questions, answers, comments, and rating events.</p>\n\n<p>I think it works nicely in many ways, which is why I suspend my usual skepticism and contribute.</p>\n\n<p>Nonetheless, I would be negligent as a meta-contributor if I didn't mention some incentivization flaws that affect long term content quality objectives most of us would unanimously affirm as useful. I'm specifically talking about two important cases that affect long term quality of site content.</p>\n\n<ol>\n<li>Saving the best aspects of questions that may be otherwise closed. This condition frequently presents because of the current cultural sense of duty to avoid changing details of the original author's intent. The question is almost never edited by the original author, who may get discouraged by the vote to close, and attempts to preserve the positive aspects of the question by discarding the offensive ones by veterans on this site seem to often be reverted.</li>\n<li>Imbalance in the scale of reputation, where questions that have been around a long time might have high reputation and provably low quality. This condition persists largely because posting alongside an answer with a super high reputation seems futile. This is the bigger problem when answers with seriously flawed presentations of theory have accumulated extremely high reputations resulting mostly because they sound good and there are zero alternatives.</li>\n</ol>\n\n<p>See <a href=\"https://ai.meta.stackexchange.com/questions/1487/how-can-we-adopt-a-more-long-range-quality-first-vision\">How can we adopt a more long range, quality first vision?</a>? for a call to meta-contributors and readers to think about these.</p>\n\n<p>There are many ways to modify incentives slightly to resolve both these problems, but they are incentive imbalances that may only be balanced through modification of the SE/SO social engineering model and corresponding modifications of the server framework that implements it.</p>\n"}, "1491": {"ParentId": 1490, "Score": 5, "Body": "<p>First, badly formatted posts should be fixed; that is what the wiki-style editing is for. </p>\n\n<p>But that specific question should be closed as <code>primarily opinion-based</code> because it is soliciting arguments and debate centered around a vague premise built on a hypothetical future which does not currently exist. Please don't let this site become <a href=\"https://worldbuilding.stackexchange.com/help/on-topic\">Worldbuilding</a>. It is not a good fit for this site. </p>\n\n<p>But to answer your question more generally, if the premise of a question is wrong or misleading &mdash; whether by misunderstanding or pop culture hype &mdash; you should answer in a way that dispels the mistaken belief. Head off the incorrect information or assumption with a cohesive answer explaining the issue correctly. </p>\n\n<p>Folks around the Internet are searching for this (mis)information wherever they can find it. It would nice if they landed <strong><em>here</em></strong> to straighten out the issue authoritatively.</p>\n"}, "1492": {"ParentId": 1490, "Score": 2, "Body": "<p>There's actually a great deal of debate about this subject in general in the wider AI community (ethics re: implementation of AI).  </p>\n\n<p>That said, the question is poorly worded, and overly focuses on the proffered scenario, as opposed to the underlying general issue.</p>\n\n<p>I've retagged (ethics, social, legal) and have provisionally closed the question, pending clarification.  </p>\n"}, "1493": {"ParentId": 1458, "Score": 1, "Body": "<p>It depends on how the questions are asked.  Linear Regression is the foundation for many different machine learning and artificial intelligence algorithms.  If someone were to ask a question on how their problem could be formatted as a regression, then I would argue that it's perfectly relevant to this SE.  Technically, linear regression alone is one of the simplest forms of machine learning.  Now, if you were to ask to prove the bounding condtions of certain types of optimizations under purely theoretical conditions, it may not be as relevant to this SE as cross validated for example.</p>\n\n<p>In short, it depends on how the question is asked.  If it deals more with the application side of AI, then yes.  I think it is perfectly reasonable to ask on the AI SE.</p>\n"}, "1496": {"ParentId": 1495, "Score": 5, "Body": "<p>Neither of those questions, nor this one make any sense to me. I have read and re-read trying to understand what you mean, and I honestly have no idea.</p>\n\n<p>I would vote either of those ones as unclear what you are asking, or possible offtopic, and have to also vote this one as unclear.</p>\n\n<p>There seems to be a language challenge here. The body of your questions doesn't align with the titles. The titles seem like off topic questions, but the body of the questions is all over the place.</p>\n"}, "1497": {"ParentId": 1495, "Score": 5, "Body": "<p><a href=\"https://ai.stackexchange.com/revisions/10539/7\">At the time</a> I read the question for the first time, this is what I interpreted:</p>\n\n<ul>\n<li><p><strong>Title</strong>: \"Should\" suggests that the question was eliciting opinions of the readers, whether \"yes\", \"no\", \"doesn't matter\", etc., which is opinion-based (off-topic) because there's no one correct answer, or every answers are correct.</p></li>\n<li><p><strong>1st paragraph</strong>: According to your personal experience, \"Safety Check\" doesn't seem to work when you're stuck on \"Name Change Checkpoint\" page.</p></li>\n<li><strong>2nd paragraph</strong>: According to Zuckerberg, \"Safety Check\" is using AI.</li>\n<li><strong>3rd paragraph</strong>: More explanation about \"Safety Check\", particularly about it not being able to be moderated by public users (i.e. fully automatic)?</li>\n<li><strong>4th paragraph</strong>:  Explanation about checkpoint page and Name Change Checkpoint page</li>\n<li><strong>2 list items</strong>: Meta commentary that there are no related questions about \"Safety Check\" on AI.SE</li>\n<li><strong>5th paragraph</strong>: Meta commentary, and a slight hint of another question (\"<em>what is important for a question about safety</em>\"), and a comment about \"911 case\" (globally recognized), \"211 case\" (I never heard about that until I googled it), and \"911 API\" (also not sure, but based on googling, perhaps an emergency reporting system)</li>\n</ul>\n\n<p>So, after finished reading this, the question left me with the impression that it is opinion-based (title) and too-broad (5th paragraph).</p>\n\n<hr>\n\n<p>Regarding the title of the meta discussion,</p>\n\n<blockquote>\n  <p>Is FB.com's \u201cSafety Check/\u201dCrisis Response\" for AI.stack or WebApp.stack if @zuck called it Artificial Intelligence?</p>\n</blockquote>\n\n<p>As I'm not a regular of this community, I don't have enough knowledge to determine if it's on-topic or not.</p>\n\n<p><em>Perhaps</em> the inside work/mechanic of the feature <em>might</em> be on-topic, e.g. \"<em>How does Facebook's 'Safety Check' recognize a crisis and alert the relevant user?</em>\" looks like AI-related. (Note again, whether it's really acceptable question or not, I can't answer that as I'm not a regular)</p>\n\n<p>However, for your specific question on AI.SE, reading from the title and the non-existence of the explicit question on the body made me assuming that you're asking if Facebook <em>should</em> work or not on a particular case. Most possibly due to language barrier/misunderstanding (note: I'm not a native English speaker), I read the question as a moral question (\"is it right/wrong if FB is not doing this?\") or a company's policy question (\"does FB do this?\"), which is certainly off-topic on this site, because <em>the core question</em> is not related to AI at all.</p>\n\n<p>This is an example case of <a href=\"https://meta.stackexchange.com/q/14470/241919\">\"boat programming\"</a>, i.e. just because Zuckerberg stated that FB's \"Safety Check\" is done by AI, doesn't mean this question is automatically on-topic on AI.SE.</p>\n\n<hr>\n\n<p>After the back-and-forth comments on this meta question and <a href=\"https://ai.meta.stackexchange.com/revisions/1495/2\">the revision to it</a>, looks like the real question is</p>\n\n<blockquote>\n  <p>I asked about the fact of if a user [currently stuck on checkpoint] still gets safety notifications.</p>\n</blockquote>\n\n<p>This is a clear question about <em>the current policy of Facebook</em>. While this is off-topic on AI.SE, this looks like on-topic on WebApps.SE based on their meta discussion: <a href=\"https://webapps.meta.stackexchange.com/q/97\">Are questions regarding website policies on-topic?</a></p>\n\n<p>Apparently, you have <a href=\"https://webapps.stackexchange.com/questions/103217/will-facebook-safety-check-work-if-my-account-is-stuck-at-a-checkpoint-page\">posted the question on WebApps.SE</a> before posting here, but it's been deleted, and according to you, you got angry comments. I believe the core question is on-topic on WebApps.SE, but perhaps the wording gave the readers wrong impression. While I can't see deleted posts on there (so I won't judge anything), the correct place to discuss and request for feedback on how to improve your question is on their meta site, <a href=\"https://webapps.meta.stackexchange.com/\">Web Applications Meta</a>.</p>\n"}, "1500": {"ParentId": 1499, "Score": 2, "Body": "<p>I remember that one, and the first thing I did was edit the question to make the wording more suitable.</p>\n\n<p>So \"Why are AI models so racist and how can we actually reverse this?\" became \"How is it that AI can become <em>biased</em>, and what are the proposals to mitigate this?\"</p>\n\n<p>Now, if this had been a question about chatbot Tay, racism would have been the relevant term, because there it's not statistical bias, but an algorithm learning and replicating racist human behavior in an NLP context.</p>\n\n<p>In terms of answers, we need to clarify the issue or method or application, in service of disambiguation, demystification and demythification.  </p>\n\n<hr>\n\n<p>Bear in mind we are likely to only see questions on issues of algorithmic bias increase\u2014it is a major issue, involving data and statistics.  (Neo-luddism seems to be rearing it's head in that the effects reported on are initially unforeseen.)  </p>\n\n<p>If we're not lucky as a society, we are likely to also get increasing questions about procedurally generated racism.  Malicious bot activity in relation to politics I suspect will only ever increase. </p>\n"}, "1503": {"ParentId": 1487, "Score": 2, "Body": "<p>I was about to post to Meta about something similar, so I'm glad I discovered this question first. I also have some concerns about content quality. These concerns are due to what I consider systematic weaknesses rather than specific posts. </p>\n\n<p>Because this community is so small, there's less of a reason to trust the upvote count as a measure of answer quality. To combat this, it might be worth considering requiring answers to cite sources. </p>\n\n<p>This might be a bit harsh, though. I'm a new member of the community and probably not aware of many of the friendlier ways of incentivizing behavior. However we accomplish it, I think we should rely less on upvote count to measure answer quality. </p>\n"}, "1504": {"ParentId": 1448, "Score": 1, "Body": "<p>I also think every RL question should be on-topic here. Funnily enough, I've been flagging posts for migration to DataScience or CrossValidated according to the <a href=\"https://ai.stackexchange.com/help/on-topic\">help page</a> that defines what is off-topic. But it seems like not everyone really abides by those definitions! I regularly see both implementation and mathematics questions here, related to RL and otherwise. I've stopped flagging these questions because I enjoyed reading and answering them.</p>\n\n<p>So. If no one wants to abide by our current definition of 'on-topic' (including me), we should change it, right?</p>\n"}, "1507": {"ParentId": 1506, "Score": 4, "Body": "<p>I agree strongly and think this is necessary, especially now that we're getting a good number of questions, and need to raise out stats on having multiple answers.</p>\n\n<p>2 suggested additions:</p>\n\n<ul>\n<li><p>Clear guidance on when to ask on Data Science and Overflow.</p></li>\n<li><p>\"Social impacts\" as a separate sub-category</p></li>\n</ul>\n\n<p>re: social impacts, I think it's distinct from philosophy, because it deals with tangible effects.  It would also cover \"mythology of AI\" (singularity, robot takeover, etc.) and \"AI journalism\", which I think is an increasingly important topic--policing misleading reporting.</p>\n"}, "1509": {"ParentId": 1506, "Score": 4, "Body": "<p>I mostly agree with the guidelines for on-topic topics proposed in the OP. The only possibly gray area for me is in this:</p>\n\n<blockquote>\n  <p>Furthermore, I would say that every implementation-related question should always be considered off-topic here, given that there's already Stack Overflow (and Data Science SE) for this.</p>\n</blockquote>\n\n<p>Now in most cases I do agree implementation-only questions are better suited for StackOverflow (especially Tensorflow ones, since Stackoverflow is the official place for Tensorflow questions). However, a recent implementation question that I feel like may be better suited here was this one:</p>\n\n<p><a href=\"https://ai.stackexchange.com/q/11433/1641\">Expressing Arbitrary Reward Functions as Potential-Based Advice (PBA)</a></p>\n\n<p>It technically is just an implementation / bugfixing question, which I'd usually feel like should be off-topic... but it is about a rather specific, non-trivial, relatively recent AI publication. I was personally already familiar with the paper (maybe because I spent a couple of years working in the same lab that these publications came from earlier, with some of the same people), but I think very few people on StackOverflow would be familiar with the paper or feel like reading it just to make sure they'd be able to answer the question correctly.</p>\n\n<p>Would such implementation questions about very specific, relatively uncommon approaches still be considered on-topic here? I'm not talking about common stuff, like implementing \"Neural Networks\" or \"an image classifier\", plenty of people on SO know about that too.</p>\n"}, "1513": {"ParentId": 1510, "Score": 1, "Body": "<p>Personally I don't mind the softball questions that could have been answered with a Google search because I feel SE:AI can add context to a Wikipedia entry, and I think we should be the #2 result for that stuff, behind Wikipedia but certainly ahead of Quora.  (Drives traffic to our site and potentially expands our user base.)</p>\n\n<p>Regarding the other stuff, I think we need more voting in general, both up and down!</p>\n"}, "1519": {"ParentId": 1518, "Score": 4, "Body": "<p>My feeling is this should be addressed by voting since Quora is no more commercial than Stack (limited ads,) thus such links don't constitute spam.</p>\n\n<p>I do see Stack &amp; Quora in competition, although I hope Stack will ultimately prevail in terms of search rankings.  (US Alexa ranking for Stack is 115 worldwide and 65 in the US, vs. 78/47, so we're not quite there yet.)</p>\n\n<p>But, in some sense, both sites have the same mission, if Stack seems to to a better job because of our voting system.  </p>\n"}, "1521": {"ParentId": 1520, "Score": 3, "Body": "<p>Looking at it, it looks like the OP didn't realise how user accounts work, or how the site works, so created a new account and a new post in order to be able to interact with the post.</p>\n\n<p>I have flagged for the posts and the user accounts to be merged.</p>\n\n<p>It's not a major issue - on a small site with few active members things like this happen, just vote to close as dupe or flag if necessary.</p>\n"}, "1522": {"ParentId": 1518, "Score": 4, "Body": "<p>I think it's fine, right? As long as it's not just a link, but there is some explanation surrounding it. Referencing things that have been written elsewhere seems to be very much preferable to... copying without attribution?</p>\n\n<p>Sometimes in my answers I'll reference papers which I'm an author on myself. I don't think that's really different in any tangible way?</p>\n"}, "1523": {"ParentId": 1518, "Score": 4, "Body": "<p>I raised the flag, since it was the second time OP posted link to quora answer written by the OP. IMO referring to one's blog is ok, but referring frequently is not ok. Also it is not much hard to copy paste from the blog and at the end attribute it to the blog (both the answers did not involve any technical or Math details), so it does not make sense not to do it.</p>\n\n<p>Also since the user was new I did not want to comment wrongly on what's accepted and what's not in this stack, so I just thought moderators will do a better job.</p>\n"}, "1525": {"ParentId": 1524, "Score": 1, "Body": "<p>I introduced this tag because ACO is a well developed sub-field of swarm intelligence, so it deserves (IHMO) its own tag, like e.g. reinforcement learning deserves its own tag (compared to machine learning) on a website dedicated to AI.</p>\n\n<p>I used <a href=\"https://ai.stackexchange.com/questions/tagged/ant-colony\" class=\"post-tag\" title=\"show questions tagged &#39;ant-colony&#39;\" rel=\"tag\">ant-colony</a> because it is shorter and there's no ambiguity in the field of AI. Furthermore, a lot of people do not refer to these algorithms as \"ACO\", but e.g. as \"ant colony system\" or just \"ant colony algorithms\". I would argue that <a href=\"https://ai.stackexchange.com/questions/tagged/ant-colony\" class=\"post-tag\" title=\"show questions tagged &#39;ant-colony&#39;\" rel=\"tag\">ant-colony</a> is a more general tag and expression.</p>\n\n<p>Furthermore, several questions on ACO have already been asked on the website.</p>\n"}, "1526": {"ParentId": 1524, "Score": 0, "Body": "<p>Wondering if we should maybe just have a general tag for \"ant-intelligence\" that could cover all aspects, including swarm intelligence, engineering (tunnel building) and path finding..</p>\n"}, "1528": {"ParentId": 1527, "Score": 1, "Body": "<p>To be safe, I would remove the link / replace it with the official (non-PDF) link. </p>\n\n<p>I don't know what IEEE's policy was back in 2008 (which is when this particular paper was published), but I am familiar with their policy in more recent years (since I've got some recent IEEE papers myself). Basically, all copyright is transferred to IEEE, but in return IEEE gives a few rights/privileges back to the authors. </p>\n\n<p>This boils down to that the authors of the paper are also allowed to put certain versions of their paper (not the final published version as it appears in journal/proceedings) on their own personal homepage, or on something like arXiv (I'm not sure if arXiv was always allowed, but it is allowed recently). They do not permit publishing just anywhere though, and also certainly don't permit people who are not the original authors to distribute it wherever they like.</p>\n\n<p>If the authors of this paper had published the pdf on their own homepages for example, we could've easily linked to that... but that does not appear to be the case here as far as I can tell. So, somewhere along the line it looks like copyright is being violated. I don't think the violation is necessarily on this site (since we just have a link to a different place, and the distribution over there on that site is the violation)... but probably better to remove it anyway.</p>\n"}, "1529": {"ParentId": 1518, "Score": 1, "Body": "<p>Quora has login popup which often prevent reading answer. In my opinion it's definitely not OK to reference  Quora.</p>\n"}, "1531": {"ParentId": 1530, "Score": 2, "Body": "<p>I believe that, in an academic setting, this would be considered plagiarism, even though you cite or attribute it. If we accept this type of answers, we might encourage users do it again (which would not bring anything new to the web) or to adopt this strategy to easily increase their reputation.</p>\n\n<p>So, I am against this type of answers (especially, if the author of the answer is not the author of the cited article).</p>\n"}, "1535": {"ParentId": 1534, "Score": 1, "Body": "<p>I also think that this type of questions should be closed as off-topic and, anyway, they will lead to primarily opinion-based answers. However, we have already a lot of these questions on the website.</p>\n\n<p>I think that the quality of the answers should be assessed using the voting system. If someone does not agree with the suggestions, then he/she should downvote the answer (and possibly leave a comment in order to encourage the answerer to improve his/her answer). Furthemore, it is the reponsibility of the asker to accept or not an answer. In general, the web is full of misleading and incorrect information, so it is the responsibility of the web surfer to select or not any information.</p>\n"}, "1539": {"ParentId": 1440, "Score": 0, "Body": "<p>Natural language <em>by itself</em> (that is, without considering computation-related aspects) has little to do with AI. In AI, we want to do NLP, which can be based on natural language, but the tag <a href=\"https://ai.stackexchange.com/questions/tagged/natural-language-processing\" class=\"post-tag\" title=\"show questions tagged &#39;natural-language-processing&#39;\" rel=\"tag\">natural-language-processing</a> or <a href=\"https://ai.stackexchange.com/questions/tagged/nlp\" class=\"post-tag\" title=\"show questions tagged &#39;nlp&#39;\" rel=\"tag\">nlp</a> should also include these related discussions or questions. So, the tag <a href=\"https://ai.stackexchange.com/questions/tagged/natural-language\" class=\"post-tag\" title=\"show questions tagged &#39;natural-language&#39;\" rel=\"tag\">natural-language</a> should not really exist.</p>\n"}, "1540": {"ParentId": 1216, "Score": 1, "Body": "<p>I think that \"deep learning\" is already a standard expression, so this tag should be the main tag. The tag <a href=\"https://ai.stackexchange.com/questions/tagged/deep-network\" class=\"post-tag\" title=\"show questions tagged &#39;deep-network&#39;\" rel=\"tag\">deep-network</a> could also exist on this website, given that the expression \"deep neural network\" is also common, but I would not say that it is a synonym for <a href=\"https://ai.stackexchange.com/questions/tagged/deep-learning\" class=\"post-tag\" title=\"show questions tagged &#39;deep-learning&#39;\" rel=\"tag\">deep-learning</a>. A deep network is a network that is deep (that is, it possesses \"many\" layers). However, deep learning is not just concerned with the architecture of the NNs, but it also concerned with the <em>learning</em> part.</p>\n"}, "1542": {"ParentId": 1541, "Score": 2, "Body": "<p>Have a look at the source of this answer</p>\n\n<p><span class=\"math-container\">$$\\underset{\\boldsymbol{\\theta}}{\\operatorname{argmax}}$$</span></p>\n"}, "1548": {"ParentId": 1544, "Score": 1, "Body": "<ul>\n<li>Sentience can refer to biological agents, so has a broader scope.  </li>\n</ul>\n\n<p>We sometimes discuss intelligence in general, as a concept underlying AI, and do too with sentience.</p>\n\n<ul>\n<li>Emotional intelligence seems to be an informal term related to a specific kind of decision making</li>\n</ul>\n\n<p>I don't see much relation to sentience in general, except that we regard only sentient beings as having emotions in the conventional sense.</p>\n"}, "1549": {"ParentId": 1545, "Score": 1, "Body": "<p>Self-awareness has a lot of usage in general, and I don't think it's entirely synonymous.  Consciousness, in the most basic definition, is merely awareness of an environment.  </p>\n\n<p>Additionally, non-artificial intelligences (humans) have self-awareness.  So it's useful to be able to distinguish.</p>\n"}, "1550": {"ParentId": 1546, "Score": 2, "Body": "<p>I created a soft-question tag, but people don't seem to like using it. But just because a question is \"soft\" doesn't mean it's invalid--many of the hard science sites have the tag, which was what inspired me to add it here.</p>\n\n<p>I don't know if this is fully sufficient, but at least part of the solution.</p>\n"}, "1552": {"ParentId": 1551, "Score": 4, "Body": "<p>According to <a href=\"https://area51.stackexchange.com/proposals/93481/artificial-intelligence\">our Area 51 page</a>, we entered public beta on August 22, 2016, nearly three years ago.</p>\n<p>90 days may indeed have been the cutoff in the early days of Area 51-launched Stack Exchange sites, prior even to that post. The post opens with it because users of one small site were concerned about getting shut down at that mark. It reassures those users that graduation could take longer:</p>\n<blockquote>\n<h3>How long can a site stay in beta?</h3>\n<p>The simple answer is, <em>it takes as long as it takes</em>. We\u2019ll wait. If a site needs more activity, go out and evangelize it. As long as your site shows steady progress and continues to make the Internet a better place to get expert answers to your questions, it will march on.</p>\n</blockquote>\n<p>More recently (in 2015) there was <a href=\"https://meta.stackexchange.com/q/257614/295684\">a Meta Stack Exchange announcement</a> with more specifics:</p>\n<blockquote>\n<p>The TL;DR:</p>\n<ol>\n<li><strong>When a site starts to consistently receive 10 questions/day, we\u2019ll consider it for graduation.</strong></li>\n<li><strong>If a public beta site does not produce consistently helpful content, and lacks the caretakers needed for flags and spam to get handled and our Be Nice policy to be upheld, it will be closed.</strong></li>\n</ol>\n</blockquote>\n<p>We are not at risk of closure, so we'll definitely stick around in some form (<a href=\"https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sites#comment840165_257614\">perpetual beta is possible</a>). According to the Area 51 stats, we get about 7.5 questions per day, so we're making progress toward graduation eligibility. Graduation includes privilege threshold adjustments, which we <em>could</em> survive now, but without any 10K users it's probably ideal to hold off for a while.</p>\n<p>The sketched graph in <a href=\"https://meta.stackexchange.com/a/227016/295684\">this MSE answer</a> visually shows &quot;a typical growth pattern for a Stack Exchange site.&quot; Eyeballing our current site analytics, we seem to be at the halfway mark between the sketch's start of public beta and graduation.</p>\n"}, "1553": {"ParentId": 1547, "Score": 1, "Body": "<p>I propose the following new description to make this tag more broadly applicable</p>\n\n<blockquote>\n  <p>For questions related to designing standards and procedures of intelligent agents, algorithms or models.</p>\n</blockquote>\n"}, "1555": {"ParentId": 1554, "Score": 1, "Body": "<p>Similar situations and issues to the one you describe sometimes happen. It occurred to me that I downvoted a post and I left a comment. Moments later some of my posts were randomly downvoted (see e.g. <a href=\"https://ai.meta.stackexchange.com/q/1468/2444\">Taking revenge on me because I publicly downvoted and commented</a>). Nonetheless, I believe that downvotes (and upvotes) should have a <strong>mandatory</strong> associated comment that motivates the downvote, in a similar fashion to the peer-review process that research papers need to go through. This feature or similar ones have been requested by several members of the SE community.  See e.g. these discussions <a href=\"https://meta.superuser.com/q/7223\">https://meta.superuser.com/q/7223</a> or <a href=\"https://meta.stackexchange.com/q/135/287113\">Encouraging people to explain downvotes</a>.</p>\n"}, "1558": {"ParentId": 1557, "Score": 2, "Body": "<p>First of all, I think this question has attracted a lot of people because it is about neural networks, which is a \"hot topic\" nowadays, and an issue that neural networks face. Given that a lot of people use and like neural networks and were not aware of this issue, people are probably interested in knowing about this problem and how to solve it.</p>\n\n<p>Furthermore, I think the original title of this question, <em>A flaw with nerual networks?</em>, would not have attracted so many people. I realized that the author of such post, to some extent, was asking about the catastrophic forgetting (or inference) of neural networks, so I changed the title to the current one (which is quite descriptive), which I think I has contributed to the current popularity of the question, given that it contains the known (and maybe mnemonic) technical expression \"catastrophic forgetting\". In general, I have been trying to edit questions, so that to improve their titles and make them more descriptive, which I think can potentially attract more people. The title <em>A flaw with nerual networks?</em> is not very descriptive, because neural networks might have many flaws. So, I encourage every user to edit questions to make their titles more descriptive of the actual problem.</p>\n\n<p>The given answers are also not very technical or long, so they are accessible or understandable by anyone in the field. Hence we should also strive for simplicity, when possible!</p>\n\n<p>There are other questions that I think should have received a lot more attention and upvotes (for example, <a href=\"https://ai.stackexchange.com/q/13317/2444\">Where can I find the proof of the universal approximation theorem?</a>), but I don't know how exactly Stack Exchange tags a question as a \"hot\" (and maybe this is just my opinion).</p>\n"}, "1560": {"ParentId": 1559, "Score": 3, "Body": "<p>If we want to accept all or most questions that are related to AI and are also on-topic on the Data Science SE, Cross Validated SE, and Stack Overflow websites, then we'd better just merge the websites. We <strong>focus</strong> on the theoretical and philosophical aspects of AI, but I would not say that all implementation-related questions are off-topic here (but <strong>we need to define precisely which ones can be on-topic</strong>, which has not yet been done, AFAIK). However, questions that involve the debugging of source code (like &quot;Why am I getting this TypeError in this machine learning program?&quot;) should be considered off-topic, because there is already Stack Overflow for these. AFAIK, this website was created because there wasn't yet a website dedicated to the philosophical (and, partially, theoretical) aspects of AI.</p>\n<p>(There are a lot of questions on Stack Overflow, Data Science SE and Cross Validated SE that would be better asked here, including some of the questions I had asked there. For example, <a href=\"https://datascience.stackexchange.com/q/26938/10640\">What exactly is bootstrapping in reinforcement learning?</a>. I remember I had asked it there because, at the time, I had almost no hope in this website and I thought it would not have had a future, given the number of poor questions and answers that I used to see and the small number of competent regular users. I suppose that, if I had asked that question on this website, it would not have received so much attention. There are still users on this website that degrade its quality, because they do not follow the SE standards or because they are just trolling. Furthermore, I think that moderators on this website are too slow and are hesitant to take action regarding certain questions that are not compliant with the supposed goal of the website. For example, there are a lot of broad questions on this website, which could have been avoided, if we had more active moderators that follow the rules. During this year, I've invested a lot of time on this website, so I believe that, in general, the quality of the website (answers and questions) has increased (but this is just my perception of the situation). By the way, I believe that this website still lacks more competent people in certain areas, such as geometric deep learning, POMDP, hierarchical RL, swarm intelligence, etc. People that give good answers on this website are the usual suspects. We need more diversity and perspectives.)</p>\n<p><em>Which implementation-related questions should be on-topic here?</em> I believe that this is a question that should be asked on this meta (if it wasn't already asked). In any case, I believe we should still focus on the theoretical and philosophical aspects of AI. If you also like to answer questions related to implementation issues, then you'd better <strong>also</strong> use other dedicated websites, such as Stack Overflow and Data Science.</p>\n<blockquote>\n<p>From there, there exist 2 types of people: The ones who are complacent with what they achieved (by just using others' code on their data) or the ones that start to think, How does this work?, or how could I adjust this to also do that?</p>\n<p>The latter people I feel are definitely a category of people this site wants to attract (if I've understood this site's purposes correctly). Through implementation, they are trying to understand the process. I understand the counter-claim to this is that questions should be generalized to try to assist as many people as possible, but the number of people this category would invite would make up for this difference (I have no proof/ pure speculation)</p>\n</blockquote>\n<p>There is Data Science SE for these people. However, maybe some implementation-related questions that also involve theoretical or philosophical aspects could also be on-topic here. For example, &quot;How is this concept usually implemented?&quot;.</p>\n"}, "1564": {"ParentId": 1561, "Score": 2, "Body": "<p>Since this question is unanswered for a week now, I would like to contribute a suggestion.</p>\n\n<p>Questions that are <a href=\"https://ai.stackexchange.com/help/on-topic\">on-topic</a> on the AI SE include the theory/concepts of AI, social issues, and so on. Questions regarding the implementation of algorithms are definitely off-topic.</p>\n\n<p>I suggest the community should be allowed to discuss the theory and the theoretical concepts of algorithms that have a high likelihood of being used in an unethical way as long as the discourse stays purely theoretical. Questions regarding the implementation, or the application of such algorithms should be flagged as off-topic (what they actually are) and closed. These questions should be treated more strictly (when in doubt, close them) since they are not only probably off-topic but also have a higher probability of being used with unethical intentions.</p>\n\n<p>That means, a question like <a href=\"https://ai.stackexchange.com/questions/13784/how-to-make-deepfake-video-without-a-fancy-pc\">How to make deepfake video without a fancy PC?</a> should be closed and a question like <a href=\"https://ai.stackexchange.com/questions/13260/what-are-the-differences-between-deepfakes-faceswap-and-face2face\">What are the differences between Deepfakes, FaceSwap and Face2Face?</a> should be left open.</p>\n\n<p>An open issue is still where to draw the line. I think this has to be evaluated on a case by case basis. In the end, questions about the implementation of an algorithm are off-topic anyways.</p>\n"}, "1569": {"ParentId": 1568, "Score": 2, "Body": "<p>Yes, there are restrictions. For example, you cannot delete a question with more than one answer or with an upvoted or accepted answer. See <a href=\"https://meta.stackexchange.com/q/5221/287113\">How does deleting work? What can cause a post to be deleted, and what does that actually mean? What are the criteria for deletion?</a> for more info. Apparently, your answer wasn't upvoted. </p>\n\n<p>Regarding the \"block a user\" feature, see <a href=\"https://meta.stackexchange.com/q/3353/287113\">Add the ability to ignore users</a>.</p>\n\n<p>I understand your feelings now, given that you spent time to provide a good answer and information. However, I would advise you not to give much importance to this episode. It may happen, but this usually does not happen!</p>\n"}, "1574": {"ParentId": 1573, "Score": 1, "Body": "<p>I believe that only questions and answers that have been edited by multiple users and that no longer resemble the original question or answer, respectively, should be made community wiki, given that the upvotes or downvotes are no longer only associated with or attributed to the user that originally posted the answer or question. For example, this answer <a href=\"https://ai.stackexchange.com/a/8688/2444\">https://ai.stackexchange.com/a/8688/2444</a> should be made a community wiki, given that its current version and quality is due to multiple users.</p>\n<p>In the article <a href=\"https://stackoverflow.blog/2011/08/19/the-future-of-community-wiki/\">The Future of Community Wiki</a>, it is stated in the section <strong>Community Wiki is not a &quot;Quick Fix&quot;</strong></p>\n<blockquote>\n<p>Many sites propose using community wiki to allow content that is on-topic and useful, but can be considered borderline or questionable in other ways. Someone notes that a certain class of question has problems, and proposes using community wiki as a quick fix.</p>\n<p>If a question is valuable enough that you believe it belongs on the site, chances are you don\u2019t need it to be community wiki! We welcome all contributions which improve the quality of a site and advertise its greatness to the rest of the world. If you allow a certain class of questions, but only under the stipulation that no one can earn reputation from them, you\u2019ve strongly discouraged these sorts of questions. People aren\u2019t going to put in nearly as much effort to ask them.</p>\n<p><strong>Instead, strive for quality. If you're unsure a certain question class belongs on the site, don't tolerate the worst examples \u2014 demand that these questions be awesome. Questions shouldn\u2019t be swept under the rug with community wiki; they should get the same respect and treatment as the rest of your Q&amp;A. If those questions are something you are uncomfortable showing to visitors \u2026 they probably don\u2019t belong on your site</strong>.</p>\n<p>Many things which &quot;need&quot; to be community wiki simply don't. Sometimes it\u2019s just a matter of understanding the root of a question: <strong>&quot;Software to record video games&quot; can be turned into a great question without needing the crutch of community wiki. Or, you may need to break the original question into smaller parts</strong>; a rather well-timed Ask Different Meta post explores this very avenue.</p>\n</blockquote>\n<p>Hence, the question <a href=\"https://ai.stackexchange.com/q/15594/2444\">What are all the different kinds of neural networks used for?</a> should probably be closed as too broad. However, given that I edited the post to include &quot;I just need a brief overview (1-2 lines) of their applications.&quot;, the scope has been slightly limited. So, at this point, more than one user has contributed to the quality and current version of the question, so maybe it should be made a community wiki (according to my belief above).</p>\n<p>In the section <strong>Community Wiki is primarily for Answers</strong> of the same article</p>\n<blockquote>\n<p><strong>If we haven\u2019t said this enough already, questions rarely, if ever, need community wiki</strong>. What about answers? We removed the ability for users to make a question community wiki, but left the ability for users to make an answer wiki.</p>\n<p>The intent of community wiki in answers is to help share the burden of solving a question. An incomplete \u201cseed\u201d answer is a stepping stone to a complete solution with help from others; an incomplete question is a hindrance and an obstacle to getting a solution as no one understands the inquiry. It is in answers that the goal of community wiki, for the community, by the community, shows its truest colors.</p>\n<p>Yet even in answers, true collaboration is scarce. Most of the time, a single individual can provide a complete answer. There are even times where a question looks like it\u2019ll need a massive effort, but one gallant user steps up to the plate with an impressive and comprehensive answer.</p>\n</blockquote>\n<p>See also <a href=\"https://meta.stackexchange.com/q/11740/287113\">What are &quot;Community Wiki&quot; posts?</a>.</p>\n"}, "1575": {"ParentId": 1570, "Score": 2, "Body": "<p>This website should rarely need this feature, given that we are mainly concerned with theoretical and philosophical AI questions. Most implementation-related questions are off-topic here. You can ask them on Data Science SE or Stack Overflow. See <a href=\"https://ai.stackexchange.com/help/on-topic\">Help Center > Asking > What topics can I ask about here?</a>. </p>\n"}, "1577": {"ParentId": 1576, "Score": 1, "Body": "<p>My main thought is that we've been seeing requests for data sets to use in training, and these would represent resource requests as opposed to reference requests.</p>\n\n<p>Similarly for people looking for published code to utilize (GitHub as a resource.)</p>\n"}, "1585": {"ParentId": 1584, "Score": 3, "Body": "<p>There are several problems. Some of them have already been raised but not addressed.</p>\n\n<ol>\n<li><p>Too broad questions (or posts with multiple questions) are not closed (immediately). See <a href=\"https://ai.meta.stackexchange.com/q/1536/2444\">Why aren&#39;t too broad questions closed?</a>.</p></li>\n<li><p>Too many duplicate questions, which are not marked as duplicate. See <a href=\"https://ai.meta.stackexchange.com/q/1532/2444\">What should we do regarding extremely similar questions or duplicates?</a>.</p></li>\n<li><p>The on-topic and off-topic pages of the site are not clear enough. See <a href=\"https://ai.meta.stackexchange.com/q/1506/2444\">On-topic and off-topic pages need to be clarified</a>. </p></li>\n<li><p>In general, new users should have a clear idea of the most appropriate website to ask a question (among AI SE, Data Science SE, Stats SE, and Stack Overflow), but this has not yet been clarified.</p></li>\n<li><p>It is still unclear which implementation-related questions are on-topic.</p></li>\n<li><p>Too many tags that should not exist because they are not directly or strictly related to our scope. See <a href=\"https://ai.meta.stackexchange.com/q/1538/2444\">On the management of tags on this website</a>. In general, if a question mentions e.g. a certain concept or tool, it does not mean that an associated tag needs to be created. For example, it makes sense to have a tag associated with ant-colony optimization (given that this is a theoretical AI topic), but it makes no sense to have a tag like <a href=\"https://ai.stackexchange.com/questions/tagged/accessibility\" class=\"post-tag\" title=\"show questions tagged &#39;accessibility&#39;\" rel=\"tag\">accessibility</a> (which is extremely vague and general). In general, only tags that are associated with common concepts should exist. We shouldn't create a tag for every possible concept or tool. </p></li>\n<li><p>Some users that (constantly) provide out-of-context and poor answers. These answers often look like spam, so they degrade the quality of the website.</p></li>\n<li><p>Currently and generally, moderators are often not very active, responsive and strict enough. </p></li>\n<li><p>There's a need for more competent people in certain areas. It seems that the usual suspects tend to answer to almost all questions. We need more diversity and competence.</p></li>\n</ol>\n"}, "1591": {"ParentId": 1538, "Score": 2, "Body": "<p>It's telling that it's much easier to create tags than remove them, and I have to wonder if this is intentional or just a fail-safe, to avoid untagged questions.</p>\n\n<p>I like tags in general because they allow degrees of specificity.  For instance, most of our questions involve machine learning, but in relation to what?  </p>\n\n<p>That said, there is a lot to digest in your post and I am still going through it, so I don't have any specific response at this time, other than to note that Bayes is a good example. </p>\n"}, "1593": {"ParentId": 1592, "Score": 2, "Body": "<p>Career advice may currently be off-topic, but, more importantly, it leads to primarily opinion-based answers and related questions can be too broad. For example, to answer the question \"What classes to take to get this job?\" satisfactorily, we need to know the background of the user, his (or her) location (because certain job titles may differ from place to place), etc., and the answers to such a question can become obsolete very rapidly.</p>\n\n<p>Personally and generally, I am not against this type of questions, but they usually lead to poor answers. I think we should <strong>NOT</strong> broaden our scope only to increase the activity of our website, at the expense of a possible degradation of the quality of the questions and answers, which, in my opinion, and qualitatively, isn't already very high. We do NOT necessarily have to be big. We just need to find our place among all other SE websites and try to focus on doing our job well.</p>\n\n<p>To conclude, in my opinion, <strong>career advice</strong> should be <strong>OFF-TOPIC</strong>. However, questions that ask for <strong>facts</strong> (rather than opinions) can be on-topic.</p>\n"}, "1597": {"ParentId": 1592, "Score": 2, "Body": "<p>I would not be opposed to making this kind of advise on topic. I think @nbro makes some good points too though. My suggestion is that we experiment with allowing this kind of question, subject to the following provisos:</p>\n\n<ol>\n<li>Questions must be of the form \"What is the ideal academic background for someone who wants to work in <em>AI Specialty X</em>.</li>\n<li>Questions must not be duplicates or near duplicates.</li>\n<li>Questions must be about general job titles, not positions at specific companies (that would be speculative).</li>\n<li>Questions must be accompanied by examples of job postings from at least two specific companies (so that we don't get made-up titles, which we otherwise will).</li>\n</ol>\n"}, "1600": {"ParentId": 1598, "Score": 4, "Body": "<p>AI has always been an interdisciplinary field. It therefore should not surprise us that AI.SE's content overlaps with that of other established stacks. I think this is essentially okay.</p>\n<p>Perhaps as an analogy: The SoftwareEngineering.SE allows programming questions, but not of the same flavor as the StackOverflow main site. If you want to know <em>how to do X in language Y</em>, you visit StackOverflow. If you want to know <em>whether to do X using language Y</em>, you are better off asking on SoftwareEngineering.SE</p>\n<p>If you want to know <em>how</em> to train a deep neural network in Python, you should visit DataScience.SE. If you want to know <em>whether</em> to train a deep neural network in Python (or, use any of the other various approaches in AI), you should visit AI.SE.</p>\n<p>I think this means that a tag-based approach is the wrong one. We are likely to have questions that are about, say, statistical learning theory. This is part of AI. It is <em>maybe</em> part of Data Science, but I'd say it's a stretch. It is <em>maybe</em> part of statistics, but certainly not conventional statistics. It is definitely part of AI, and has been a core part for decades. Nonetheless, it encapsulates topics like support vector machines that <em>are</em> widely used in Data Science. We, therefore, oughtn't to outlaw the SVM tag. I think the same kind of argument can be used for most or all duplicate tags.</p>\n<p>I'm especially concerned to see the <code>machine-learning</code> tag highlighted in the duplicates. Modern AI without machine learning is... not much.</p>\n<p>I think if we focused only on the tags that are not present on other websites, we will not be able to claim to be about AI, and the site would (and perhaps should) then cease to exist. I think we'll do much better if we instead focus on claiming the <em>why</em> space.</p>\n"}, "1603": {"ParentId": 1602, "Score": 6, "Body": "<p>I'm interested in running for a moderator position.</p>\n"}, "1604": {"ParentId": 1602, "Score": 0, "Body": "<p>Thank you for writing to us about this. This isn\u2019t our final response here, but in the interest of being transparent and keeping lines of communication open,<strong><em>I myself, have been yearning for this mod - position for a long period of time.</em></strong>\nTherefore, with all my interest and the inner driving force, I'm running for this! I should even be hesitated for it. </p>\n\n<p>Thanks once again for being informed. Keep us posted of any updates.</p>\n"}, "1606": {"ParentId": 1602, "Score": 7, "Body": "<p>I am happy to run, especially if there is a shortage of candidates, although I think I am not the best candidate for the job.</p>\n"}, "1607": {"ParentId": 1605, "Score": 2, "Body": "<p>I agree we don't require the tag 'concepts'. But a quick Google search shows there is some <a href=\"https://www.google.com/amp/s/www.researchgate.net/post/What_are_the_differences_between_conceptual_framework_and_theoretical_framework/amp\" rel=\"nofollow noreferrer\">difference</a> between a Conceptual and Theoretical framework. So either the 'concepts' tage need to be redefined, or a new more detailed/self-explanatory tag name needs to be created.</p>\n\n<p>Although, it is debatable whether users will adhere to such narrow difference of definition to sort questions and answers.</p>\n"}, "1608": {"ParentId": 1602, "Score": 3, "Body": "<p>I would be interested in running. Though, I must say that the first two members that came to mind as the top candidates have already stated that they are interested. </p>\n"}, "1613": {"ParentId": 1612, "Score": 1, "Body": "<blockquote>\n  <p>since we're the general AI forum</p>\n</blockquote>\n\n<p>We are not a general AI forum. This forum supposedly exists to fill a certain gap. As stated <a href=\"https://ai.meta.stackexchange.com/a/1144/2444\">in this answer</a></p>\n\n<blockquote>\n  <p>It's because the OPPOSITION against creating this site argued (<strong>correctly</strong>) that we already created sites to handle this subject explicitly. The argument FOR creating this site claimed that we have a missing socio-scientific angle that needed filling.</p>\n</blockquote>\n\n<p>I believe that ALL implementation questions, such as \"Can you explain the parameters of this ML program?\", \"Why isn't my ML program working?\" or \"How do you implement this model?\", are OFF-TOPIC. They would be on-topic, if we merged this site with Data Science (aka applied machine learning). Similarly, there are already sites for <a href=\"https://hardwarerecs.stackexchange.com\">hardware</a> and <a href=\"https://softwarerecs.stackexchange.com\">software</a> (which already has the tag <a href=\"https://softwarerecs.stackexchange.com/questions/tagged/artificial-intelligence\">ai</a>) recommendations. There is absolutely no need for duplicating services, which are available somewhere else. </p>\n\n<p>Therefore, I strongly suggest we focus on the social, scientific and theoretical aspects of AI, otherwise, we'd better just merge this website with other websites. Do we want to have a website that 95% overlaps with another website only because people disagree on the meaning of the expressions \"artificial intelligence\" (or \"machine learning\") and \"data science\"? There are so many theoretical questions that have not yet been asked. For example, there could be a lot of questions on <a href=\"https://ai.stackexchange.com/questions/tagged/aixi\">AIXI</a>, which is a highly mathematical and theoretical topic (that is, a perfect topic for this site), which is not easily understandable, so I would expect a lot more questions, but we only have 2 questions. </p>\n\n<p>Unfortunately, this website has already taken the wrong direction, IMHO. We already have a bunch of implementation, hardware, and software-related questions, which is partially due to the fact that the community and moderators do not take action with respect to the original goals of the site, which has become quite redundant.</p>\n\n<p>However, there are also topics on other sites that would be better suited for this site, such as reinforcement learning on Stats. To conclude, apparently, there is a lot of duplication of services across sites. <strong>Maybe there should be a way of migrating even old questions from one website to the other, as a way of organizing better the communities</strong>. For example, there are a lot of theoretical ML questions on Stack Overflow, which could be migrated to this site or Stats.</p>\n"}, "1614": {"ParentId": 1611, "Score": 1, "Body": "<p>We had done a consensus-based edit last year: <a href=\"https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be\">What should the AI.SE Site Description be?</a>.</p>\n<p>(Essentially, a bunch of active users contributed to the thread, and then the edits were made by the active mods.  Although I was hoping for more people to participate, we had to go with the input and consensus we had at the time.)</p>\n<p>I do think this is something that should be revisited at regular intervals, especially since we are not fully graduated as a stack, and more flexibility in terms of modifying our scope.  (&quot;<a href=\"https://www.masslive.com/patriots/2017/11/the_2017_new_england_patriots.html\" rel=\"nofollow noreferrer\">Bend don't break</a>&quot; is my motto!)</p>\n<p>When we revisit again, I strongly think we should take a cue from the Data Science help page b/c they provide good advice about topic overlap between stacks: <a href=\"https://datascience.stackexchange.com/help/on-topic\">https://datascience.stackexchange.com/help/on-topic</a></p>\n<p>I also personally think we should expand our scope to reference</p>\n<ul>\n<li><p>Journalism (coverage of AI in the press per public perception and fact checking)</p>\n</li>\n<li><p>History of AI</p>\n</li>\n<li><p>Mythology of AI (portrayals of AI in popular media which informs public perception)</p>\n<p>and hold a referendum on other topics that contributors have chosen to answer over here, per the DS recommendation to &quot;ask on the stack with the most users.&quot;</p>\n</li>\n</ul>\n"}, "1616": {"ParentId": 1615, "Score": 2, "Body": "<h2>What topics can I ask about here?</h2>\n\n<p>If you have a question about <strong>theoretical, philosophical, social, historical</strong>, and certain <strong>developmental</strong> and <strong>academic</strong> aspects of artificial intelligence, then you are <em>probably</em> in the right place to ask your question!</p>\n\n<p>Below you can find a <em>non-exhaustive</em> list of specific topics that are considered on-topic here. Next to each topic, you have links to other stacks where the corresponding topics may also be on-topic.</p>\n\n<h3>Specific topics</h3>\n\n<p>You can ask a question about the <strong>theoretical</strong> aspects of the following sub-fields of artificial intelligence. </p>\n\n<ul>\n<li>Artificial general intelligence</li>\n<li>Affective computing</li>\n<li>Swarm intelligence</li>\n<li>Evolutionary algorithms (<a href=\"https://stats.stackexchange.com/help/on-topic\">1</a>, <a href=\"https://stackoverflow.com/help/on-topic\">4</a>, <a href=\"https://cs.stackexchange.com/help/on-topic\">6</a>)</li>\n<li>Machine learning (<a href=\"https://stats.stackexchange.com/help/on-topic\">1</a>, <a href=\"https://datascience.stackexchange.com/help/on-topic\">2</a>, <a href=\"https://stackoverflow.com/help/on-topic\">4</a>, <a href=\"https://cs.stackexchange.com/help/on-topic\">6</a>)</li>\n<li>Computational learning theory (<a href=\"https://stats.stackexchange.com/help/on-topic\">1</a>, <a href=\"https://cs.stackexchange.com/help/on-topic\">6</a>, <a href=\"https://cstheory.stackexchange.com/help/on-topic\">7</a>)</li>\n<li>Natural language processing and understanding (<a href=\"https://cs.stackexchange.com/help/on-topic\">6</a>)</li>\n<li>Computer vision (<a href=\"https://stats.stackexchange.com/help/on-topic\">1</a>, <a href=\"https://datascience.stackexchange.com/help/on-topic\">2</a>, <a href=\"https://stackoverflow.com/help/on-topic\">4</a>, <a href=\"https://cs.stackexchange.com/help/on-topic\">6</a>, <a href=\"https://dsp.stackexchange.com/help/on-topic\">10</a>)</li>\n<li>Knowledge representation and reasoning  (<a href=\"https://cs.stackexchange.com/help/on-topic\">6</a>)</li>\n<li>Robotics (<a href=\"https://robotics.stackexchange.com/help/on-topic\">5</a>)</li>\n<li>Planning (<a href=\"https://cs.stackexchange.com/help/on-topic\">6</a>)</li>\n</ul>\n\n<p>The following <strong>philosophical</strong> (or theoretical) aspects are on-topic.</p>\n\n<ul>\n<li>Intelligence definitions and testing</li>\n<li>Superintelligence</li>\n<li>Emotional intelligence</li>\n<li>Artificial consciousness</li>\n</ul>\n\n<p>The following <strong>social</strong> aspects are on-topic.</p>\n\n<ul>\n<li>Ethics (<a href=\"https://philosophy.stackexchange.com/help/on-topic\">3</a>)</li>\n<li>Explainable artificial intelligence</li>\n<li>Applications</li>\n</ul>\n\n<p>The following <strong>historical</strong> aspects are on-topic.</p>\n\n<ul>\n<li>Timeline (e.g. AI winters)</li>\n<li>Progress</li>\n</ul>\n\n<p>You can also ask questions about</p>\n\n<ul>\n<li>Terminology and notation</li>\n<li>Proofs (<a href=\"https://math.stackexchange.com/help/on-topic\">8</a>)</li>\n<li>Clarifications of certain excerpts from papers, books, etc.</li>\n<li>Reference requests (e.g. \"Which paper introduced vanilla RNNs?\")</li>\n</ul>\n\n<h3>Notes</h3>\n\n<ul>\n<li><p>Before posting, please, <strong>look around to see if your question has been asked before</strong>. Your question could be closed as a duplicate of another, if you don't do it.</p></li>\n<li><p>You should <strong>put some effort into writing your question</strong>. If your question is unclear, it could be flagged as unclear, your question could be closed, and you will not receive help. Furthermore, we expect users to do a little bit of research before asking a question.</p></li>\n<li><p><strong>Ask specific questions</strong>! If your question has potentially many answers, your question may be closed as too broad.</p></li>\n<li><p><a href=\"https://meta.stackexchange.com/a/39224/287113\"><strong>You should try asking one question or address a single problem per post</strong></a>, unless the questions are really very related to each other. If you ask multiple questions per post, your post may be closed as too broad.</p></li>\n<li><p>Ideally, we are looking for <strong>questions that can be answered objectively</strong>. More precisely, do not ask for advice (such as career path recommendation or a tool, which are, in general, <strong>off-topic</strong> here anyway) but for facts (including references) and arguments. If you have a philosophical question, you should demand a logical, rational and reasonable answer that argues the philosophical perspective (and not just an opinion).</p></li>\n<li><p><strong>Implementation questions in the context of understanding the theoretical topics are on-topic</strong>. For example, if a theoretical topic is described by a certain mathematical formula and you want to understand how a certain implementation is related to the formula, then your question is on-topic. As a rule of thumb, if you can describe your problem without the source code and if you think that a solution to your problem can be given without the source code, then your question is on-topic. The source code can be provided to further clarify the issue, but you should provide a <a href=\"https://stackoverflow.com/help/minimal-reproducible-example\">Minimal, Reproducible Example</a>.</p></li>\n<li><p><strong>General programming questions are off-topic</strong>. For example, if you have a question like \"Why am I getting this exception?\", \"How do I merge two Pandas' data frames?\" or \"How can I use this Keras API?\", then your question is off-topic (and you should probably ask it on <a href=\"https://stackoverflow.com/help/on-topic\">Stack Overflow</a>).</p></li>\n<li><p>It's also OK to ask and answer your own question.</p></li>\n</ul>\n\n<h3>Overlapping Stacks</h3>\n\n<p>If your question is not specifically on-topic for Artificial Intelligence Stack Exchange, it may be on-topic for another Stack Exchange site, such as </p>\n\n<ol>\n<li><a href=\"https://stats.stackexchange.com/help/on-topic\">Cross Validated</a></li>\n<li><a href=\"https://datascience.stackexchange.com/help/on-topic\">Data Science</a></li>\n<li><a href=\"https://philosophy.stackexchange.com/help/on-topic\">Philosophy</a></li>\n<li><a href=\"https://stackoverflow.com/help/on-topic\">Stack Overflow</a></li>\n<li><a href=\"https://robotics.stackexchange.com/help/on-topic\">Robotics</a></li>\n<li><a href=\"https://cs.stackexchange.com/help/on-topic\">Computer Science</a></li>\n<li><a href=\"https://cstheory.stackexchange.com/help/on-topic\">Theoretical Computer Science</a></li>\n<li><a href=\"https://math.stackexchange.com/help/on-topic\">Mathematics</a></li>\n<li><a href=\"https://psychology.stackexchange.com/\">Psychology &amp; Neuroscience</a></li>\n<li><a href=\"https://dsp.stackexchange.com/help/on-topic\">Signal Processing</a></li>\n</ol>\n\n<p>Certain questions are probably on-topic on multiple of these websites. For example, machine learning questions are also on-topic at <a href=\"https://stats.stackexchange.com/help/on-topic\">Cross Validated</a>, which is more statistics-oriented. There are probably other overlapping sites.</p>\n\n<p>If no site currently exists that will accept your question, you may commit to or propose a new site at <a href=\"https://area51.stackexchange.com\">Area 51</a>, the place where new Stack Exchange communities are democratically created.</p>\n"}, "1617": {"ParentId": 1615, "Score": 0, "Body": "<p>I adjusted <a href=\"https://ai.meta.stackexchange.com/a/1616/2444\">@nbro's answer</a> to remove the parts I thought were too restrictive. AI is a broad field, and the whitelist of \"on-topic\" areas omits a huge number of topics which are certainly within AI (consider, for contrast, <a href=\"https://aaai.org/Conferences/AAAI-19/aaai19keywords/\" rel=\"nofollow noreferrer\">the topics</a> that are present at AAAI this year alone, all of which are active areas of research). I think that the entry under the \"What topics can I ask about here?\" is specific enough. If we want to use a list of valid topics, we should formulate it by starting with actual active areas of research for the field, perhaps by amalgamating the keywords and topics that are present at AAAI, NIPS, UAI, IJCAI, AAMAS, CEC, and other major conferences. I suspect that's a lot more work than it's worth however.</p>\n\n<p>I also adjusted the wording of the programming portion to better reflect the idea that programming questions are fundamentally <em>on-topic</em> here, as long as they are about AI algorithms or implementations, and not applications. I think that without this, the stack is going to lack a connection to academic AI, and will descend into a sort of futurism/singularity board. We want to encourage more programming related content, not less, but only of the kind that actually relates to AI.</p>\n\n<h2>What topics can I ask about here?</h2>\n\n<p>If you have a question about <strong>theoretical, philosophical, historical, social</strong> and <strong>algorithmic</strong> or <strong>academic</strong> aspects of AI, then you are <em>probably</em> in the right place to ask your question! </p>\n\n<h3>Notes</h3>\n\n<ul>\n<li><p>Before posting, please, <strong>look around to see if your question has been asked before</strong>. Your question could be closed as a duplicate of another, if you don't do it.</p></li>\n<li><p>You should <strong>put some effort into writing your question</strong>. If your question is unclear, it could be flagged as unclear, your question could be closed, and you will not receive help. Furthermore, we expect users to do a little bit of research before asking a question.</p></li>\n<li><p><strong>Ask specific questions</strong>! If your question has potentially many answers, your question may be closed as too broad.</p></li>\n<li><p><a href=\"https://meta.stackexchange.com/a/39224/287113\"><strong>You should try asking one question per post</strong></a>, unless the questions are really very related to each other. If you ask multiple questions per post, your post may be closed as too broad.</p></li>\n<li><p>Ideally, we are looking for <strong>questions that can be answered objectively</strong>. More precisely, do not ask for advice (such as career path recommendation or a preferred tool, which are, in general, <strong>off-topic</strong> here anyway) but for facts (including references) and arguments. If you have a philosophical question, you should demand a logical, rational and reasonable answer that argues the philosophical perspective (and not just an opinion).</p></li>\n<li><p>It's also OK to ask and answer your own question.</p></li>\n<li><p>Programming questions about the implementation of AI algorithms, or the source code of implementations of those algorithms, are on-topic. <strong>Programming questions about applying AI tools to specific problems are off-topic</strong>, and probably belong on DataScience.SE, or the main StackOverflow site. If you're looking for a clarification of the implementation of a certain AI concept, then your question is on-topic. For example, if a theoretical topic is described by a certain mathematical formula and you want to understand the implementation of this formula, then your question is on-topic. However, if you have a question like \"Why am I getting this exception?\", \"How do I merge two Pandas' data frames?\", or \"How can I use Tensorflow to train a neural network to recognize cats?\" then your question is off-topic (and you should probably ask it on <a href=\"https://stackoverflow.com/help/on-topic\">Stack Overflow</a>).</p></li>\n</ul>\n\n<h2>Similar websites</h2>\n\n<p>If your question is not on-topic for Artificial Intelligence Stack Exchange, it may be on-topic for another Stack Exchange site, such as </p>\n\n<ul>\n<li><a href=\"https://datascience.stackexchange.com/help/on-topic\">Data Science</a></li>\n<li><a href=\"https://stats.stackexchange.com/help/on-topic\">Cross Validated</a></li>\n<li><a href=\"https://stackoverflow.com/help/on-topic\">Stack Overflow</a></li>\n<li><a href=\"https://robotics.stackexchange.com/help/on-topic\">Robotics</a></li>\n<li><a href=\"https://cs.stackexchange.com/help/on-topic\">Computer Science</a></li>\n<li><a href=\"https://philosophy.stackexchange.com/help/on-topic\">Philosophy</a></li>\n</ul>\n\n<p>Certain questions are probably on-topic on multiple of these websites. For example, machine learning questions are also on-topic at <a href=\"https://stats.stackexchange.com/help/on-topic\">Cross Validated</a>, which is more statistics-oriented.</p>\n\n<p>If no site currently exists that will accept your question, you may commit to or propose a new site at <a href=\"https://area51.stackexchange.com\">Area 51</a>, the place where new Stack Exchange communities are democratically created.</p>\n"}, "1620": {"ParentId": 1615, "Score": 1, "Body": "<p>I like all of the suggestions in general, and think it's now just a matter of hammering out details, and dealing with the competing concerns of brevity vs. extrapolation.</p>\n<p><strong>I think we should lift some of the the guidance from Data Science re: Overlap</strong></p>\n<blockquote>\n<p>Even though the boundaries are not always perfectly clear and we often accept questions that are also appropriate on other sites, here are a few guiding thoughts:</p>\n<p>If you think a question is equally appropriate on multiple sites, ask on the site with the most users (usually Stack Overflow or Data Science). That way you have the best chance to get good and quick answers and site contents will stay more coherent. If it is not accepted there, it can be migrated to the correct site. Don't post your questions on more than one site.</p>\n<p>Other relevant sites include:</p>\n<p>Open Data (Dataset requests)\nComputational Science (Software packages and algorithms in applied mathematics)\netc.</p>\n</blockquote>\n"}, "1621": {"ParentId": 1598, "Score": 2, "Body": "<blockquote>\n<p>Does it really make sense to have all these separate websites (especially, CrossValidated, Data Science and ours), only because of these small differences</p>\n</blockquote>\n<p>No, it doesn't make any sense, because whatever people are saying on meta, in practice if you look at the questions posted on AI.SE, over 90% of them are on-topic on CrossValidated and Data Science. This creates plenty of crossnetwork question duplicates, which personally kills my motivation to participate.</p>\n"}, "1624": {"ParentId": 1598, "Score": 2, "Body": "<ul>\n<li><p>We can address futurism (one of the leading drivers of misinformation about AI!) and serve an important function of myth-busting.</p></li>\n<li><p>We deal with social impacts in general, which other related stacks don't address.  </p></li>\n<li><p>We can take pyschology/cognitive/neuroscience questions related to AI, which may unwelcome on those stacks. </p></li>\n<li><p>We can treate AI milestones in general, not just those related to statistical AI.</p></li>\n</ul>\n\n<p>re: Philosophy, although we have few questions formally containing that tag, <a href=\"https://ai.stackexchange.com/questions?tab=Votes\">a search of the most voted SE:AI questions</a> reveals the subject to be popular and well-treated on this Stack.  (Compare to the <a href=\"https://philosophy.stackexchange.com/questions/tagged/artificial-intelligence?tab=Newest\">relative lack of activity for AI questions on SE: Philosophy, especially in recent years</a>.)  SE:Philosophy also lack a \"neoluddism\" tag, which is the more relevant philosophy tag, in that it relates to material effects of AI implementation, including bias.</p>\n"}, "1625": {"ParentId": 1623, "Score": 2, "Body": "<p>In general, I agree with these guidelines. However, I think that misinformation can also be a good reason for deleting an answer, because (intentionally or not) the answer can be harmful. Moreover, it is not always clear the intentions of the answerer. If a user regularly gives answers with misleading or wrong information, this is an obvious sign that his/her answers need to be deleted and this user can and probably should be banned.</p>\n"}, "1629": {"ParentId": 1388, "Score": 0, "Body": "<p>My sense is that answer that provide a religious perspective can be on-topic for certain issues related to social or philosophical subjects, but do need to be well supported, and ideally should be well referenced.  </p>\n"}, "1630": {"ParentId": 1627, "Score": 2, "Body": "<p>Here's a non-exhaustive list of my favorite questions and answers, which does not mean they are perfect or cannot be improved.</p>\n<h2>Questions</h2>\n<ul>\n<li><a href=\"https://ai.stackexchange.com/q/7416/2444\">Can neural networks be used to prove conjectures?</a></li>\n</ul>\n<h3>Questions to which I gave an answer</h3>\n<ul>\n<li><a href=\"https://ai.stackexchange.com/q/13261/2444\">Why do we need common sense in AI?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/13289/2444\">Are neural networks prone to catastrophic forgetting?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/12971/2444\">What sort of mathematical problems are there in AI that people are working on?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/145/2444\">What is the relevance of AIXI on current artificial intelligence research?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/17044/2444\">Why is dropout favoured compared to reducing the number of units in hidden layers?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/17670/2444\">How can supervised learning be viewed as a conditional probability of the labels given the inputs?</a></li>\n</ul>\n<h3>My questions</h3>\n<ul>\n<li><a href=\"https://ai.stackexchange.com/q/11679/2444\">Why doesn&#39;t Q-learning converge when using function approximation?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/27830/2444\">Why is the equation $\\mathbb{E} \\left[ (Y - \\hat{Y})^2 \\right] = \\left(f(X) - \\hat{f}(X) \\right)^2 + \\operatorname{Var} (\\epsilon)$ true?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/27854/2444\">Why was the VC dimension not defined for all configurations of $d$ points?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/24375/2444\">Why does a negative reward for every step really encourage the agent to reach the goal as quickly as possible?</a></li>\n</ul>\n<h2>Answers</h2>\n<ul>\n<li><a href=\"https://ai.stackexchange.com/a/11133/2444\">What is the Bellman operator in reinforcement learning?</a> (with mathematical details)</li>\n<li><a href=\"https://ai.stackexchange.com/a/17328/2444\">Why is a softmax used rather than dividing each activation by the sum?</a> (with mathematical details)</li>\n<li><a href=\"https://ai.stackexchange.com/a/14247/2444\">Why do we need explainable AI?</a></li>\n</ul>\n<h3>My answers</h3>\n<ul>\n<li><a href=\"https://ai.stackexchange.com/a/28566/2444\">How can we find the value function by solving a system of linear equations?</a> (with mathematical details; topic: RL)</li>\n<li><a href=\"https://ai.stackexchange.com/a/17881/2444\">How to estimate the capacity of a neural network?</a> (with mathematical details; topic: learning theory)</li>\n<li><a href=\"https://ai.stackexchange.com/a/10818/2444\">What is the difference between First-Visit Monte-Carlo and Every-Visit Monte-Carlo Policy Evaluation?</a> (with mathematical details; topic: RL)</li>\n<li><a href=\"https://ai.stackexchange.com/a/8909/2444\">How is iterative deepening A* better than A*?</a> (with mathematical details; topic: search)</li>\n<li><a href=\"https://ai.stackexchange.com/a/27831/2444\">Why is the equation <span class=\"math-container\">$\\mathbb{E} \\left[ (Y - \\hat{Y})^2 \\right] = \\left(f(X) - \\hat{f}(X) \\right)^2 + \\operatorname{Var} (\\epsilon)$</span> true?</a> (with mathematical details; topic: ML)</li>\n<li><a href=\"https://ai.stackexchange.com/a/22000/2444\">Do convolutional neural networks perform convolution or cross-correlation?</a> (with mathematical details; topic: CNNs)</li>\n<li><a href=\"https://ai.stackexchange.com/a/10377/2444\">What is the relevance of AIXI on current artificial intelligence research?</a> (topic: AGI/AIXI)</li>\n<li><a href=\"https://ai.stackexchange.com/a/13293/2444\">Are neural networks prone to catastrophic forgetting?</a> (topic: neural networks)</li>\n<li><a href=\"https://ai.stackexchange.com/a/10624/2444\">What is self-supervised learning in machine learning?</a> (topic: ML)</li>\n<li><a href=\"https://ai.stackexchange.com/a/11387/2444\">What is artificial intelligence?</a>  (topic: AI field)</li>\n</ul>\n<p>Of course, I am biased towards questions and answers where I am involved, but this does not mean that there aren't many other good questions and answers on this site.</p>\n"}, "1634": {"ParentId": 1633, "Score": 5, "Body": "<p>Yes, <a href=\"https://charcoal-se.org/#whats-smokey\" rel=\"nofollow noreferrer\">SmokeDetector</a> is active on Artificial Intelligence as well, and it's <a href=\"https://meta.stackexchange.com/q/291301/295232\">automatically flagging posts</a> of which it's 99.75% sure it's spam. Fortunately, Artificial Intelligence <a href=\"https://metasmoke.erwaysoftware.com/sites/dash?utf8=%E2%9C%93&amp;site_id=322&amp;months=12&amp;tab=all\" rel=\"nofollow noreferrer\">doesn't see as much spam as the rest of the network</a>, and only 117 flags have been cast last year. Most (all?) other bots in that blog post are tuned towards Stack Overflow content and can't be ported directly to Artificial Intelligence, though some of them might be after some adjustments.</p>\n\n<blockquote>\n  <p>If one decided to create a bot for accelerating moderation by flagging duplicates and off-topic questions, is that specifically allowed in the website? A bot that helps to automatically flag questions and duplicates may help a lot in removing and noticing unwanted posts and answers</p>\n</blockquote>\n\n<p>Yes, that is allowed, as long as you don't do anything stupid. You need to be reasonably sure the flag accuracy is at least as high as the average human user (which is about 95% IIRC). If you get flag banned because of a bad algorithm, that's your own problem.</p>\n\n<blockquote>\n  <p>and with a machine learning algorithm one can classify it to a very high degree of accuracy.</p>\n</blockquote>\n\n<p>Well ... that might surprise you. SmokeDetector relies heavily on old-school regexes. We've tried a few times to classify spam based on machine learning, and we got nowhere near the 95% mark, let alone the 99.75% needed for autoflagging. (That percentage is so high because validated spam flags carry a heavy penalty.) Determining off-topic and duplicate questions looks even more challenging to me, but I hope you can surprise us.</p>\n"}, "1635": {"ParentId": 1632, "Score": 5, "Body": "<p>Quoting <a href=\"https://ai.meta.stackexchange.com/questions/1404/something-new-coming-to-the-artificial-intelligence-stack-exchange?noredirect=1#comment3202_1404\">this comment</a> by Stack Exchange's Director of New Community Development, Robert Cartaino:</p>\n\n<blockquote>\n  <p>The IBM sponsorship has concluded, but AWS has signed on to take over later this year! We are currently finalizing the materials needed and it should go live when everything is completed.</p>\n</blockquote>\n\n<p>According to the <a href=\"https://web.archive.org/web/20200114103020/https://ai.stackexchange.com/\" rel=\"nofollow noreferrer\">Wayback Machine</a>, the logo started to show somewhere between January 10th and 14th.</p>\n"}, "1637": {"ParentId": 1636, "Score": 4, "Body": "<p><a href=\"https://ai.meta.stackexchange.com/questions/1636/empty-sponsored-by-label-under-top-bar-aws-logo-not-shown#comment3208_1636\">Catija's hunch</a> was right: the logo is blocked by uBlock, since it's a link to ad.doubleclick.net.</p>\n\n<p>I <em>would</em> have checked that, if I hadn't seen the AWS logo on <a href=\"https://stats.stackexchange.com/\">Cross Validated</a> a few weeks ago. But right now it's not showing there either. I guess the ad link is important enough (in terms of revenue, or just part of the sponsorship contract) to keep it, so I'm no longer considering it a <a href=\"https://ai.stackexchange.com/questions/tagged/bug\" class=\"post-tag\" title=\"show questions tagged &#39;bug&#39;\" rel=\"tag\">bug</a>.</p>\n"}, "1639": {"ParentId": 1638, "Score": 1, "Body": "<p>This issue has been discussed several times in the past. AFAIK, initially,  this site wasn't meant to accept machine learning, statistics and programming questions (because that's already covered by other sites), but machine learning questions have been asked on this site for a long time and, given that they are considered part of AI, they are certainly considered on-topic now. However, not all implementation- or programming-related questions are on-topic here. I've proposed a <a href=\"https://ai.meta.stackexchange.com/a/1616/2444\">new description for the on-topic page</a>, which also attempts to explain which programming questions can be on-topic here, even though this is still a grey area, honestly. See <a href=\"https://ai.meta.stackexchange.com/q/1615/2444\">What should the on-topic page look like?</a>. My proposal has now become the <a href=\"https://ai.stackexchange.com/help/on-topic\">new on-topic page</a>. I suggest you carefully read and follow it.</p>\n"}, "1645": {"ParentId": 1644, "Score": 5, "Body": "<p>I am really flattered by this opportunity and vote of confidence! I will try to do my best, in collaboration with the other moderators and community members! Feel free to ping me in <a href=\"https://chat.stackexchange.com/rooms/43371/the-singularity\">our main chat room</a> and I will try to answer as soon as possible. Hopefully, our community will continue to grow in quantity but especially in quality!</p>\n"}, "1649": {"ParentId": 1648, "Score": 1, "Body": "<blockquote>\n  <p>Why does not Stack Exchange make one specific page for researchers or anyone with interests in the area of Computer Vision?</p>\n</blockquote>\n\n<p>Apparently, there was a proposal for a computer vision SE site, but <a href=\"https://stats.meta.stackexchange.com/a/2799/82135\">the proposal was deleted</a> because of low activity. In general, if there aren't enough users interested in the topic and enough activity, the site will not be created.</p>\n\n<p>Computer vision is clearly an AI topic, so, in general, any theoretical CV question is on-topic here. See <a href=\"https://ai.stackexchange.com/questions/tagged/computer-vision\">all our CV questions</a>.</p>\n\n<p>Signal Processing SE is also an appropriate site to ask CV questions. In fact, in the past, I've asked some questions there. <a href=\"https://stats.stackexchange.com/tags\">Stats SE</a> may also be an appropriate site to ask your question.</p>\n\n<p>See also <a href=\"https://stats.meta.stackexchange.com/q/2794/82135\">Stack Exchange site to ask questions about computer vision?</a>.</p>\n"}, "1651": {"ParentId": 1650, "Score": 1, "Body": "<p>No, this is not the reason. The reason is that you create posts whose content is off-topic. Please, see <a href=\"https://ai.stackexchange.com/help/on-topic\">our on-topic page</a>. Please, read it very carefully (especially, the notes)! If something is unclear there, please, let me know or ask another meta-question.</p>\n"}, "1653": {"ParentId": 1652, "Score": 1, "Body": "<p>I believe that the current description of the site does not highlight certain important aspects of the site (e.g. AI history) and it contains redundant or noisy information. </p>\n\n<p>In the current description of the site, the topics that I believe are redundant or noisy are</p>\n\n<ul>\n<li>mathematics (theory)</li>\n<li>discovery (theory/development), </li>\n<li>design (theory/development), </li>\n<li>practice (development), </li>\n<li>embedded uses (development), </li>\n<li>cognition (theory)</li>\n<li>policy (social)</li>\n<li>impact  (social)</li>\n</ul>\n\n<p>So, here's my initial new proposal (based on the current first paragraph of the <a href=\"https://ai.stackexchange.com/help/on-topic\">new on-topic page</a>).</p>\n\n<blockquote>\n  <p>Artificial Intelligence Stack Exchange is a question and answer site for people interested in the <strong>theoretical</strong> (including mathematical), <strong>philosophical, social, historical</strong>, and <em>certain</em> developmental and academic aspects of artificial intelligence.</p>\n</blockquote>\n\n<p>Maybe we could also explicitly mention \"research\"?</p>\n"}, "1667": {"ParentId": 1661, "Score": 3, "Body": "<p>The \"sponsored by\" is gone, for now, because the site sponsorship is currently paused.</p>\n\n<p>While we don't have a set date yet for the sponsorship to return, current conversations with AWS point to relaunching in early Q3, though the date isn't locked in yet.</p>\n"}, "1669": {"ParentId": 1668, "Score": 1, "Body": "<blockquote>\n  <p>Should such questions remain open?</p>\n</blockquote>\n\n<p>Yes. The CR argument is probably the most famous argument in the philosophy of artificial intelligence. It's about the meaning of intelligence, imitation and understanding. The typical bad answer to this question is one where someone just says \"yes\" or \"no\" without providing a rational explanation or considering previous debates, discussions, and philosophical positions on the topic.</p>\n\n<p>In general, philosophical questions related to AI are on-topic on our site, as <a href=\"https://ai.stackexchange.com/help/on-topic\">our on-topic page</a> explicitly says. </p>\n\n<p>Questions that are considered opinion-based are e.g.</p>\n\n<ul>\n<li>Which book <em>do you think</em> is <em>the best</em> (for task X)?</li>\n<li><em>Do you think</em> that AI will take over the world?</li>\n</ul>\n\n<p>All questions that ask explicitly for opinions (e.g. that start like \"What do you think...\"?), rather than for an objective answer, are opinion-based, and you should flag them to be closed as such. </p>\n\n<p>Sometimes, certain opinion-based questions can be rephrased. For example, the question \"What is the best tool to solve task X given constraints Y?\" could be rephrased as \"What are some available tools to solve...?\", which would be more acceptable. </p>\n\n<p>The question above \"Do you think that AI will take over the world?\" could also be \"saved\", if rephrased differently. For example, we could ask instead </p>\n\n<blockquote>\n  <p>What are the existing arguments of real philosophers about the topic 'AI takeover'? Why do they think it will happen or not?</p>\n</blockquote>\n\n<p>These questions can lead to more useful answers, where users will need to refer to existing philosophical work rather than providing their own opinion based on their possibly wrong intuition. (Btw, I don't think this question has already been asked, so feel free to ask it!)</p>\n\n<p>As a rule of thumb, avoid term/expressions such as</p>\n\n<ul>\n<li>Do you think...?</li>\n<li>What is <em>the best</em>...? </li>\n<li>Do you like...?</li>\n</ul>\n"}, "1672": {"ParentId": 1668, "Score": 1, "Body": "<p>My take is that it's a philosophical question, and all philosophy outside of formal logic is essentially opinion, just that those opinions have to be well founded and well argued.  (i.e. without logical falacies.)</p>\n\n<p>This particular question yielded several solid answers that make the point that the Chinese Room Argument is highly subjective, and assumes some special quality of human cognition (which has not yet been proved, only speculated on.)</p>\n"}, "1676": {"ParentId": 1675, "Score": 2, "Body": "<p>Yes, but do not use the words <em>recommendation</em> or <em>suggestion</em> in your questions. Avoid words that can lead to opinions and try to ask questions that can be answered objectively and that are as much specific as possible, i.e. ask for facts or evidence.</p>\n\n<p>For example, the question \"Which model <em>should</em> I use for object detection?\" is not very specific, and can lead to opinions (because you're using \"should\"). There are many models for object detection. You should at least describe which objects you want to detect (and, in general, your dataset), and why you're asking for a reference model to use: haven't you found one already by searching the web? If yes, share it with us, and explain why you think it's not \"good enough\". A better way of rephrasing that question would be </p>\n\n<blockquote>\n  <p>Which models are more likely to perform well on this specific problem X with this data Y? I have found models Z and W, but, given that I am not very familiar with them, I don't know which one is more appropriate for my scenario.</p>\n</blockquote>\n\n<p>or something like that.</p>\n\n<p>You can also ask for references (paper, books, articles), but, again, try to be specific and explain your problem well and why are you looking for a reference.</p>\n"}, "1678": {"ParentId": 1677, "Score": 4, "Body": "<p>Yes, you can ask for an intuitive explanation of a model, algorithm or, in general, topic. Just make sure that you clarify in your post what exactly you are looking for.</p>\n\n<p>For example, if you're looking for an intuitive explanation of how a u-net works, you should ask</p>\n\n<blockquote>\n  <p><strong>Intuitively</strong>, how does u-net work? What are the main ideas behind this model?</p>\n</blockquote>\n\n<p>If you just ask </p>\n\n<blockquote>\n  <p>How does u-net work?</p>\n</blockquote>\n\n<p>a person could think that you are looking for a detailed explanation (and that could even considered a too broad post). Alternatively, if you are (also) looking for a detailed explanation, you may (also) ask for a reference that explains the topic in detail.</p>\n\n<p>Moreover, before asking a question, you should probably do a little bit of research on your own, then explain WHAT you haven't understood in the sources that you have researched/read so far (maybe you should also cite the sources that you have read).</p>\n"}, "1680": {"ParentId": 1679, "Score": 9, "Body": "<p>Don't use MathJax unless you need to. Here are some hacks to do formatting like this:</p>\n<ul>\n<li><p>Blockquotes (<code>&gt;</code>). Useful for marking out a block of text as different, without doing much additional formatting to them.</p>\n</li>\n<li><p>Inline MathJax. You can enclose MathJax in <code>$</code> to make it render in line (ie. not on a seperate, centered line. eg. <code>$\\alpha$</code> gives <span class=\"math-container\">$\\alpha$</span></p>\n</li>\n<li><p>Indenting. Number of ways to achieve this. <code>$\\quad$</code> (and similar) might be most familiar to you, but piles of unbreakable spaces (<code>&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;</code>) also works as a hack-y way to do this.</p>\n</li>\n<li><p>Linebreaks. You can do linebreaks by having multiple spaces at the end of a line, or using the html tag <code>&lt;br/&gt;</code></p>\n</li>\n</ul>\n<p>To see it in action with your specific example:</p>\n<blockquote>\n<p>Algorithm parameters: step size  <span class=\"math-container\">$\\alpha \\in (0 , 1] , \\epsilon &gt; 0$</span><br />\nInitialize  <span class=\"math-container\">$Q  ( s, a ), \\  \\forall s \\in S^+ , a \\in A ( s ),$</span> arbitrarily except that <span class=\"math-container\">$Q ( terminal , \\cdot ) = 0$</span></p>\n<p>Loop for each episode:<br />\n<span class=\"math-container\">$\\quad$</span>Initialize <span class=\"math-container\">$S$</span><br />\n<span class=\"math-container\">$\\quad$</span>Loop  for  each  step  of  episode:<br />\n<span class=\"math-container\">$\\qquad$</span>Choose  <span class=\"math-container\">$A$</span> from <span class=\"math-container\">$S$</span> using some policy derived from <span class=\"math-container\">$Q$</span> (eg <span class=\"math-container\">$\\epsilon$</span>-greedy)<br />\n<span class=\"math-container\">$\\qquad$</span>Take action <span class=\"math-container\">$A$</span>, observe <span class=\"math-container\">$R, S'$</span><br />\n<span class=\"math-container\">$\\qquad Q(S,A) \\leftarrow Q(S,A) + \\alpha[R+\\gamma \\max_a(S', a) - Q(S, A)]$</span><br />\n<span class=\"math-container\">$\\qquad S \\leftarrow S'$</span><br />\n<span class=\"math-container\">$\\quad$</span> until <span class=\"math-container\">$S$</span> is terminal</p>\n</blockquote>\n<p>Which is produced from:</p>\n<pre><code>&gt; Algorithm parameters: step size  $\\alpha \\in (0 , 1] , \\epsilon &gt; 0$   \nInitialize  $Q  ( s, a ), \\  \\forall s \\in S^+ , a \\in A ( s ),$ arbitrarily except that $Q ( terminal , \\cdot ) = 0$    \n&gt;\n&gt; Loop for each episode:  \n$\\quad$Initialize $S$   \n$\\quad$Loop  for  each  step  of  episode:    \n$\\qquad$Choose  $A$ from $S$ using some policy derived from $Q$ (eg $\\epsilon$-greedy)   \n$\\qquad$Take action $A$, observe $R, S'$   \n$\\qquad Q(S,A) \\leftarrow Q(S,A) + \\alpha[R+\\gamma \\max_a(S', a) - Q(S, A)]$   \n$\\qquad S \\leftarrow S'$    \n$\\quad$ until $S$ is terminal\n</code></pre>\n"}, "1684": {"ParentId": 1683, "Score": 3, "Body": "<p>No.</p>\n<p>General programming issues are off-topic here. For example, if you have an exception/bug/error in your source code or you don't know how to use a certain library/API, then that's off-topic. If you have this type of question, the most appropriate site is probably Stack Overflow (or Data Science SE).</p>\n<p>However, if you want to understand how a certain concept/algorithm/model is implemented, then you can ask questions about that because that's more a conceptual question. <a href=\"https://ai.stackexchange.com/q/20803/2444\">Here is an example of such a question</a>. (But, please, try to ask a specific and clear question that explains what you don't really understand, so that to facilitate the answerer's life).</p>\n<p><a href=\"https://ai.stackexchange.com/help/on-topic\">Our on-topic page</a> actually states these things explicitly, so I suggest that you read or at least skim through our on-topic page again.</p>\n"}, "1685": {"ParentId": 1683, "Score": 0, "Body": "<p>I'm personally in favor of this, but the overall consensus is that we should focus on theory, as opposed to implementation.</p>\n<p>(We haven't historically had good response to programming or implementation questions, so the argument for leaving those to overflow and other stacks is strong.)</p>\n"}, "1687": {"ParentId": 1686, "Score": 5, "Body": "<p>Editing tags is also always welcome (and I think you get a little rep for it.)</p>\n<p><em>Note: We do require reliable references for tag info.</em></p>\n<hr />\n<p>Also, Vote!  THat's our method of vetting information, so more vote is always better.  Also incentivizes quality contributors and disincentivizes low quality content.</p>\n"}, "1691": {"ParentId": 1644, "Score": 1, "Body": "<p>Congratulations to our new moderator, Dennis! He has a very good overall knowledge of the AI field, he's patient, and he's been around for a long time, which shows that he cares about this community. I think he will be a good moderator (if he remains at least as active as he has been)!</p>\n"}, "1692": {"ParentId": 1661, "Score": 2, "Body": "<p>Seems AWS came back up in the &quot;Sponsored by&quot; section recently, this is what it looks like right now:</p>\n<p><a href=\"https://i.stack.imgur.com/zv8hA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zv8hA.png\" alt=\"enter image description here\" /></a></p>\n"}, "1708": {"ParentId": 1707, "Score": 3, "Body": "<p>This type of question could lead to long lists or opinions, so I would suggest that when asking these questions people should ask for <strong>examples</strong> of X, something like</p>\n<blockquote>\n<p>Currently, what are <strong>some examples</strong> of the most used techniques to solve problem Z? As a reference, can you also provide a link to the research paper that introduced them?</p>\n</blockquote>\n<p>Alternatively, if you're looking for comprehensive surveys, you can explicitly say that you're looking for papers or books that do those surveys, so you could say that you would appreciate that people link to those surveys.</p>\n<p>So, when asking that type of question, the keys are</p>\n<ol>\n<li><p>to restrict the question in some way, so that it doesn't require long answers, which, in general, aren't really suitable for our site. Always keep in mind that your question should not have multiple answers that are inconsistent with each other (although there are exceptions to this, such as when a problem can be solved in different ways). This would occur if you ask a question that is not specific enough, but it would not occur if you ask for <strong>examples</strong> of models/techniques that can be used to solve some problem (provided that you clarify exactly what you're looking for).</p>\n</li>\n<li><p>avoid terms that will lead to opinions (such as &quot;in your opinion...?&quot; or &quot;what do you think...?&quot;, so you should avoid questions like &quot;<strong>in your opinion</strong>, what are the best models to solve this problem?&quot;)</p>\n</li>\n</ol>\n<p>Not a long time ago, we had two questions along these lines, which are ok for our site, as far as I'm concerned:</p>\n<ul>\n<li><a href=\"https://ai.stackexchange.com/q/20160/2444\">What are the most common deep reinforcement learning algorithms and models apart from DQN?</a></li>\n<li><a href=\"https://ai.stackexchange.com/q/25064/2444\">Is there a taxonomy of adversarial attacks?</a></li>\n</ul>\n"}, "1710": {"ParentId": 1709, "Score": 3, "Body": "<blockquote>\n<p>Do most of the researchers of deep learning go through the existing code and understand it in detail or just use it as a module for their research without complete understanding?</p>\n</blockquote>\n<p>For such a &quot;Do most researchers X or Y?&quot; question, I would be a bit concerned about whether that can really be properly answered with any level of objectivity.</p>\n<p>But if it's rephrased in a way such that it's more about <em>how</em> researchers can or cannot do something, or benefit from something or make use of something, I feel like that would be fine. For a phrasing close to what you seem to be interested in, I would think of something like:</p>\n<blockquote>\n<p>How can researchers make use of source code published alongside other researchers' publications?</p>\n</blockquote>\n<p>and then in the body of the question expand on that question by explaining your personal experiences, without that context it may not be obvious still exactly what you mean. A bit further from the question you suggested, but still related, I'd think something like this would also be fine:</p>\n<blockquote>\n<p>Why is making source code for research papers [important OR valuable OR useful]?</p>\n</blockquote>\n"}, "1712": {"ParentId": 1711, "Score": 3, "Body": "<p>I think it depends on the question to some degree.</p>\n<p>There are some questions that have objective answers via, e.g. surveys of AI researchers. For example, the question of when AI researchers believe &quot;Hard AI&quot; will be created is objectively answerable via this method.</p>\n<p>I think in general though, questions like the one in that meta-post actually belong on <a href=\"http://academia.stackexchange.com/\">academia.se</a>, a site where you could reasonably expect to get a broad range of opinions from researchers even in a relatively narrow area, and where questions like &quot;How do I get the most out of open sourced code in research papers?&quot; would surely be on-topic.</p>\n<p>In general, I think we should adopt the following heuristic:</p>\n<ul>\n<li>If the question is about <em>the opinions of AI researchers</em> about <em>something in AI</em>, it is on topic here and potentially answerable, though we should require quality sources in such answers. Example: &quot;Does the AI research community have a consensus view on whether deep neural networks can be made explainable?&quot;.</li>\n<li>If the question is about the <em>practices of AI researchers</em>, or about their <em>opinions about research practices</em>, it is off-topic here and belongs on the academia.se stack. Example: &quot;How does one become an AI researcher?&quot; or &quot;How do AI researchers use the code provided with some papers?&quot;.</li>\n</ul>\n<p>A grey area is questions about AI-specific research methodologies. (e.g. &quot;What is the right hypothesis test to use when comparing machine learning methods?&quot;). I would say these could potentially be on topic on many sites, and we should generally be permissive about them.</p>\n"}, "1714": {"ParentId": 1713, "Score": 2, "Body": "<p>After a quick look at the stats, with respect to the last year, I want you to note a few things</p>\n<ul>\n<li><p>moderators have definitely closed more posts. This is probably due to the fact that we started to have a clearer idea of the direction that the site should take.</p>\n</li>\n<li><p>moderators have deleted a lot more comments than in 2019, and the community fewer comments (which suggests that the community was not that engaged: see note number 7)</p>\n</li>\n<li><p>there have been a lot more posts deleted (this is probably a good thing because I've been trying to get rid of low-quality posts, which are still around, unfortunately)</p>\n</li>\n<li><p>moderators have been less involved in the review queue (I have definitely noticed this, although we have more moderators than in 2019!)</p>\n</li>\n</ul>\n<p>In any case, it would be better to have a more sophisticated way of seeing the evolution of these stats over the years.</p>\n"}, "1719": {"ParentId": 1718, "Score": 1, "Body": "<p>Hmmm I don't feel like they should necessarily be the same. In most machine learning contexts especially, as you say, I would view &quot;evaluation&quot; as something broader or more general than &quot;testing&quot;. I guess I'd associate &quot;testing&quot; specifically with the classic train/validation/test data splits.</p>\n<p>I could also see <code>testing</code> being used for an entirely different purpose though: testing whether an implementation is correct. Think of things like unit testing. A lot of that would probably just be about software engineering and be off-topic, but I could see questions about testing the correctness of specific things in AI being relevant. For example: <em>How can I test that my gradient computations / gradient descent implementation is correct?</em> (and an answer could get into things like numerically approximating gradients and checking that they're about the same as the analytically computed ones)</p>\n"}, "1721": {"ParentId": 1720, "Score": 5, "Body": "<p>I'd say that questions related to <code>game-theory</code> can very often end up being on topic on AI.SE, but it probably doesn't need to be explicitly listed as being on-topic in its entirety. Game theory does show up in various areas of AI (not just like minimax for search in games, but also for like any other kinds of multi-agent interactions, and probably some other areas I don't know enough about), so anything related to that should be on-topic in my opinion. I wouldn't explicitly list game theory as a whole as a topic, because if someone really has a complex, pure game theory question outside of any other AI context, they'd probably be better served on an economics or math website.</p>\n"}, "1726": {"ParentId": 1725, "Score": 7, "Body": "<p>All <strong>theoretical</strong>/conceptual questions about <em>statistical learning theory</em> (which is an approach to computational learning theory, developed by Vladimir Vapnik and others, a sub-field of AI) and <em>multi-armed bandit</em> problems/algorithms are <a href=\"https://ai.stackexchange.com/help/on-topic\">on-topic here</a>, but they are also on-topic on Stats SE.</p>\n<p>Of course, as a mod of Artificial Intelligence Stack Exchange, I would like to see <a href=\"https://ai.stackexchange.com/help/how-to-ask\">good/great questions</a> about this topic on AI SE. So, of course, I will suggest that you first ask this type of question here. However, after a while, if you don't get an answer, you probably should ask it somewhere else, such as at Stats SE.</p>\n<p>In general, the choice of where to ask your question is yours and will probably depend on</p>\n<ul>\n<li>whether it's on-topic or not (it's in both cases, so, in this case, it should not depend on this),</li>\n<li>the service that you received in the past was good or not (did you get a good answer there when you asked a question there?)</li>\n<li>your preferences (do you like more AI SE/Artificial Intelligence or Stats SE/Statistics?)</li>\n</ul>\n"}, "1728": {"ParentId": 1727, "Score": 1, "Body": "<p>I don't think that this type of question should be made on-topic here, but it may also depend on the question (maybe you can provide a few examples of questions that you have in mind?).</p>\n<p>The reasons are</p>\n<ol>\n<li><p>the site should focus on the theoretical, philosophical, and social aspects of artificial intelligence, but questions asking about funding your project do not seem to fall into any of these categories (maybe apart from the social category), as this problem is not strictly related to AI</p>\n</li>\n<li><p>answers to these questions could get outdated very quickly, given that the funding opportunities may expire after a while, so these questions could potentially only be useful to the person that asked them, but, ideally, <a href=\"https://ai.stackexchange.com/help/how-to-ask\">questions should also be relevant for other future visitors</a></p>\n</li>\n</ol>\n<p>I'm not sure which other Stack Exchange website could be suitable for this type of question. Maybe you could ask this question here: <a href=\"https://meta.stackexchange.com/\">https://meta.stackexchange.com/</a>?</p>\n"}, "1730": {"ParentId": 1662, "Score": 4, "Body": "<p>Some of you may have noticed the Meta Stack Exchange post - <a href=\"https://meta.stackexchange.com/questions/364007/testing-three-vote-close-and-reopen-on-13-network-sites\">Testing three-vote close and reopen on 13 network sites</a> (it's linked in the featured on meta sidebar) - we've finally got this project under way and Artificial Intelligence is one of the sites we'll be running the test on.</p>\n<p>Starting tomorrow, I'll be changing the site setting and closing and reopening will require only three votes. This test will run for 45 days and will be turned back to five votes to close and reopen while I review the data from the 13 sites. After we've seen the impact, I'll be posting results and, if there aren't negative impacts, we will change the setting to three permanently.</p>\n<p>A few weeks into this, I'll be posting a question here on meta to ask for your thoughts about this change, so you will have an opportunity to discuss the impact.</p>\n<p>Thank you so much for your patience while we got this prioritized and scheduled. There's a lot more information in the MSE post, so please review it.</p>\n"}, "1732": {"ParentId": 1731, "Score": 5, "Body": "<blockquote>\n<p>Is it okay treat the number of upvotes as correctness?</p>\n</blockquote>\n<p>Sometimes, there isn't a <em>single correct</em> answer to a question, so <a href=\"https://ai.stackexchange.com/help/privileges/vote-up\">upvotes may simply indicate the number of people that <strong>liked</strong> or <strong>agreed with</strong> with the contents of the answer</a>.</p>\n<p>We also have the case of a user with a lot of reputation (I cannot directly say who, but some people will know who I am talking about), but their answers are unconventional (e.g. provocative, long, contain unnecessary details, etc.) and sometimes are wrong. I'm not fully sure why this user gained so much reputation, but I believe that many inexperienced users upvoted their answers (and this user was also involved in some <em>voting irregularities</em> with multiple <a href=\"https://en.wikipedia.org/wiki/Sock_puppet_account\" rel=\"nofollow noreferrer\">sock puppet accounts</a>).</p>\n<p>So, upvotes do not necessarily mean that the answer is <em>generally correct</em> because</p>\n<ol>\n<li>there may be not a single correct answer to the question</li>\n<li>upvotes may have been given by inexperienced users (who blindly upvoted the answer by thinking it's useful, but without knowing whether the information is really correct or not)</li>\n</ol>\n<p>So, when reading an answer, you should take into account the upvotes, given that they represent the <strong>consensus</strong>, but maybe you should also <strong>consult another source of information</strong> that confirms the contents of the answer.</p>\n<p><a href=\"https://ai.meta.stackexchange.com/q/1660/2444\">I've been encouraging people not only to upvote but also to downvote content that is not good enough</a>. The higher the number of upvotes, the higher the consensus, but, especially in our community, the number of upvotes can sometimes be misleading, given that we do not have a big number of experts, so many votes are cast by inexperienced users. You can see the voters <a href=\"https://ai.stackexchange.com/users?tab=Voters&amp;filter=all\">here</a>. You should also not blindly trust a user only because he has a high reputation. Of course, users with high reputation are more likely to be &quot;correct&quot;, but, especially when you're not familiar with the topic, as I said, you should consult another source of information, ask for more details, ask for references, etc.</p>\n"}, "1733": {"ParentId": 1731, "Score": 2, "Body": "<p>I see the main purpose of Stack as vetting information.  Q&amp;A, which is the main purpose, is subordinate to the purpose of vetting information, in that Q&amp;A has little value when information is not sufficiently challenged.</p>\n<p>(This likely explains why Stack is so robust, where reddit and Quora continue to be problematic.)</p>\n<p>Ultimately, users need to read and digest the answers, and vet the citations where relevant, to determine the reliability of a given answer.</p>\n"}, "1735": {"ParentId": 1734, "Score": 3, "Body": "<p>If you think that a question can potentially be <strong>useful</strong> for future readers, you should not delete it, even when you have found the answer to your question in the meanwhile, because questions can also be valuable/relevant not just to the original asker but to future visitors of the site too (see the section &quot;<strong>Make it relevant to others</strong>&quot; <a href=\"https://ai.stackexchange.com/help/how-to-ask\">here</a>).</p>\n<p>Of course, if you have found an answer to your own question, you can clearly write a formal answer below your question (especially when you can add a different perspective or more info to what might have been already stated in other answers) or maybe just leave a comment under it to explain that more info can be found in another specific source.</p>\n<p>In any case, it's up to you to decide whether you want or not to delete your question, so <a href=\"https://ai.stackexchange.com/help/deleted-questions\">you can delete your question, provided that nobody has yet given an answer that has already been upvoted</a>.</p>\n<p>Note that <a href=\"https://ai.stackexchange.com/posts/27725/timeline#history_b82d8867-5da2-48c9-8b56-ac1a12196a3b\">the specific post that you are mentioning</a> has become a <a href=\"https://meta.stackexchange.com/q/60756\">hot post</a>, so you should really not delete it, as the system has detected that it can potentially be interesting to more people, and you can't also delete it because an upvoted answer has already been given (at this point, you could request a moderator to delete it, but I wouldn't advise you to do it for the reasons just mentioned above).</p>\n"}, "1739": {"ParentId": 1738, "Score": 3, "Body": "<p>That post was closed after the vote of 3 community members (including myself). It would have been closed anyway even if I was not a moderator, given that, right now, <a href=\"https://ai.meta.stackexchange.com/a/1730/2444\">only 3 votes are required to close a post on this site</a>. The post was later <em>automatically</em> deleted by the system (the system automatically deletes posts that have no answer and have been downvoted after a while).</p>\n<p>So, what is unclear in your post? Many things. For example, I don't understand the following paragraph</p>\n<blockquote>\n<p>Based of ai nature(needs to information and Calculayion unit) I guess, it could do the time traveling in the our univerese by finding some calculation unit for doing it's calculation and do its calculation for funding the challenge of time traveling puzzles like</p>\n</blockquote>\n<p>Why don't I understand this paragraph? Here are a few questions that come to my mind after having read it.</p>\n<ol>\n<li>What is &quot;ai nature&quot;?</li>\n<li>What's the meaning of &quot;(needs to information and Calculayion unit)&quot; and how is it related to &quot;ai nature&quot;?</li>\n<li>...</li>\n</ol>\n<p>I could go on and on, but I guess it should be clear now that the post was unclear. If this was just a &quot;language issue&quot;, I would suggest that you write the post in your language first, then use Google Translate or DeepL to translate from your native language to English. Moreover, before posting again, please, take some time to correct the typos and read <a href=\"https://ai.stackexchange.com/help/how-to-ask\">this</a>.</p>\n"}, "1741": {"ParentId": 1740, "Score": 5, "Body": "<p>You give three good reasons why many experienced users here are not very active or as active as you and I would like. Unfortunately, this is a problem that exists for a long time. There aren't and there haven't been many active experts on this site (from my perspective, without looking into the details/statistics, only 2-3 users regularly answer questions and almost nobody cares about editing posts to clarify them, although I've observed a small improvement in this area in the last weeks).</p>\n<p>In my case, I am busier now than in the past two years because of my professional activity, so my activity on the site has gone down a little bit, although I try to visit the site every day and even several times a day, but, unfortunately, I am not able to edit as many posts as I used to in the past and to provide answers regularly, which sometimes require a little bit of time and effort. I've actually stopped contributing to other Stack Exchange sites in order to focus on this site, which, as you also noticed, requires more experts, in order to make new users more engaged.</p>\n<p>I think that we haven't yet attracted many experts because experts in an AI topic are typically very busy (solving their problems in research, academia or industry), so typically you will not find many people that are doing active serious research on an AI topic here.</p>\n<p>To attract more experts, we could advertise our site and talk about this site to people that are interested in AI. However, to attract more experts, I think it's very important to keep the quality of the site high. So, for instance, if you see a bad question/answer, you should downvote it. If you see a post that is not written clearly, either downvote it or, if you have time, edit it to improve its clarity and structure. I've been trying to do this for a long time. I've noticed a little bit of progress in terms of people providing answers, but not as much as I would like: a new user comes for a few weeks or months, another one goes for many months or forever. So, if you really believe in this site, as I do, stay around and try to <a href=\"https://ai.meta.stackexchange.com/q/1686/2444\">help the community in whatever way you can</a> :)</p>\n"}, "2742": {"ParentId": 2741, "Score": 7, "Body": "<p>There have been more closed posts by the non-mod community members, so I've not intervened as much as I used to. When I've come across a post that should be closed, in multiple cases, I restrained myself from doing that in order to understand if it was going to be closed later by our members, and, in most cases, that really happened, which is a good thing in order for the community to be more self-sustainable (and so that I can have more free time).</p>\n<p>So, from my point of view, the experiment is going well, and the 3-close vote should be permanent, in particular, because I don't think that our community will grow significantly (in the next months or even years) to the point of having multiple active users involved in this task, if this has not happened so far (and we have been around for 4 years).</p>\n<p>I also think that, even though there's a higher chance of false positives (posts that are closed that should not have been closed) with only 3 votes compared to 5, the disadvantage is really minor compared to the false negatives (posts that should have been closed but weren't), because, in my view, they deteriorate the quality of the site (and, from my experience, it's rarely the case that post that was closed should be reopened).</p>\n"}, "2743": {"ParentId": 1740, "Score": -3, "Body": "<blockquote>\n<p>My question: Why do many (domain) expert users remain silent or calm?</p>\n</blockquote>\n<ol>\n<li>SE value doesn't our time given than <a href=\"https://ai.meta.stackexchange.com/q/4/4\">AI, CV and DS are ~90% duplicate of one another</a>.</li>\n<li>SE value doesn't our content: <a href=\"https://meta.stackexchange.com/q/355097/178179\">roomba</a>, <a href=\"https://meta.stackexchange.com/q/269392/178179\">deletions</a>, <a href=\"https://meta.stackexchange.com/q/359132/178179\">unexplained closures</a>, <a href=\"https://meta.stackexchange.com/q/355329/178179\">unexplained downvotes</a>, etc.</li>\n</ol>\n<p>My question: Why contribute in that context?</p>\n"}, "2744": {"ParentId": 1740, "Score": 2, "Body": "<p>I think I can only really speak for myself, but for me it's very much simply just this one:</p>\n<blockquote>\n<ol start=\"3\">\n<li>They are busy with their professional or personal activities;</li>\n</ol>\n</blockquote>\n<p>I used to be much more active a while ago than I am now, and that decline in activity is very much solely because my energy goes towards other stuff. For me, I think it's also simply something that comes in... waves? Sometimes there's a period of time where I'm in the mood for spending a significant amount of my spare time on stackexchange sites, and sometimes I'm not. That's not due to anything about the site itself though.</p>\n<p>For me, it's certainly not about preferring other stackexchange sites. In fact, usually when I'm active, I tend to be active on multiple of those sites at the same time. And when I'm not, I'm inactive in all of them at the same time.</p>\n"}, "2745": {"ParentId": 1740, "Score": 2, "Body": "<p>I find the types of questions on the AI SE are often hard to answer. A lot of questions are about the latest ML/DL fad, where someone tries something out and gets stuck. And I don't have the time to wade through pages of error messages to diagnose something. As I do that in my job already, I also don't feel inclined to do that on here.</p>\n<p>The questions I try to answer are mostly about 'old school' AI/NLP stuff, which has somewhat gone out of fashion in the public eye, but is still widely used in actual applications (because it works). But there are fewer and fewer of them.</p>\n<p>At least it's not as bad as on some of the language SEs, where grammar fanatics downvote anything that doesn't comply with their favourite grammar rules they learned in school decades ago...</p>\n"}, "2747": {"ParentId": 2746, "Score": 6, "Body": "<p>I'm not sure if there are any... &quot;official&quot; rules for something like this on the site. Probably not. Personally, I think it's always useful to explicitly mention when you're not sure or confident about something though. The more specific you can make this, the better. If I'm sure about a large part of my answer, but not about a small detail somewhere, I'd explicitly mention it there. If you can also concretely describe <strong>why</strong> you're not sure about something, or which assumptions you make (that may be wrong) that lead you to whatever conclusion you're not 100% sure about, even better!</p>\n"}, "2748": {"ParentId": 2746, "Score": 4, "Body": "<p>In addition to what was written in the other answer, which I agree with (so, generally, if you think you're unsure about something you should inform the reader, as misinformation can hurt the readers), I think it's important to note that, ideally, people that are also familiar with the topic or know whether your answer is correct or not are expected to upvote or downvote your answer (depending on whether it's correct or incorrect) or leave a comment.</p>\n<p>So, even if you didn't leave that disclaimer, in my view, incorrect answers should be downvoted, independently of whether the OP will fix the mistakes later or not (note that I didn't even read your answer and I don't really know if it's correct or not, but this is a general suggestion). Downvoting should not be used to personally attack someone, but it's our tool to determine what is good/correct/useless or bad/incorrect/useful content, but, unfortunately, not all people understand this.</p>\n"}, "2750": {"ParentId": 2749, "Score": 4, "Body": "<p>I agree with your points. This is a question that I've been asking myself for a long time, but I don't have a definitive answer/solution. Some potential solutions are</p>\n<ol>\n<li>Advertise our website (but not sure how and where); I've tried to do this sporadically and not very seriously (e.g. by pasting links on other chats, but this actually led to some hot debates between me and others, so I've stopped doing this)</li>\n<li>Talk about this site to your friends/colleagues/classmates (when you have the occasion)</li>\n<li>Mention the name of this site in events like conferences or workshops</li>\n</ol>\n<p>We should highlight the strengths of our site and we should especially try to attract users that are interested in those strengths and topics. We tend to attract several users interested in reinforcement learning (which is very nice, given that RL is very central to AI), but, unfortunately, we do not attract many qualified users in other areas, like the philosophy of AI, cognitive architectures, AGI, evolutionary computation or even just the regular machine learning topics.</p>\n"}, "2752": {"ParentId": 2751, "Score": 1, "Body": "<p>In theory, this is a good idea, in my opinion. In practice, Stack Exchange websites do not seem to like or want to collaborate with each other (at least, this is my impression).</p>\n<p>Why? Because I tried to do something similar in the past (like publishing links to some of the interesting posts on our site on their chat rooms or stating that RL questions can also be asked here and, in some cases, I said &quot;should be asked here&quot; because RL is central to AI, in my view: this &quot;should&quot; was probably what scared or made them angry, because RL is also on-topic there...), although without officially asking them (which was probably a mistake), but the guys at Cross Validation Stack Exchange didn't really like my actions, given that, in my view, they feel threatened that this can reduce their number of users and some of them would argue that our site shouldn't exist because they already cover a big part of our scope, which is true, although our site also covers topics that they do not cover and we focus on Artificial Intelligence and not Statistics, that's why we exist, I would say.</p>\n<p>In any case, this is something that should also be asked on their metas to really understand what the status/consensus is now. In my view, collaboration can only help us and them. However, to be honest, I will not invest more of my energies and free time on these debates with them because I already lost too much time and effort in vain (but I admit that my approach in the past was not ideal and diplomatic, to start with, and that might have contributed to the unsuccessful attempts to try to attract more experts and users to our site). This does not mean that you or others can't try to do that by starting with asking the same question or proposing the same idea on their metas.</p>\n"}, "2754": {"ParentId": 2753, "Score": 1, "Body": "<p>Those two questions (especially, the second one) are currently off-topic here, as they fall under the general category &quot;software recommendations&quot;, which is off-topic here, although there may be some exceptions (e.g. questions related to AGI may not be closed as off-topic, as they may not be on-topic anywhere else and only people that visit our site may know the answer to those questions). You could try asking this type of question on <a href=\"https://datascience.stackexchange.com/\">Data Science Stack Exchange</a> or <a href=\"https://softwarerecs.stackexchange.com/\">Software Recommendations Stack Exchange</a>. We have those tags because some questions may involve those libraries, but I guess we shouldn't have many posts tagged with them. However, a question like &quot;<a href=\"https://ai.stackexchange.com/q/3494/2444\">Why is Python widely used AI?</a>&quot; may not be closed as off-topic, as this is more an &quot;implementation&quot;/general question. To be honest, it's not always clear even to me where the boundary is, but, generally, <em>specific</em> programming issues are off-topic here. See our <a href=\"https://ai.stackexchange.com/help/on-topic\">on-topic page</a> for more info and examples.</p>\n<p>Note that our site is still subject to change in scope (we're still a public beta site), so we can still discuss changes to our on-topic page, but this type of question has been asked multiple times here and, generally, people seem to agree that programming questions (which should be distinguished from &quot;implementation&quot; questions: again, the boundaries are fuzzy) should be off-topic.</p>\n"}, "2756": {"ParentId": 2755, "Score": 4, "Body": "<p>I am in favour of this type of question being on-topic here. In particular, it seems that those questions would be at the intersection of &quot;history of AI&quot; (which is on-topic here) and &quot;terminology&quot; (in the sense that you want to know something about terms). We have had some of those question in the past. I remember one that I actually provided an answer to which was never closed as off-topic and I had never considered it as such: <a href=\"https://ai.stackexchange.com/q/20044/2444\">Why is it called back-propagation?</a>.</p>\n"}, "2758": {"ParentId": 2757, "Score": 3, "Body": "<p>In theory, questions about any topic of a paper in machine learning, deep learning or neural networks are on-topic here, so I think your questions would be on-topic here, so you could try to ask them here, but ultimately it's your choice.</p>\n<p>The problem is: do we really have the people capable of answering questions on such advanced topics? I do <strong>not</strong> think so, at least, I don't think that the regular users have the required knowledge, but I could be wrong and maybe some new/irregular user would be able to answer your questions. Category theory is really an abstract subfield of math, which shouldn't be taught in any AI curriculum/programme. Maybe if you study functional programming with Haskell you will learn about some of the related concepts, but, in AI, I don't see many potential applications of category theory, and that paper may be a good example or not of a potential application.</p>\n<p>In any case, typically, you will not find many people capable of answering questions related to research papers, whether you ask them here or any other site. To understand a research paper, even for people involved in the field, requires some time and effort. In particular, in machine learning, it's not like reading a regular book or a tutorial: it's often a condensed reading that contains many technical/mathematical details that are not easily understandable, unless you really have a solid knowledge of the topic and prerequisites.</p>\n<p>By the way, I read your post on Math SE, and I don't see how your initial claims could be close to the truth. Why/how would category theory ever be able to overcome the current limitations of deep learning? Without reading that paper, I don't really see why/how, but I only have a vague idea of what category theory is.</p>\n"}, "2763": {"ParentId": 2762, "Score": 5, "Body": "<p>I am against this idea because there are already other sites (DS SE and Stack Overflow) that cover these programming issues.</p>\n<p>If we allowed this type of question, there would be more reasons to merge DS SE, CV SE, and AI SE, which, in my opinion, wouldn't really be a bad solution to the problem of having a limited number of experts, although, now, we cover topics that people that visit those other sites are or should not be really interested in (e.g. AGI) and people interested in AI and, in particular, AGI have a different ultimate goal than people interested only in ML or Statistics: AI is not just ML, that's why we exist.</p>\n<p>Other sites do or should not cover certain aspects that we cover, such as AGI, cognitive architectures, or superintelligence. Unfortunately, not many people ask questions about these topics here anymore and we wouldn't also have many people prepared to answer those questions (because there aren't really many people interested in or researching these topics anyway), and most of the questions are just about the regular ML topics, so these questions could also have been answered on CV SE. For example, I was expecting <a href=\"https://ai.stackexchange.com/q/28662/2444\">this question</a> to have at least more upvotes (not to say an answer, as I don't believe there aren't many people that could answer this question: maybe I am one of the few that could attempt to answer that question, but I have not done it yet), but, apparently, almost nobody is interested in AGI anymore.</p>\n<p>So, in my opinion, we should keep focusing on the <strong>theoretical</strong>, <strong>philosophical</strong>, and <strong>social</strong> aspects of Artificial Intelligence. In my view, it's fine to have a small community, provided that we can be self-sustained and we provide good-quality answers and ask good questions that can be useful in the future for anyone interested in AI and AGI. Moreover, it's also normal that we have many unanswered questions, as some of them are not trivial to answer or may not even have a definitive answer right now: there are still unsolved problems in AI, the first one being that we still don't know how to really create an AGI.</p>\n<p>(Personally, I don't really want to see questions of the form &quot;Why am I getting this IndexErrror in this ML program&quot; here on AI SE. Generally, I am not interested in solving other people's programming issues/bugs (although occasionally I may do that on Stack Overflow). I am interested in the theoretical aspects of AI, I am interested in RL, AGI, explainable AI, evolutionary algorithms, and computational learning theory. Of course, these are just my personal tastes, but this is the main reason why I decided to stick to this site.)</p>\n<p>So, if you're interested in programming, you should visit Stack Overflow. If you're interested in reinforcement learning, AGI (e.g. AIXI, Godel Machines, etc.), cognitive architectures, superintelligence, evolutionary algorithms, you should visit Artificial Intelligence Stack Exchange.</p>\n<p>Having said that, there may still be some room to expand or redefine our scope, but, right now, I don't see many ways to expand our scope other than allowing questions about programming issues here.</p>\n"}, "2764": {"ParentId": 2761, "Score": 1, "Body": "<p>We have had already <a href=\"https://ai.stackexchange.com/q/15594/2444\">a similar question</a> in the past, and, in the end, I closed it as &quot;too broad&quot;. It's unlikely that someone will have exactly that same question (i.e. it's unlikely that someone will be interested in a brief description of those <em>specific</em> models).</p>\n<p>I don't like this type of question where there could be potentially many different and/or overlapping answers for multiple reasons.</p>\n<ol>\n<li><p>A model that is widely used today may not be anymore in 5-10 years, so these answers would also become outdated.</p>\n</li>\n<li><p>A good answer to this question may require a lot of effort to write and prepare.</p>\n</li>\n<li><p>Nobody will probably be interested in all those <em>specific</em> models.</p>\n</li>\n<li><p>Answers could potentially overlap a lot, so we'd better just merge them in one single very long answer, which may also not be very pleasant to read</p>\n</li>\n</ol>\n<p>It would be better to ask for <strong>examples</strong> of models that could be used for the <strong>specific</strong> task that you want to solve. For example,</p>\n<blockquote>\n<p>What are <em>examples of</em> (or <em>the state-of-the-art</em>) models that potentially can successfully solve this specific task X or have been applied to solve similar problems to my problem X?</p>\n</blockquote>\n<p>Of course, you should first describe your task X.</p>\n<p>In fact, we created the tags <a href=\"https://ai.stackexchange.com/questions/tagged/model-request\" class=\"post-tag\" title=\"show questions tagged &#39;model-request&#39;\" rel=\"tag\">model-request</a> and <a href=\"https://ai.stackexchange.com/questions/tagged/algorithm-request\" class=\"post-tag\" title=\"show questions tagged &#39;algorithm-request&#39;\" rel=\"tag\">algorithm-request</a> for this purpose.</p>\n<p>Why do I like more this type of question? For multiple reasons.</p>\n<ol>\n<li><p>If people are interested just in knowing 1-2 examples of models (in this case) that could solve their task (this can happen frequently in case people are new to ML), all answers should address their concerns.</p>\n</li>\n<li><p>The answers to the questions would require less effort to write, as people wouldn't need to make a review, but just need to come up with an example (and maybe also argue why they are suggesting it)</p>\n</li>\n</ol>\n<p>If you're interested in literature reviews, you could specifically ask for that. We have the tag <a href=\"https://ai.stackexchange.com/questions/tagged/reference-request\" class=\"post-tag\" title=\"show questions tagged &#39;reference-request&#39;\" rel=\"tag\">reference-request</a> that could be used in those cases.</p>\n"}, "2765": {"ParentId": 1736, "Score": 2, "Body": "<p>I don't think I have ever <strong>fully</strong> read any technical book or textbook (on an AI-related subject/topic). Typically, I start reading a book, then, after a while, I don't have more time to read it, so I interrupt the reading, which I may resume later.</p>\n<p>So, I have partially read multiple books and consulted others multiple times. Below, I list some of the books that I read or consulted the most, as far as I remember. There are probably other books that I've partially read. Currently, I'm also reading another book (not mentioned below), and I may start reading another one. I will be updating this list.</p>\n<h3 id=\"artificial-intelligence-a8s6\">Artificial Intelligence</h3>\n<ul>\n<li><strong>Reinforcement Learning: An Introduction</strong> (by Barto and Sutton, this is probably the book I read the most, almost all chapters of the first edition, and I regularly consult it)</li>\n<li><strong>Artificial Intelligence: A Modern Approach</strong> (by Russell and Norvig, I read several chapters, especially the ones related to search, and I often consult it)</li>\n<li><strong>Superintelligence: Paths, Dangers, Strategies</strong> (by Bostrom, the first chapters, then I got tired of reading the speculations)</li>\n<li><strong>Universal Artificial Intelligence: Sequential Decisions Based On Algorithmic Probability</strong> (by Hutter I think only the first and maybe second chapters; very technical book, so it's not an easy reading at all, even if you're familiar with the theory of computation)</li>\n<li><strong>Multiple view geometry in computer vision</strong> (by Richard Hartley; this book introduces some traditional computer vision topics; I didn't read much)</li>\n</ul>\n<h3 id=\"computer-science-ki2a\">Computer Science</h3>\n<ul>\n<li><strong>Introduction to Algorithms</strong> (by CLRS, any computer scientist should be aware of this book; do you want to know about red-black trees or binary search? this is the book!)</li>\n<li><strong>Introduction to the Theory of Computation</strong> (by Sipser, which is one of my favorite books, among all of these; do you want to know about finite-state machines, push-down automata, Turing machines, formal languages, the pumping lemma, the Halting problem, undecidability, complexity theory [e.g. NP-completeness], reducibility, etc.)? This is the book you should read!)</li>\n<li><strong>Quantum Computing for Computer Scientists</strong> (by Mannucci and Yanofsky, which is also one of my favorite books)</li>\n<li><strong>Computational Geometry: Algorithms and Applications</strong> (by Mark de Berg et al., I didn't read much)</li>\n<li><strong>Structured Computer Organization</strong> (by Andrew S. Tanenbaum; we had used this book in a course &quot;Computer Architecture&quot; during the first year of my bachelor's in CS; I don't remember what I had read...)</li>\n</ul>\n<h3 id=\"math-d2bs\">Math</h3>\n<ul>\n<li><strong>Elementary Analysis: The Theory of Calculus</strong> (by Ross; this is a very nice book that will help you consolidate your knowledge of calculus, if you go through the details, proofs, etc.; my professor, when I was doing my bachelor's, in fact, noticed, from my one of my exams, that I had read the book; I didn't fully read it, only a few chapters, but it's a book to keep an eye on if you want to have a solid knowledge of the topic)</li>\n</ul>\n"}, "2767": {"ParentId": 2766, "Score": 7, "Body": "<p>Yes, you <em>can</em> and <em>should</em> remove those sentences, as <a href=\"https://ai.stackexchange.com/help/behavior\">our policy</a> states</p>\n<blockquote>\n<p><strong>Do not use signature, taglines, greetings, thanks and other chit chat.</strong></p>\n<p>Every post you make is already \u201csigned\u201d with your standard user card, which links directly back to your user page. Your user page belongs to you, so fill it with information about your interests, links to stuff you\u2019ve worked on, or whatever else you like!</p>\n<p><strong>Thanks and other statements of appreciation are unnecessary, and like other chit chat should not be included.</strong></p>\n<p><strong>If you use signatures, taglines, greetings, thanks or other chit chat, it will be removed to reduce noise in the questions and answers.</strong></p>\n</blockquote>\n"}, "2769": {"ParentId": 2768, "Score": 5, "Body": "<p>I use the site RSS feed <a href=\"https://ai.stackexchange.com/feeds\">https://ai.stackexchange.com/feeds</a> to see recent questions and pick out the ones I want to contribute to. I use it with a third-party feed aggregator (Feedly), but I don't think that is important.</p>\n<p>The RSS feed link is on right hand side underneath the Hot Network Questions list, and looks like this: <a href=\"https://i.stack.imgur.com/2y3q1.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/2y3q1.png\" alt=\"enter image description here\" /></a></p>\n<p>Different feeds appear on each page in Stack Exchange, and if for example you filter questions to specific tags, the feed link that you see will also be filtered. AI Stack Exchange is relatively quiet, so I don't filter. I do filter on Cross-Validated.</p>\n<p>Sometimes even though I know nothing about a topic I will read along so I can learn something (I'm not only here to write answers).</p>\n"}, "2770": {"ParentId": 2768, "Score": 5, "Body": "<p>You can see in <a href=\"https://ai.stackexchange.com/users/2444/nbro?tab=profile\">my profile</a> that I've visited the site 908 consecutive times out of 1097 days that I've visited it, so I've been visiting the site at least once per day for more than 2 years.</p>\n<p>Having said that, I am a bit chaotic and irregular, so I do not visit Artificial Intelligence Stack Exchange always at the same time or use the same approach. I can visit the site and contribute to it (e.g. by answering questions or editing posts) in the morning or late at night. If I feel bored, I may visit the site more frequently.</p>\n<p>One of the first things that I do when I visit the site is to take a look at the latest questions. If I have some time or feel bored, I try to read a few of them, maybe leave a comment asking for clarifications (if that's necessary), edit the post if it contains mistakes or its clarity and readability can be improved, or maybe upvote/downvote it (depending on the quality). If I know the answer to the question and it can be written in a short time (and I have time to write it), I may decide to write an answer immediately, but sometimes I leave some time for others to answer it, so that it's not always me that answers it, or I may keep a tab opened for a few days, until I have the time to answer it (sometimes, those tabs are closed to reduce the noise or because I lost interest in those questions). Sometimes, I do not remember or know all the details needed to answer an interesting question that I want to answer, so I may leave a tab opened with the question, so that I can answer it later, after having done a little bit of research (e.g. take a look at a reference book or paper) that contains the details that I forgot or don't know.</p>\n<p>Occasionally, I may also read posts that have popped up in the &quot;Top Questions&quot; section (i.e. the section that appears when you visit our site), which may also contain old posts &quot;bumped by the community user&quot;. Moreover, sometimes, I also read posts that are connected to a post that I'm already reading (right section). For example, if I see a post with a weird or unclear title, I may read it, in order to try to improve the title. I've done this many times in the past. That's also why you see many posts edited by me.</p>\n<p>As a moderator, I also have other responsibilities. In particular, recently, I've been trying to verify that the posts closed by other community members have been correctly closed. See <a href=\"https://ai.meta.stackexchange.com/q/2741/2444\">this</a>. Occasionally, I also look at the queues, but I leave this job for other community members or moderators, as I already spent a lot of time reading the latest questions/posts. There are also other tasks that I may need to do as a moderator, but I don't want to dwell on that here, as the question doesn't seem to be about what a moderator may be doing in the background (and I couldn't and don't want to share everything anyway).</p>\n<p>Similar to what Neil does, I also have a few private chat rooms where, thanks to the RSS feeds, I can regularly read about posts tagged with topics that I may be interested in. Often, I forget about these chat rooms, as I don't have much time to read everything.</p>\n"}, "2772": {"ParentId": 2771, "Score": 2, "Body": "<p>Just to quickly comment on that particular situation:</p>\n<p>Since that particular discussion went on for way too long anyway, I moved it in its entirety to <a href=\"https://chat.stackexchange.com/rooms/128104/discussion-on-question-by-hanugm-is-it-abuse-of-notation-to-use-tilde-operator-i\">a chat room</a>. Which kind of resolves all those flags on all those comments automatically. If it had not been moved into a chatroom, personally I would have agreed with the second flag (the &quot;no longer needed flag&quot;), but not agreed with the first flag (the &quot;unfriendly/unkind&quot;) flag. Nbro had already rightfully pointed out that meta would be the appropriate place to continue that topic, and it's fine to try to put a stop to that discussion continuing on forever.</p>\n<hr />\n<p>To respond to the actual questions:</p>\n<blockquote>\n<p>So, do we have a code of conduct in place, dictating that in cases were a mod is involved, the relevant flags should not be handled by the involved mod?</p>\n<ul>\n<li>If yes, was this code of conduct followed in the case described above?</li>\n<li>If no, should we? Does it makes sense that cases were a mod is involved cannot be resolved by decisions of the involved mod?</li>\n</ul>\n</blockquote>\n<p>The only thing I've been able to find on this topic is <a href=\"https://meta.stackexchange.com/q/306740/376651\">this meta discussion</a>. There doesn't really seem to be such an official rule, but it is sort of an unofficial rule... with a bunch of exceptions, because sometimes it really is just reasonable and useful for a moderator to immediately handle flags on their own content. Personally, yeah I think it makes sense to try to refrain from resolving flags on your own content, especially at the point in time where it turns out to be a contentious topic... but more so as a rule of thumb than as a hard rule.</p>\n"}, "2774": {"ParentId": 2773, "Score": 4, "Body": "<p>I would say that your question was perfectly fine. If a user doesn't want to say something about their intentions, it is also fine. If you think you're bothering/annoying a user, it may be a good idea to stop the discussion there (at least for a while), but, in any case, your question was totally fine from my perspective and, as far as I know, there's no policy that would prevent you from asking such a question (that would be quite absurd, in my opinion).</p>\n"}, "2775": {"ParentId": 2773, "Score": 4, "Body": "<p>Since the user you are referring to is me, let me clarify some things to avoid misunderstandings.</p>\n<p>In principle, there is <strong>absolutely nothing wrong</strong> in asking such questions in the comments.</p>\n<p>The whole issue has also nothing to do with &quot;friendliness&quot; (we can disagree and still be friendly); in hindsight, I should have worded the comment slightly differently, as:</p>\n<blockquote>\n<p>I <strong>need</strong> not be asked beforehand if I intent or not to post anything on Meta.</p>\n</blockquote>\n<p>and that's all.</p>\n<p>IMO, I just think that such questions of <em>intent</em> are not particularly useful, and that's all. What if I had replied &quot;<em>yes, I will</em>&quot; and then do nothing (because I am busy, away, changed my mind etc)? What if I had replied &quot;<em>no, I will not</em>&quot;, and then, on a second thought (everyone is entitled to a 2nd thought, right?), proceeded to open a thread at Meta? Why should I commit, at the certain point of time, about doing or not doing something in the future, and why this (non)-commitment from my side should affect you and your own intended actions? Even if we both decided to open a Meta question, there is no guarantee of sorts that these questions would be identical (either in spirit or in letter).</p>\n<p>So, while nothing wrong, my <em>personal recommendation</em> here would be to refrain from doing it, only because it does not seem to me to be particularly useful or productive, and not for any other reason. Even if the recipient chooses <em>not</em> to reply (for any reason, including that they have not made up their mind yet), they run the danger of looking somewhat rude; why you would want to put anyone in such a (potentially awkward) situation?</p>\n<p>So, that was all behind my own comment, and nothing more. Hope it is clear now, and if it came out in any unfriendly way, let me hereby assure you that something like that was nowhere close to my intentions.</p>\n"}, "2777": {"ParentId": 2776, "Score": 7, "Body": "<p>I don't know if someone has done that in the past or not, but I don't think it's a very good idea. These users probably don't contribute to the site anymore because they don't have the time or desire to do it. Most, if not all, of them are volunteers, like you and me, so we should not bother them with these requests.</p>\n<p>It seems to me that a user usually remains because he likes the idea of helping others and maybe also learning something by reading other people's answers/questions and, in the meantime, he/she also finds the time to do it. I've stayed around because I thought that this community could be useful and I like to help others whenever I can, so not because someone asked me to do it.</p>\n"}, "2779": {"ParentId": 2778, "Score": 4, "Body": "<p>I think it's not just fine but you should remove the upvote and an unaccept the answer until you are sure that the answer is correct or not (note that this is just my personal suggestion, so it's not a policy). You could, for example, leave the upvote because you think the answer is useful, although it may not be (fully) correct. That's also fine (but if it turns out to be wrong, you should remove the upvote, so that it's not misleading). Of course, the answerer may not like the idea. However, once you know the answer was actually correct, you can upvote and accept it again. It may not be a good idea to share this with the answerer, as they may take it personally (that's why votes are anonymous), but you're free to explain your decision to the answerer, if you think they deserve an explanation.</p>\n"}, "2780": {"ParentId": 2778, "Score": 2, "Body": "<p>This behavior is fully OK, and fully consistent with the site policies as well; there is a reason why such actions are indeed permitted by the site functionality.</p>\n<p>IMO, the site policies should be even more relaxed in such matters: currently, you cannot remove your vote (up or down) after a certain time, unless the post gets edited - but I am not sure how useful such a restriction is (except maybe for forcing you to be more careful when voting, but I doubt this is useful either).</p>\n"}, "2783": {"ParentId": 2782, "Score": 1, "Body": "<p>I am ambiguous about it and almost completely biased towards not becoming a moderator now.</p>\n<p><strong>Reasons</strong>:</p>\n<p>I am a beginner in AI and hence I don't know much of the concepts in Artificial Intelligence. I may get confusions easily in editing or other tasks.</p>\n<p>Along with less expertise in AI, I feel that my style of framing sentences may not be correctly interpret-able to many users on our main site.</p>\n<p>But, I want to continue my contribution in some or other way as a member of or community rather than a moderator which needs some skills that currently I don't have.</p>\n"}, "2786": {"ParentId": 2785, "Score": 2, "Body": "<blockquote>\n<p>Is it allowed to do?</p>\n</blockquote>\n<p>No, this is not allowed in general for images, or in fact <em>any</em> content that you discover online or anywhere else.</p>\n<p>To use an image in a question or answer, you need to be the original image author, or to have been given copyright that is compatible with uploading to Stack Exchange.</p>\n<p>The Stack Exchange terms and conditions <a href=\"https://stackoverflow.com/legal/terms-of-service#licensing\">include a section on content permissions</a> and this has a section called &quot;Subscriber Content&quot; which covers this in detail.</p>\n<p>In short, all content that you post - any question or answer - is licensed to the Stack Exhchange by you under <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" rel=\"nofollow noreferrer\">a Creative Commons v4 license</a>. You must have the rights to do this, otherwise you are in copyright violation (and so is Stack Exchange, but they can hold you responsible).</p>\n<p>As well as being an image author, you may have received it in a way that means it is OK to re-use it in Create Commons content. For instance, it may be public domain or already licensed as Creative Commons or compatible license.</p>\n<p>If you are not sure about rights to re-use an image on the site, then you have a few options:</p>\n<ul>\n<li><p>Link the image where you found it, don't embed it.</p>\n</li>\n<li><p>Contact the image author and ask.</p>\n</li>\n<li><p>Search for a similar image that is Creative Commons already. Google image search allows you to do this, and <a href=\"https://commons.wikimedia.org/wiki/Main_Page\" rel=\"nofollow noreferrer\">Wikimedia Commons</a> allows you to search for images on its site that might cover your needs.</p>\n</li>\n<li><p>Re-draw your own version.</p>\n</li>\n</ul>\n<p>A lot of people do not understand the fine details of copyright rules. That also means that a lot of technically invalid content gets posted, and also that a fair amount of that is de-facto OK, because the original owner does not mind (they just don't know or care about the licensing to do the work to share legally). However, the <em>safe</em> advice is to not use images that you are not sure about.</p>\n"}, "2788": {"ParentId": 2787, "Score": 2, "Body": "<p>Yes, to attract attention to your posts/questions, you can start a <strong>bounty</strong> on them. You should carefully read <a href=\"https://ai.stackexchange.com/help/bounty\">this</a>, which explains what a bounty is and what the consequences are (i.e. you will not get your reputation back even though you're not satisfied with the answers or it's not even guaranteed that you will get an answer at all).</p>\n"}, "2790": {"ParentId": 2781, "Score": 1, "Body": "<h3>Short Version:</h3>\n<p>There's no official limit. StackOverflow has the most, with 24, but sites the size of AI.SE typically have 3-4 (though AI.SE has had more simultaneously in the past).</p>\n<hr>\n<h3>Long Version:</h3>\n<p>StackOverflow <a href=\"https://stackoverflow.com/users?tab=moderators\">currently has 24 \u2666moderators</a> but they also get 10 million visits/day and 5.7k questions/day right now.</p>\n<p>Here's the sites that have approximately the same number of questions/day as Artificial Intelligence SE:</p>\n<p><a href=\"https://i.stack.imgur.com/jNugV.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/jNugV.png\" alt=\"enter image description here\" /></a></p>\n<ul>\n<li>Biblical Hermeneutics currently has 3 \u2666mods.</li>\n<li>Sharepoint currently has 3 \u2666mods.</li>\n<li>Software Engineering currently has 3 \u2666mods.</li>\n<li>Bitcoin currently has 3 \u2666mods.</li>\n<li>Islam currently has 3 \u2666mods.</li>\n</ul>\n<p>However, Artificial Intelligence did have more simultaneous \u2666mods in the past, and this can often happen if for example the current \u2666team requests for it due to too much workload or whatever reason they feel appropriate.</p>\n<p>I'll note the following:</p>\n<ul>\n<li>Role Playing Games currently has 7.8 questions/day but 4 \u2666mods.</li>\n<li>Raspberry Pi currently has 7.6 questions/day but 4 \u2666mods</li>\n<li>Biology currently has 6.4 questions/day (maybe more when COVID began) but 4 \u2666mods</li>\n<li>Astronomy currently has 6.3 questions/day but 4 \u2666mods</li>\n<li>The Workplace currently has 5.9<sup>1</sup> questions/day but 4 \u2666mods</li>\n<li>Meta Stack Exchange currently has 5.7<sup>2</sup> questions/day but 4 \u2666mods</li>\n<li>Webmasters currently has 5.4<sup>2</sup> questions/day but they're currently electing their 4th \u2666mod</li>\n<li>Hinduism currently has 5.2<sup>3</sup> questions/day but 4 \u2666mods</li>\n<li>Travel currently has 5.1 questions/day (maybe more, or less? before COVID) but they're currently electing their 5th \u2666mod</li>\n<li>Bicycles currently has 5.1 questions/day but 4 \u2666mods</li>\n<li>Aviation currently has 5.0 questions/day but 4 \u2666mods</li>\n<li>Christianity currently has 4.4 questions/day but 4 \u2666mods</li>\n<li>Puzzling currently has 3.9 questions/day but 4 \u2666mods</li>\n<li>Photography currently has 3.4 questions/day but 4 \u2666mods</li>\n<li>Seasoned Advice currently has 3.1 questions/day<sup>4</sup> but 4 \u2666mods</li>\n<li>Latin Language currently has 2.9 questions/day<sup>4</sup> but 4 \u2666mods</li>\n<li>Psychology and Neuroscience currently has 2.9 questions/day<sup>4</sup> but 4 \u2666mods</li>\n<li>History currently has 2.6<sup>4</sup> questions/day but 4 \u2666mods</li>\n<li>Literature currently has 1.9<sup>5</sup> questions/day but 4 \u2666mods</li>\n<li>Skeptics currently has 1.5<sup>6</sup>   questions/day but 4 \u2666mods</li>\n<li>Code Golf currently has 1.4<sup>7</sup> questions/day but  4 \u2666mods</li>\n<li>Interpersonal Skills has 0.9<sup>8</sup> questions/day but 5 \u2666mods !!!</li>\n</ul>\n<p>Very few sites have only 2 \u2666mods:</p>\n<ul>\n<li>Engineering currently has 5.1 questions/day but only 2 \u2666mods</li>\n<li>\u0420\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a currently has 3.3 questions/day but only 2 \u2666mods</li>\n<li>Hardware Recommendations currently has 2.4 questions/day but only 2 \u2666mods</li>\n<li>HSM currently has 1.4 questions/day but only 2 \u2666mods</li>\n<li>Tezos currently has 1.4 questions/day but only 2 \u2666mods</li>\n<li>Computer Graphics currently has 1.1 questions/day but only 2 \u2666mods (the last election had 2 openings but only 1 candidate so they have 2 instead of 3)</li>\n<li>Korean Language currently has 1.0 questions/day but only 2 \u2666mods</li>\n<li>Sound Design currently has 0.7 questions/day but only 2 \u2666mods</li>\n<li>Monero currently has 0.7 questions/day but only 2 \u2666mods</li>\n<li>Ask Patents currently has 0.4 questions/day but only 2 \u2666mods</li>\n<li>Freelancing currently has 0.4 questions/day but only 1 \u2666mods !!! (there's been multiple failed attempts at an election recently)</li>\n<li>Computer Science Educators currently has 0.4 questions/day but only 2 \u2666mods</li>\n<li>Homebrewing currently has 0.4 questions/day but only 2 \u2666mods</li>\n<li>Windows Phone currently has 0.1 questions/day but only 2 \u2666mods</li>\n<li>Constructed Languages currently has 0.1 questions/day but only 2 \u2666mods</li>\n<li>Iota currently has 0.0 questions/day and 3 \u2666mods (demonstrating that the site with least activity doesn't necessarily have the least \u2666mods).</li>\n</ul>\n<p>But this year a plethora of sites had fewer than 3 \u2666mods and gradually elections have been taking place to fill up those spots, so these sites might be next.</p>\n<p><strong>Finally I will note that:</strong></p>\n<ul>\n<li>Unix&amp;Linux currently has 53 questions/day but only 3 \u2666mods.</li>\n<li>TeX currently has 51 questions/day but only 3 \u2666mods.</li>\n<li>Salesforce currently has 40 questions/day but only 3 \u2666mods.</li>\n<li>Etherium currently has 28 questions/day but only 3 \u2666mods.</li>\n<li>Data Science currently has 21 questions/day but only 3 \u2666mods</li>\n<li>Database Administrators currently has 20 questions/day but only 3 \u2666mods</li>\n<li>Magneto currently has 20 questions/day but only 3 \u2666mods</li>\n<li>World Building currently has 14 questions/day but only 3 \u2666mods</li>\n<li>Law currently has 12 questions/day but only 3 \u2666mods</li>\n<li>Computer Science currently has 12 questions/day but only 3 \u2666mods</li>\n<li>Stack Overflow in Japanese currently has 11 questions/day but only 3 \u2666mods</li>\n<li>Web Applications currently has 11 questions/day but only 3 \u2666mods</li>\n<li>elementaryOS currently has 10 questions/day but only 3 \u2666mods</li>\n<li>Stack Overflow in Spanish currently has 98 questions/day but only 4 \u2666mods</li>\n<li>Unix&amp;Linux currently has 61 questions/day but only 4 \u2666mods.</li>\n</ul>\n<p>This covers all sites with more questions/day than AI.SE yet only 3 \u2666mods, and all sites with fewer questions/day than AI.SE yet more than 3 \u2666mods!</p>\n<ul>\n<li><sup>1</sup> Keep in mind that The Workplace gets an enormous volume of HNQ (see <a href=\"https://meta.stackexchange.com/q/298608/391772\">here</a>, <a href=\"https://meta.stackexchange.com/q/316934/391772\">here</a>, <a href=\"https://workplace.meta.stackexchange.com/q/5779/97330\">here</a> or the more recent discussion in which I was involved but can't currently find, haha) so it will likely need more moderation per question.</li>\n<li><sup>2</sup> MSE is where complaints about the SE network go, so it might not be surprising that more moderation/question may be necessary than normal (though one of the 4 of them was added only 2 about months ago).</li>\n<li><sup>3</sup> This is one of those rare cases where I happen to know a bit about why they got a 4th. The flags/day grew from whatever it was in 2017 (see the &quot;A year in moderation&quot; Meta post, to <a href=\"https://hinduism.meta.stackexchange.com/questions/2019/2020-potential-community-moderator-election-community-interest-check#comment10412_2019\">apparently 6/day</a> in 2020.</li>\n<li><sup>4</sup> This is another rare case where I happen to know that at least one has taken some breaks from activity in recent times, so there's really not as many active at any given time, as it may seem from the numbers.</li>\n<li><sup>5</sup> One quit then came back.</li>\n<li><sup>6</sup> Similar to footnote #1.</li>\n<li><sup>7</sup> Similar to footnote #1 above, but not long ago <a href=\"https://codegolf.meta.stackexchange.com/q/18477/91582\">they had only 1!</a>.</li>\n<li><sup>8</sup> They unusually had at least 4 appointed in 2018 without an election, then had 5 candidates compete for 1 position in 2019. The large need for moderation may have to do with the topic on the site!</li>\n</ul>\n"}, "2791": {"ParentId": 2789, "Score": 2, "Body": "<p>We tried to specify in <a href=\"https://ai.stackexchange.com/help/on-topic\">our on-topic page</a> examples of questions that would be off-topic here (see the section &quot;Off-topic&quot;), but we didn't provide an extensive list of types of questions that would be off-topic. I think we could indeed create a meta-post with a list of all types of questions that would be off-topic, but I am not sure if it's worth it, as the on-topic page should already be quite clear. Let me know what isn't clear enough by reading the on-topic page, so that we can clarify that.</p>\n"}, "2792": {"ParentId": 2787, "Score": 1, "Body": "<p>Bounties can be an incentive, by my sense is they are mostly attractive to people new to a given stack, who want to build initial rep quick.  (There are good reasons for this, as it confers a series of privileges.)</p>\n<p>When I'm new on a stack, I seek out questions I can answer to get basic mod privileges quickly, so I can start doing some &quot;housekeeping&quot; on those stacks when time permits.</p>\n<p>My sense is that users with sufficient rep often transition to answering the questions that pique their interest, or occupy a subject in which they feel it's important to educate.</p>\n<p>Since your rep is low, and you don't have a lot to spend, I might reserve bounties only for critical questions.</p>\n<p><em>(My own questions typically don't do well on any stack, and I've just had to accept that, but I still find participation in the stack community incredibly rewarding:)</em></p>\n"}, "2793": {"ParentId": 2784, "Score": 1, "Body": "<p>I reviewed the question, which I like very much, but here's why it was closed:</p>\n<p>It's more of a thesis that gets around to the question.  In the previous incarnation of this stack, we were allowing it.  But it becomes too easy to abuse, and so the community felt it was better not to allow.</p>\n<p>I don't see this question as that, but I think it would be more suitable if you addressed a single claim per question.  I want to see more of these questions, so I hope you'll give the subject another shot.</p>\n"}, "2794": {"ParentId": 2784, "Score": -1, "Body": "<p><strong>Repost of Question in question:</strong></p>\n<p>The following is an argument for why I don't think artificial general intelligence (AGI) is technologically feasible with <em>machine learning methods</em>. There are likely many flaws in my argument, but I do find the overall idea to be compelling.</p>\n<p><strong>Question.</strong> Is my argument valid? Are there any significant holes or logical fallacies? Has any form of this argument been made before?</p>\n<hr />\n<p><strong>TL;DR.</strong> Training an AGI would require resources (computational power and data) comparable to all the resources that nature has invested into the evolution of human beings. Given our current abilities, this does not seem feasible.</p>\n<p><strong>Claim 1.</strong> Most of human knowledge is encoded into DNA.</p>\n<p>Consider our knowledge of language. Why is it that the language model GPT-3 needed to be trained on hundreds of billions of words over thousands of GPUs to develop language skills comparable to what a human can develop in just several years? The answer is DNA. Humans already have language skills genetically hard-wired into them when they are born, which allows a human baby to learn language significantly faster than a computer can (this idea is similar to the [purely speculative] idea of a <a href=\"https://en.wikipedia.org/wiki/Language_acquisition_device\" rel=\"nofollow noreferrer\">language acquisition device</a>). More importantly, there is a huge difference in the amount of time and energy it takes a computer to learn language compared to a human. This huge difference indicates that most of an adult human's language knowledge is not learned within their short lifetime, but rather encoded through their DNA. A similar argument can be made for other aspects of human knowledge.</p>\n<p>So if most of human knowledge comes from DNA, how is this knowledge obtained? I argue that the answer lies in evolution.</p>\n<p><strong>Claim 2.</strong> Natural selection can be viewed as a machine learning system.</p>\n<p>To generate the DNA of an intelligent animal, let's suppose we treat this animal as a machine learning model. The parameters of this model are segments of DNA, and the optimization objective is to maximize the likelihood of an animal's survival. Natural selection trains this model via the following process:</p>\n<ol>\n<li><p>Start with <span class=\"math-container\">$n$</span> animals.</p>\n</li>\n<li><p>Let <span class=\"math-container\">$\\mathcal{L}$</span> be a function that computes the likelihood of an animal surviving. Apply this function to each of our <span class=\"math-container\">$n$</span> animals to determine whether they survive. Suppose at the end, we have <span class=\"math-container\">$n'$</span> animals remaining.</p>\n</li>\n<li><p>Let <span class=\"math-container\">$c$</span> be the number of children each animal gives birth to, on average. Using the <span class=\"math-container\">$n'$</span> available animals, mix and match their genetic codes and add random mutations to create <span class=\"math-container\">$cn'$</span> new animals.</p>\n</li>\n<li><p>Repeat steps 2 and 3 with <span class=\"math-container\">$n := cn'$</span>.</p>\n</li>\n</ol>\n<p>By definition, this process describes a machine learning algorithm. For instance, consider the following analogous method of training a neural network:</p>\n<ol>\n<li><p>Start with <span class=\"math-container\">$n$</span> neural networks with randomized weights.</p>\n</li>\n<li><p>Let <span class=\"math-container\">$\\mathcal{L}$</span> be the loss function of the neural network. Pick the <span class=\"math-container\">$n'$</span> neural networks with the smallest loss.</p>\n</li>\n<li><p>Let <span class=\"math-container\">$c$</span> be some constant. Using the <span class=\"math-container\">$n'$</span> available neural networks, mix and match their weights and make random adjustments to create <span class=\"math-container\">$cn'$</span> new neural networks.</p>\n</li>\n<li><p>Repeat steps 2 and 3 with <span class=\"math-container\">$n := cn'$</span>.</p>\n</li>\n</ol>\n<p>Of course, this is arguably much worse than backpropagation and gradient descent. I return to this point at the end of my argument.</p>\n<p><strong>Claim 3.</strong> Nature has invested significant computational power in \u201ctraining\u201d humans.</p>\n<p>We might think of nature as a large simulation. Every worldly event, whether it be the wind or the rain or the inner workings of a plant, requires \u201ccomputational power\u201d to execute. Furthermore, humans have taken hundreds of millions of years to train, and each year, natural selection has probably processed billions of animals (this number is just a wild guess, but I would say it's very conservative) that are relevant to the evolution of humans. Let's say it takes a modern computer, on average, one day to simulate the life of one such animal. Combining these estimates, the total amount of computational time <span class=\"math-container\">$T$</span> required to \u201ctrain\u201d a human is given by:</p>\n<p><span class=\"math-container\">$$\n\\begin{align}\nT &amp;= (\\text{# of years}) \\cdot (\\text{animals processed per year}) \\cdot (1 \\ \\text{day}) \\\\\n&amp;= 10^8 \\cdot 10^{9} \\cdot (1 \\ \\text{day}) \\\\\n&amp;= 3 \\cdot 10^{14} \\text{years}.\n\\end{align}\n$$</span></p>\n<p>That's a lot of time!</p>\n<p><strong>Claim 4.</strong> Nature has invested significant data in \u201ctraining\u201d humans.</p>\n<p>The argument here is similar to the previous claim: everything natural event (\u201cwhether it be the wind or the rain or the inner workings of a plant\u201d) is a piece of data that may have been used to \u201ctrain\u201d human beings. The sum of natural events that have been relevant to the training of humans has been large, so the amount of data that has been invested into the training of humans has also been large.</p>\n<p><strong>Argument.</strong> From the above four claims, we may deduce three plausible scenarios in regard to AGI:</p>\n<ol>\n<li><p>AGI will not be developed using machine learning methods.</p>\n</li>\n<li><p>AGI will be developed with machine learning methods that are many, many, MANY orders of magnitude more efficient than natural selection (in regards to data efficiency and computational efficiency). (See claims 3 and 4 for an idea of what \u201cmany, many, MANY\u201d means.)</p>\n</li>\n<li><p>AGI will be developed using computers that are many, many, MANY orders of magnitude more powerful than current computers.</p>\n</li>\n</ol>\n<p>Scenario 3 seems unlikely given the failure of Moore's law. Scenario 2 sounds more reasonable, but given how AI has developed in the past few decades, I would still say scenario 2 is rather unlikely. Currently, we don't have machine learning methods that perform significantly better than neural networks (+ variants like RNNs and CNNs) and gradient descent (+ variations like Adam). While these methods are undoubtedly better than the procedure of natural selection I described above, I don't think they are \u201cmany, many, MANY orders of magnitude\u201d more efficient, especially considering how inefficient the optimization of deep neural networks is. Therefore, scenario 1 is most likely to happen, at least in the near future.</p>\n"}, "2795": {"ParentId": 2781, "Score": 1, "Body": "<p>I pushed hard to increase to 4, and wanted 5, because we were getting crushed at one point, and one of our current mods was taking the brunt.</p>\n<p>Things seem to have normalized, such that, unless my fellow mods are calling for expansion, I'm ok with the present condition.</p>\n<p>I personally haven't had much time in the last couple of years, but I was also burned out from carrying the entire burden in the transition period before we got our new mods, who are have been instrumental in re-purposing toward the current, much more focused, stack.</p>\n<p>I think just the current structure and scope will allow us to continue to grow and improve, but it's a long term project of years and decades.</p>\n<p>If we start getting blitzed again, we can definitely hold a new election, but it's sort of a hassle, and it's not clear how many users want to carry that burden.  It takes a lot of commitment, and many of our best users are, quite frankly, much more valuable to the stack <em>not</em> having to deal with the BS mods sometimes have to deal with.</p>\n"}, "2796": {"ParentId": 2778, "Score": 1, "Body": "<p>I've grappled with this on rare occasions, where I can't undo unless the question or answer is edited. My metric for whether I'm going to edit, and probably piss someone off is:</p>\n<ul>\n<li>How much harm does it cause</li>\n</ul>\n<p>If it's trivial, I might leave it, especially if it's just an upvote.  But I think, in the case of accepted answers, where it would cause harm, one just has to bite the bullet and edit the post and remove the acceptance.</p>\n"}, "2797": {"ParentId": 2776, "Score": 1, "Body": "<p>My sense is that interest waxes and wanes over the course of years.  Sometimes the user becomes re-inspired and comes back, sometimes not.</p>\n<p>I have multiple stacks where I either have high current participation, or don't have time/inclination to think about.  This usually ping pongs with my core areas of interest.</p>\n<p>But you're on the right track that what we need to do is attract more qualified and earnest users.  My suggestion:</p>\n<ul>\n<li><strong>Post the Q&amp;As you find most rewarding on social media</strong></li>\n</ul>\n<p>Encourage others to do this.</p>\n<p>I'm not sure the wider AI community realizes what a great and reliable resource is Stack:AI.  And I've looked at the quality of AI information on less rigorous forums and Q&amp;A, such that, with certain exceptions cases, I stick to stack.</p>\n<p>See also: <a href=\"https://ai.meta.stackexchange.com/questions/1627/list-of-exemplary-questions-on-ai-theory\">List of exemplary questions on AI theory</a></p>\n"}, "2798": {"ParentId": 2755, "Score": 1, "Body": "<p>Absolutely!  This is an area where I have formal training, and can legitimate go back to proto-indo-european.  (But people typically don't like my analyses b/c they conflict with their own.)</p>\n<p>If you see any unanswered terminological question, or are interested in the etymology, this is an area of special focus for me in the tech industry and academia, as is the history of computing.</p>\n<p>Clear terminology is critical for any technical field, and good terminology is supported by etymology.</p>\n<p>One of my favorite topics is what &quot;Artificial&quot; and &quot;Intelligence&quot; mean, and what they mean together.  My research indicated the latter goes back to the pie *legh/-leg as &quot;discrimination in the sense of selection&quot;.  Think gatherers choosing which berries to gather from a set of berries, or hunters identifying the most vulnerable member in a herd.  (These are combinatorial problems in a naive sense, and definitely game theory problems\u2014maximizing the minimum reward, or minimizing-the-maximum loss.)  The Latin prefix &quot;inter&quot; means &quot;between&quot; or &quot;among&quot; in the sense of &quot;matters&quot;, originally legal, lexical and so forth, which is to say &quot;intellectual&quot;, because the Latin <em>lex</em> comes from the Greek <em>logos</em>.  I even argue that, as a function, it is a grounded symbol.  I express it M(u): &quot;in an action space, utility&quot;, which can then be extended as with Hutter&amp;Legg's formal definition of universal machine intelligence.</p>\n<p>I see other interesting etymologies. As a student of Norse mythology, I can't help but think about the Norns (Fates) when I see the word &quot;entanglement&quot;. Heisenberg pretty much coined it, if I recall correctly, and, because Old Norse, Standard German, and English all come from the Germanic branch, it translates quite precisely. I don't see this as a random choice, because H was talking about probabilities, which is a commentary on fate. The Norns wove (entangled) and cut (limit) the fates of human beings. I feel like Norse mythology allowed for free will on a local level (choosing to die in battle to gain entrance to Valhalla), as opposed to a global level (Ragnarok is predetermined.)</p>\n"}, "2799": {"ParentId": 2760, "Score": 0, "Body": "<p>I like this.  Go ahead and create it.  If other users have objections, we can always remove.</p>\n"}, "2800": {"ParentId": 2762, "Score": 1, "Body": "<p>Simple answer:</p>\n<ul>\n<li>Prior to nbro and Dennis, our scope was insanely broad</li>\n</ul>\n<p>This was because I was appointed mod by Stack when the prior mods left, knew there were issues, and felt that the community should decide what this stack needed to be.</p>\n<p>We had a few years of this, with varied success, but did manage to attract enough committed, expert users, to yield our current form.</p>\n<ul>\n<li>We worked incredibly hard to narrow the scope to increase utility</li>\n</ul>\n<p>I'm all for strategic expansion, at some point in the undetermined future, <em>iff</em> trusted users and mods agree.  Presently, I agree with nbro, but I like your energy and enthusiasm, hanugm.  Keep it coming!</p>\n"}, "2801": {"ParentId": 2749, "Score": 1, "Body": "<p>I don't have the time/focus/energy to do this, but, if I did, I would spam social media sites with the best Q&amp;As.</p>\n<p>It's blows my mind, but people actually got to places like Quora and reddit for information.  I'm not saying you can't occasionally finds pearls hidden under all the garbage, but it's rarely worth the effort.</p>\n<p>Users on other stacks used to claim we had no function, and should be subsumed into overlapping stack.  We disagreed.  <strong>Strongly.</strong></p>\n<p>Our scope, even narrowed, is still one of the widest\u2014our field overlaps pretty much every field in some way.  The related stacks could never deal with this potential depth.</p>\n<p>We can take questions on the social impacts and history and etymology, in addition to the mathematical treatment of AI theory.  We can discuss the philosophy, not just the practice.</p>\n<p>Can you talk about Searle or Minsky and their ideas on those other stack? Can you ask what was the first AI?  Or about what AI means? Nope.</p>\n"}, "2802": {"ParentId": 2746, "Score": 1, "Body": "<p>I think it depends also partly on the question.  If it's a formal question, or a hard science question, with a precise, provable answer, disclaimer would be good, and acceptance of downvotes if other's deem it incorrect.  (OK to remove also.)</p>\n<p>For fuzzy questions, which I often answer a lot of on other stacks, I'll directly say &quot;this is my guess&quot; before I make a supportable, well reasoned argument, because there is no source that has answered it, or there may even be differences of opinion.</p>\n<p>(&quot;What is the difference between a sword and a knife&quot; on martial arts, as an example. I've never been able to find an answer, but now that I've studied them sufficiently, significantly more than most people, I'm confident I can answer it, and the correctness of that answer will be validated by the argument.)</p>\n<p>The humanities stacks, such as Literature, don't often have objective answers, and are more about providing analysis which may benefit students and scholars.  Sometimes an OP will accept the one they most agree with, but, in those cases, all well reasoned answers are valuable.</p>\n<p>We have some fuzziness in the case of philosophy and social aspects, but those questions are more rare here.</p>\n"}, "2803": {"ParentId": 1720, "Score": 0, "Body": "<p>I personally think all of the game theories can comment at a much more fundamental level than search, because I see it as the root of all rational decision making, which is the basis for intelligence (utility in an action space.)</p>\n<p>I don't know that we need an explicit on-topic reference, but, in view of genetic algorithms/evolutionary game theory, I think we might want to consider it...</p>\n<p>(Because I'm doing a database program, I'm currently thinking about game theoretic approaches to data storage, structure, and management.  I don't know if it will be fruitful, but it will be interesting!)</p>\n<p>I'd want to specify that we're interested in game theory in regard to things like search, genetic algorithms, and rational agents, not specific real world economic questions like those explored by think tanks.</p>\n"}, "2808": {"ParentId": 2807, "Score": 2, "Body": "<p>Your answer can quote a statement or excerpt from another source or author, but it's a good idea to explain <strong>why</strong> you're quoting that excerpt or statement, and you should make it clear that you're quoting something, otherwise, it could be considered <strong>plagiarism</strong>, which is at least discouraged, and your answer can be deleted (as explained <a href=\"https://ai.stackexchange.com/help/referencing\">here</a>).</p>\n<p>To quote something, make sure to precede it with <code>&gt;</code> (explained <a href=\"https://ai.stackexchange.com/editing-help#simple-blockquotes\">here</a>), and provide the name of the source/author (and ideally also the link to it, especially if freely available). This is explained well <a href=\"https://ai.stackexchange.com/help/referencing\">here</a>, but I think you're already familiar with this.</p>\n<p>An example of my answers where I thought that quoting would have been a good idea is <a href=\"https://ai.stackexchange.com/a/23427/2444\">this one</a>, but <em>note that</em> I didn't just quote the book, but I also tried to answer the question <strong>specifically</strong> based on my interpretation of that quote and knowledge, and I also tried to explain why I am quoting the book. In this case, I was also more or less familiar with the topic, so I am relatively sure that my interpretation of the excerpt (but not just that, because that specific answer was also based on my knowledge of the topic) and specific answer are correct.</p>\n<p>A quote-only answer may also be discouraged because I think we want to be a source of original content (which doesn't necessarily mean &quot;original science&quot;, otherwise, you may just try publishing your new findings on a journal or conference proceedings; in any case, note that, in most cases, I came up with answers and solutions that I didn't find elsewhere; sometimes, you can find the partial answer to your question in a book or on the web, but not the <em>full</em> answer; for example, in <a href=\"https://ai.stackexchange.com/a/28566/2444\">this case</a>, I really tried to make the full derivation, but, without my previous knowledge of the topic, probably, I would not have been able to do it). I am not sure if this is a policy, but I think it's pretty clear that, if we all just copied from other sources, there would be no reason for us to exist (you can just search for your answer elsewhere).</p>\n"}, "2812": {"ParentId": 2811, "Score": 2, "Body": "<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence\" rel=\"nofollow noreferrer\">Ethics of artificial intelligence</a> is a new field</li>\n</ul>\n<p>This is a new area of moral philosophy that only became non-hypothetical when we have the processing and memory to achieve strong-narrow superintelligence around 2015.</p>\n<ul>\n<li>Neoluddism</li>\n</ul>\n<p>I don't mean this in a strictly negative way, but in terms of the core principle, which can be summarized as:</p>\n<blockquote>\n<p>New technologies create problems that cannot be predicted.</p>\n</blockquote>\n<p>The classic example is the &quot;blackening of London&quot; due to pollution beginning in the 1660's.  (See: <a href=\"https://www.tandfonline.com/doi/pdf/10.1080/00022470.1978.10470577\" rel=\"nofollow noreferrer\">Air Pollution in Industrializing England</a>, Brimblecombe, 1978)</p>\n<p>By contrast, the old-school <a href=\"https://en.wikipedia.org/wiki/Luddite\" rel=\"nofollow noreferrer\">Luddites</a> got it wrong about the <a href=\"https://en.wikipedia.org/wiki/Jacquard_machine\" rel=\"nofollow noreferrer\">Jaquard looms</a>.</p>\n<p>Not hypothetical, and one can argue supportably that the present social dysfunction is a largely a function of automated algorithmic decisionmaking (See: Facebook, Youtube, et al.)</p>\n<p>Key topics here involve voluntary human obsolescence\u2014offloading not only repetitive tasks, but <a href=\"https://en.wikipedia.org/wiki/WALL-E#Plot\" rel=\"nofollow noreferrer\">offloading competency</a> and responsibility (militarized drones as an example.)</p>\n<ul>\n<li>If strong Artificial General Intelligence is ever achieved, the question of personhood will become non-hypothetical</li>\n</ul>\n<p>There was already an attempt to list an algorithm as an inventor on a patent, which was rejected because the algorithm is not a &quot;natural person.&quot;  (<a href=\"https://www.jurist.org/news/2021/09/federal-court-rules-artificial-intelligence-cannot-be-an-inventor-under-us-patent-law/\" rel=\"nofollow noreferrer\">Thaler v. Hershfeld,  09/02/21</a>)</p>\n<p>This is a legal question but deeply philosophical.  What does it mean to be a person?</p>\n<ul>\n<li>The Grecian Room</li>\n</ul>\n<p>I'm calling to change the <a href=\"https://plato.stanford.edu/entries/chinese-room/\" rel=\"nofollow noreferrer\">unfortunate name</a> of this thought experiment to something more consistent with the mythology of AI.  (Phillip K. Dick, here understood as a narrative philosopher, wrote about the difference between <a href=\"https://en.wikipedia.org/wiki/Xenoglossy\" rel=\"nofollow noreferrer\">xenoglossia</a> and <a href=\"https://en.wikipedia.org/wiki/Speaking_in_tongues\" rel=\"nofollow noreferrer\">glossolalia</a>, which comment on Searle, in regard to Ancient Greek specifically. [See <a href=\"https://en.wikipedia.org/wiki/Valis_(novel)\" rel=\"nofollow noreferrer\">VALIS</a> trilogy.] Dick is a major narrative philosopher along with Asimov, <a href=\"https://en.wikipedia.org/wiki/Stanis%C5%82aw_Lem\" rel=\"nofollow noreferrer\">Lem</a>, and recently, Rajaniemi. Dick and <a href=\"https://en.wikipedia.org/wiki/I,_Robot\" rel=\"nofollow noreferrer\">As</a>i<a href=\"https://en.wikipedia.org/wiki/Foundation_series\" rel=\"nofollow noreferrer\">mov</a> have probably had more influence that Searle in the public understanding of AI. They use mythology of AI to explore social concepts in the manner of <a href=\"https://en.wikipedia.org/wiki/Atlantis\" rel=\"nofollow noreferrer\">Plato</a>.)</p>\n<p><em>There are more examples, so others should answer as well if I've missed anything.</em></p>\n"}, "2814": {"ParentId": 2810, "Score": 1, "Body": "<p>I think so.  But <strong>how you ask in important</strong>.</p>\n<ul>\n<li>Questions that simply produce a simple &quot;yes&quot; are not good questions</li>\n<li>Questions that produce a &quot;no&quot; might not be either</li>\n</ul>\n<p>i.e. <strong>avoid questions that may result in Boolean output.</strong></p>\n<p>Better to ask about some concept in general, not necessarily presenting your own knowledge, and let the answerer provide the details.</p>\n<ul>\n<li>It's almost better to do a self Q&amp;A, then let others vote and provide alternate answers.</li>\n</ul>\n<p>Think about it before you post, but I won't hold it against you if we find that some questions are unsuitable and must close.</p>\n<p>But don't spam question until you get a sense of what is a suitable way to ask, and, ideally, the community weighs in via voting.</p>\n<p>You have sufficient rep that you can take some hits, and you can always delete the question that get heavily downvoted.</p>\n<p>Maybe try one, gauge the result, then try another.</p>\n<ul>\n<li>We definitely need more questions, and questions on concepts and theory would be ideal.</li>\n</ul>\n"}, "2815": {"ParentId": 2813, "Score": 0, "Body": "<p>Whether or not people like this name, this is how it has been known in the AI community for many years, so I don't think we should relabel it. It's called the Chinese-Room argument because it questions/involves the &quot;understanding&quot; of the Chinese language, which many people think to be very difficult, more difficult than, for example, German or Russian. (Of course, for Chinese people, it might be easier than other languages, but maybe not necessarily). So, in a sense, this is a good name for the philosophical argument because it is suggestive/descriptive.</p>\n<p>I don't think it creates a negative perception of Asian people. I've never thought of that. Searle had to pick something that people would think that you really need &quot;understanding&quot; to deal with and you can't just manipulate symbols. The Chinese language was chosen probably because it may be difficult for many people.</p>\n"}, "2816": {"ParentId": 2811, "Score": 2, "Body": "<p>The philosophical aspects of AI are related to the following arguments, issues, or questions.</p>\n<ul>\n<li><p>Is it really possible to create an AGI?</p>\n</li>\n<li><p>Can a machine &quot;think&quot;?</p>\n<ul>\n<li>(One of the first people who asked this question, although he correctly thought to be ambiguous, was Alan Turing, in his <a href=\"https://academic.oup.com/mind/article/LIX/236/433/986238\" rel=\"nofollow noreferrer\">influencial paper</a>, which describes the Turing test)</li>\n</ul>\n</li>\n<li><p>Can a machine be conscious and/or self-aware?</p>\n<ul>\n<li>This raises the obvious question: what is consciousness and/or self-awareness, and could these &quot;things&quot; be implemented/replicated in software?</li>\n</ul>\n</li>\n<li><p>Can a machine have free will?</p>\n</li>\n<li><p>If we created an AGI, should we give &quot;rights&quot; to it?</p>\n</li>\n<li><p>Are humans and other animals (or organisms) also computers? Do we just compute or do we have something that isn't &quot;just&quot; computation?</p>\n</li>\n<li><p>Is intelligence just symbol manipulation?</p>\n</li>\n<li><p>If we created an AGI and it had the ability to self-improve, could it become so intelligent (i.e. become a super-intelligence) that we humans wouldn't understand anymore its intentions?</p>\n</li>\n</ul>\n<p>Some of these issues are very related. If you want to find more about this, you could read the related chapter in Norvig &amp; Russell's book.</p>\n"}, "2817": {"ParentId": 2813, "Score": 3, "Body": "<p>Of course it is also unfair on a large number of Chinese-speaking AI reseachers that the metaphor in Searle's argument makes less sense to them (imagine the &quot;English Room&quot;). I would support re-naming it for clarity in this case, separately to any concerns of causing offense.</p>\n<p>However, I don't think AI Stack Exchange or its meta site is the forum for renaming things, beyond noting the issue for reference (as the question does). AI Stack Exhange is not a leading/influencing site for AI researchers and writers.</p>\n<p>Our task is to be a repository of questions and answers. If someone asks &quot;What is the Chinese Room argument in AI?&quot; they would reasonably expect to find an answer here. No-one is going to ask &quot;What is the Graecian Room argument?&quot; or see any other name for the analogy that is associated with Searle.</p>\n<p>The best you can do here - and I note you have - is to make your alternative suggestion when answering a question on the topic. Until any influence on the subject spreads out to other sites and media such that a new name takes hold, then AI Stack Exchange should continue to refer to the name that Searle gave the problem, with maybe an aside or footnote with other suggestions, or maybe linking this meta question.</p>\n"}, "2819": {"ParentId": 2818, "Score": 2, "Body": "<blockquote>\n<p>Is on-topic ask about the lack of R tagged questions in ai.stackexchange?</p>\n</blockquote>\n<p>I am not sure I understand this question. If you're asking whether it would be on-topic/off-topic to ask a question on our main site about why we don't have many questions tagged with the R programming language, then the answer is &quot;yes, it would be off-topic&quot;. That question is better suited for meta (i.e. here).</p>\n<blockquote>\n<p>how can I reframe the question of why R is few used in AI? or all is off-topic?</p>\n</blockquote>\n<p>I think that asking something like</p>\n<blockquote>\n<p>Why isn't R widely used in AI?</p>\n</blockquote>\n<p>will lead to opinions. Some people will say that it's used in many cases, and other people will say &quot;Because Python is better&quot;, which I am not saying, of course, that is true or false.</p>\n<p>I think a question like</p>\n<blockquote>\n<p>What characteristic of the R language would make it a &quot;good&quot; language for AI?</p>\n</blockquote>\n<p>would be more suitable for our site. But we already have a similar question <a href=\"https://ai.stackexchange.com/q/13775/2444\">here</a>, and we closed it as off-topic. For some reason, I had also voted to close this post. However, we have other similar questions on programming languages that were not closed. For example, <a href=\"https://ai.stackexchange.com/q/6185/2444\">this one</a>.</p>\n<p>To be honest, I think <strong>we really need to clarify which type of questions on programming language would then be on-topic here on our on-topic page</strong>. This is a good time to do it.</p>\n<p>The <a href=\"https://ai.stackexchange.com/q/13775/2444\">first post</a> was probably closed because the OP was looking for a piece of advice on which language is best for data science. That will lead to opinions. One could say &quot;R is good because it has this data structure&quot;, but one could also say &quot;Python has also that data structure&quot;, and so on. So, this type of question, where one compares one language to the other, will lead to debates/opinions, not just in AI, but, in general, in computer science or software development (this has been the case, historically), so I would say that this type of question should be closed for these reasons, although they can be useful for many people. For example, I think that the answers to that <a href=\"https://ai.stackexchange.com/q/13775/2444\">first question</a> can be useful. In particular, in my answer, I try to list the strengths and weaknesses of both languages. Nevertheless, this type of question, as I said, can always lead to opinions and debates, so we should avoid it.</p>\n<p>I think that questions on programming languages that are related to the <strong>history of AI</strong> would and should be on-topic here, as questions related to the history of AI are on-topic here.</p>\n<p>For example,</p>\n<blockquote>\n<p>Why was LISP widely used in the early ages of AI? Which characteristics of the LISP language make it suitable for what people were doing in AI in the beginning?</p>\n</blockquote>\n<p>could be on-topic here. This question can be answered more objectively (I think we may already have a similar question on the site anyway, see <a href=\"https://ai.stackexchange.com/q/2236/2444\">here</a> and <a href=\"https://ai.stackexchange.com/q/77/2444\">here</a>).</p>\n"}, "2822": {"ParentId": 2821, "Score": 3, "Body": "<p>If you click on the &quot;Show activity on this post&quot; button (in red in the screenshot below)</p>\n<p><a href=\"https://i.stack.imgur.com/46cg7.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/46cg7.png\" alt=\"enter image description here\" /></a></p>\n<p>You should see the activity of the post.</p>\n<p>For example, if you click on that button of <a href=\"https://ai.stackexchange.com/q/10053/2444\">this post</a>, you should see this</p>\n<p><a href=\"https://i.stack.imgur.com/tqvoB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tqvoB.png\" alt=\"enter image description here\" /></a></p>\n<p>The purpose of the bot is partially suggested in the message written by the same</p>\n<blockquote>\n<p>This question has <strong>answers that may be good or bad</strong>; the system has marked it active so that they <strong>can be reviewed</strong>.</p>\n</blockquote>\n<p>So, the bot bumps posts that, for example, do not have an accepted answer or have answers but without votes so that people can review the answers and assess their quality.</p>\n<p>You have more info about this bot <a href=\"https://meta.stackoverflow.com/a/412121/3924118\">here</a>.</p>\n"}, "2827": {"ParentId": 2826, "Score": 2, "Body": "<p>The question is your example is a bit vague/ambiguous because it's not clear what you mean by &quot;perceive variables&quot;. So, that's the first problem with that question.</p>\n<p>Having said that, generally, I think that <strong>questions in the context of understanding theoretical AI/ML concepts (which includes mathematical notation and terminology used in AI) should be on-topic here, provided they have an objective answer and don't lead to just opinions</strong>.</p>\n<p>You already asked a question <a href=\"https://ai.stackexchange.com/q/23983/2444\">here</a> that falls into the category you're describing. How do people in AI imagine higher dimensions or objects in higher-dimensional spaces? The reason why this question is on-topic here is that you're specifically interested in how &quot;AI researchers&quot; approach this problem (so you assume that AI researchers approach this problem differently than other researchers, which may or not be the case), but, generally, an answer to these questions may also be applicable to other cases.</p>\n<p>So, here are my recommendations</p>\n<ul>\n<li><p>Don't ask mathematical questions (like &quot;what is a vector space?&quot;) and just put them in the context of machine learning as an excuse for making it on-topic here. If something is just purely mathematical, it may be a good idea to ask your question on Math Stack Exchange. It depends also on the type of answer you're looking for. Of course, on AI SE, you may find people with a different background than on Math SE, so you may get different types of answers here. If you think that something is done differently in AI or ML than in other fields, then you should ask your question here. For example, if you think that a &quot;vector space&quot; may have different connotations in AI/ML than in other fields (e.g. statistics) then you probably should clarify this in your post (e.g. I found that this article describes X as Y, but I thought X was Z in mathematics), so that people know why you're asking that question, which apparently is a question that should be asked on Math SE.</p>\n</li>\n<li><p>Try to formulate your questions so that they do not lead to opinions, but, preferably, for example, <strong>common practices/guidelines</strong>. If a question can lead to answers like &quot;In my opinion, I think you should view higher dimensions as X&quot;, then your question might have been formulated incorrectly or could be closed as opinion-based.</p>\n</li>\n</ul>\n"}, "2829": {"ParentId": 2825, "Score": 2, "Body": "<p>Indeed it will; we have just posted <a href=\"https://ai.meta.stackexchange.com/q/2828/1641\">an announcement</a> (as a separate post, seemed more sensible for visibility).</p>\n"}, "2830": {"ParentId": 2828, "Score": 2, "Body": "<p>Thanks for the update!</p>\n<p>Now I'm a bit confused because very recently, a diamond moderator at Medical Sciences Stack Exchange said that <a href=\"https://medicalsciences.meta.stackexchange.com/a/1313/16670\">one requirement was that at least 70% of the questions would have to be answered </a> for graduation out of Beta.</p>\n<p>Likewise, a diamond moderator at Freelancing Stack Exchange quoted the <a href=\"https://freelancing.meta.stackexchange.com/q/340/25010\">specific reason why they will be graduating</a>.</p>\n<p>Since AI doesn't have 70% of the questions answered, could you help us understand better like they did at Medical Science and Freelancing?</p>\n"}, "2832": {"ParentId": 2831, "Score": 1, "Body": "<p>Which question were you trying to edit?<br />\nI get exactly that message (in the iOS app) when I'm trying to submit a (suggested) edit on a post which already has a pending suggested edit. When using the website, you're blocked from composing the edit, but the mobile apps are different (which <a href=\"https://meta.stackexchange.com/q/348075/295232\">won't change</a>) and show an error only after trying to submit an edit.</p>\n"}, "2836": {"ParentId": 2835, "Score": 2, "Body": "<p>The problem is your <strong>wrong assumption</strong> (and, in my view, absurd accusation) that I copied from you. I did not copy your answer, which I didn't even know existed.</p>\n<p>As I wrote under your answer (which you just copied and pasted from Data Science SE), which was actually plagiarised from external sources (2 external websites)</p>\n<blockquote>\n<p>Note that I didn't even know that your answer existed on another site. I didn't even know that this question had also been asked on Data Science. So, I didn't copy from your answer, so I didn't plagiarise you, as you're attempting to demonstrate (with your flagging). In addition to that, you're not the author of those papers. Even if I had read your answer on the other site (which did not happen, again!), my answer is completely different from yours. Plagiarism happens you copy and paste and don't give proper attribution, which is not the case at all.</p>\n</blockquote>\n<p>The craziest thing is that you're accusing me of plagiarizing you when there's no evidence, while, in reality, you copied from external sources and you didn't give proper attribution, i.e. you plagiarised, which can be subject to suspension. In particular, in your original answer, you copied from <a href=\"https://www.techopedia.com/definition/32818/online-machine-learning\" rel=\"nofollow noreferrer\">this site</a> and <a href=\"https://vowpalwabbit.org/\" rel=\"nofollow noreferrer\">this site</a>.</p>\n<p>Having said that, losing 10+15=25 reputation points (which are the points that you gain by getting an answer upvoted once and accepted, which is the case with my answer that you're mentioning) doesn't change much for me. I've been contributing to this site for a long time and I only want that this site provides high-quality content, which is not plagiarised. <a href=\"https://ai.stackexchange.com/help/referencing\">Plagiarised content will be deleted</a>, which was the case with your partially plagiarised answer.</p>\n<p>In addition to that, cross-posted content is sometimes discouraged on SE sites, so we may just delete that post, given an answer was already given somewhere else. However, I don't think that's necessary (because cross-posting is not forbidden, but just discouraged) and this issue is orthogonal to your absurd accusation.</p>\n"}, "2838": {"ParentId": 2837, "Score": 3, "Body": "<p>Your answer was deleted along with the question, which was too broad and partially off-topic. Questions that are off-topic and are of no value to our community can be deleted by moderators. Our community focuses the <strong>theoretical aspects of artificial intelligence</strong>. Asking for books, sources, programming languages, etc., all at the same time is too broad, which can lead to poor answers, so this is discouraged.</p>\n<p>Please, read <a href=\"https://ai.stackexchange.com/help/deleted-questions\">Why and how are some questions deleted?</a>, which states</p>\n<blockquote>\n<p>Questions that are <strong>extremely off topic</strong>, or of <strong>very low quality</strong>, may be removed at the discretion of the community and <strong>moderators</strong>.</p>\n</blockquote>\n"}, "2840": {"ParentId": 2839, "Score": 2, "Body": "<p>As written in <a href=\"https://ai.meta.stackexchange.com/q/2837/2444\">my other answer</a>, this question was deleted because it was <strong>off-topic and unclear</strong>, so <strong>very poor</strong>. Programming questions are off-topic here. Please, take a look at <a href=\"https://ai.stackexchange.com/help/on-topic\">our on-topic page</a>.</p>\n"}, "2842": {"ParentId": 2841, "Score": 2, "Body": "<p>This answer was deleted because you copied content from a paper without clarifying which parts you copied, so you basically tried to make it seem that the content in that answer was yours, while, in reality, you copied many things (if not everything) from that paper, i.e. plagiarism.</p>\n<p>Plagiarised content, as I explain in <a href=\"https://ai.meta.stackexchange.com/a/2836/2444\">my other answer</a>, is subject to deletion. People that plagiarise can also be suspended, so, please, avoid doing this next time. Do not copy and paste content from external sources without clearly explaining which parts were taken from the external source.</p>\n<p>If you don't know how to quote certain parts from an external source, take a look at this: <a href=\"https://ai.stackexchange.com/help/referencing\">How to reference material written by others</a>.</p>\n<p>Moreover, ideally, you should not just quote an excerpt from a paper, but you should explain with your own words.</p>\n<p>Having said that, if you're not familiar with the topic, I would recommend that you do not attempt to provide an answer, in order to avoid spreading misinformation or misunderstandings. However, this is just my personal suggestion.</p>\n"}, "2843": {"ParentId": 2837, "Score": 1, "Body": "<p>Aside from being off-topic, the &quot;locked due historical significance&quot; seems rather dubious and definitely does not satisfy the <a href=\"https://ai.stackexchange.com/help/locked-posts\">reasons for locking a post in such a way listed here</a>. As hanugm rightfully pointed out in a comment to that now-deleted question, we already have plenty of much older questions of a similar nature with much more activity on them. We're not losing anything major by deleting this, so the deletion is fine.</p>\n"}, "2844": {"ParentId": 2841, "Score": 6, "Body": "<blockquote>\n<p>Is it general norms that a diamond moderator nbro can <strong>delete an answer to prevent a user from helping others or getting bounty points for their efforts</strong>?</p>\n</blockquote>\n<p>No, those reasons as highlighted in bold would not be valid reasons for deletion. There is no indication that these were actually the reasons for deletion in this case though.</p>\n<blockquote>\n<p>It has come to my attention my answer was deleted, <strong>without cause</strong></p>\n</blockquote>\n<p>It was not without cause. The reason for deletion (plagiarism, which is a valid reason) was already pointed out by nbro in a comment shortly before/after deletion, and if I'm not mistaken you as author of the original post should still be able to read that even though it was deleted since (just like how you can still read the post itself).</p>\n"}, "2845": {"ParentId": 2839, "Score": 5, "Body": "<p>As <a href=\"https://ai.meta.stackexchange.com/a/2840/1641\">nbro already wrote</a>, this question was both off-topic and of extremely poor quality, so deletion is fine.</p>\n<blockquote>\n<p>This question closed as off topic 2 months ago, A just and unbaised moderator would have done the right thing and transfer to relevant SE site instead of deleting recently.</p>\n</blockquote>\n<p>Probably the only valid target site to migrate towards would have been StackOverflow in this case. However, <a href=\"https://meta.stackexchange.com/a/10250/376651\">generally we do not want to migrate poor-quality questions</a>, which this question was. It showed no effort at all, did not demonstrate what the author already attempted, it's basically a &quot;please do my work for me&quot; question. It would have been massively downvoted or even again deleted over on StackOverflow too.</p>\n"}, "2848": {"ParentId": 2847, "Score": 1, "Body": "<p><a href=\"https://ai.stackexchange.com/help/locked-posts\">Here's the reason.</a></p>\n<blockquote>\n<p>An extremely <strong>popular</strong> question which is now considered <strong>inappropriate</strong> for the site may be locked for &quot;Historical Significance&quot;: this alters the appearance of the question, automatically locks all answers as well, and disables flagging completely. This lock should be reserved for cases where a <strong>cherished cultural artifact would otherwise be deleted</strong></p>\n</blockquote>\n<p>If you want, I can delete the post. However, I thought that, given it's related to RL, it may have some significance for us (but not much, in my view).</p>\n"}, "2852": {"ParentId": 2851, "Score": 3, "Body": "<p>If the answer contains plagiarised content, it should be deleted, because it can be a <a href=\"https://en.wikipedia.org/wiki/Copyright_infringement\" rel=\"nofollow noreferrer\">copyright infringement</a>. So, you should vote to delete it or flag it for a moderator to intervene. You should not upvote or accept it, because that may encourage the plagiarist to provide more plagiarised answers without people realizing it. Actually, I would say that you should downvote it to discourage the plagiarist.</p>\n<p><strong>We want to be a site of high-quality original answers/questions.</strong></p>\n<p>I would expect other sites to do the same, but, unfortunately, other sites don't care too much about this and let their users copy (e.g. once one of my questions was copied from someone on Quora and posted there too).</p>\n<p><a href=\"https://ai.stackexchange.com/help/licensing\">Our content</a> is licensed under <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" rel=\"nofollow noreferrer\">Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)</a>, which basically means that you can copy and share, but you need to give proper attribution and you must license your content that is based on ours under the same license, but there are other restrictions...</p>\n<p>So, in short, in case an answer is (even just partially) plagiarised and there's no evidence of giving proper attribution</p>\n<ol>\n<li>downvote,</li>\n<li>don't accept, and</li>\n<li>flag for the deletion or moderator intervention (so that they can delete the answer)</li>\n</ol>\n<p>Even if that answer answers your question. You may consider provide an answer to your own question <strong>with your own words</strong>, in that case, once you know the answer (because that other plagiarised answer will most likely be deleted).</p>\n"}, "2854": {"ParentId": 2853, "Score": 4, "Body": "<p>With respect to last year, here are a few things I would like to note</p>\n<ul>\n<li>The suggested edits by the community increased significantly, which is a good thing, as it suggests that the community starts to care more about the quality of the posts</li>\n<li>Fewer reopened questions by mods</li>\n<li>Fewer migrated questions by mods (I've been trying to avoid migrating posts, because those off-topic posts are usually poor)</li>\n<li>Slightly more questions closed by the community, which is a good thing, as it suggests that the community starts to close more off-topic, unclear, opinion-based, etc., questions, but we still need to work on this aspect a little bit more; there are still some questions that should have been closed that were not closed and occasionally some posts are voted to be closed, when, in reality, they should not be closed (this happens only sometimes, but people should carefully read the post before voting to close it).</li>\n<li>More posts locked by the community (but this was probably due to <a href=\"https://ai.stackexchange.com/users/-1/community\">user #-1</a>) and fewer by the mods</li>\n<li>Slightly more posts deleted by the mods, which seems to be consistent with the work I've been doing to clean up some posts that are not really valuable for the site</li>\n<li>Slightly fewer comments were flagged and deleted by the community (not sure if this is a good thing)</li>\n</ul>\n"}, "2856": {"ParentId": 2855, "Score": 4, "Body": "<p>I don't think you need to provide a custom edit summary <strong>for every edit</strong>, especially when you already have the privilege to edit posts automatically.</p>\n<p>In fact, if you have the privilege to automatically edit posts, then it means that, <strong>in theory</strong>, the community trusts you and that you're going to edit posts appropriately, which means that, for example, you will not make the post unclearer, introduce inappropriate tags or change the meaning of the question.</p>\n<p>In particular, unless you want, I would say that there's no need to provide an edit summary when you're just fixing typos or improving the language. However, if you're making a <strong>substantial edit</strong>, e.g. removing unnecessary details, changing all tags, completely rewriting the title, or even rewriting the question completely differently (but make sure that the meaning of the questions is the same!), then, in that case, I really encourage you to provide an edit comment, which summarises and <strong>motivates</strong> your edit. See <a href=\"https://ai.stackexchange.com/posts/34153/revisions\">this example</a>.</p>\n"}, "2857": {"ParentId": 2855, "Score": 3, "Body": "<p>If you're suggesting an edit, and this is from experience, a good, descriptive edit reason is going to ensure your edit goes through. I've had at least one edit rejected cause I had an excessively clever edit reason involving grumpy cat which made no sense. Even Random, mysterious edit reason writer in chief on Super User now gives a reason (in brackets) for <a href=\"https://superuser.com/users/307/random?tab=activity&amp;sort=revisions\">edits</a></p>\n<p>I would treat this as I would a commit to a git repository. Its <em>harder</em> to see a small edit at a glance than a big one. I'd also add as a active user on a larger site with a significant number of questions, you're not going to remember a post you did 10 years ago, and you might find yourself looking at something just as old for answers.  Spending the extra minute or so for a descriptive edit reason just like the ones you've posted above is an investment in the future</p>\n<p>So I would say yeah, there's value in it. Its not mandatory but its good practice.</p>\n"}, "2859": {"ParentId": 2858, "Score": 4, "Body": "<p>Everyone will have slightly different boundaries on what feels ok as edits to their original content. I'm usually fine with typo and layout corrections. Most of the edits I see are due to someone editing the question for typos or clarity, then editing my answer where it quotes the old version of the question. But I do also make plenty of typos myself, and appreciate it when someone finds and corrects one.</p>\n<p>The more subjective an edit is, the more it deserves an attempt at conversation first. Obvious typos and mistakes don't need any extra conversation, it is even wasteful of OP and editor's time. However, emphasis can subtly change the meaning of text, so is worth a second or so of thought, and maybe communication.</p>\n<p>I would say in this case, an edit to bold or otherwise emphasise a key phrase <em>done directly</em> could go too far. Although I would say that for me this is a small issue of politeness, and I would not be motivated to complain or do anything about it. As the OP, I get notified of edits, so if I felt the highlighting was not appropriate it is easy to roll back. If I was repsonsible for your example answer, I'd probably just leave your edit in place.</p>\n<p>As an original poster I would prefer if possible a comment with the suggestion to highlight the key phrase, or better still a statement about what is hard to read or understand about the answer, so I can decide on a suitable edit - it may not need to be highlighting.</p>\n<p>The following things make it OK (in my opinion) to directly edit to make this kind of improvement without discussion:</p>\n<ul>\n<li><p>The rest of the answer already uses bold highlighting for key phrases, and the one you want to highlight is an obvious candidate.</p>\n</li>\n<li><p>You are already making other edits for layout and clarity, and the highlighting is one small extra.</p>\n</li>\n<li><p>The answer is old, the original poster is not available, or has made the answer a community wiki.</p>\n</li>\n</ul>\n"}, "2860": {"ParentId": 2858, "Score": 6, "Body": "<p>I generally agree with Neil's suggestions.</p>\n<p>I would also like to emphasize that making or not a word or sentence bold is sometimes a</p>\n<ul>\n<li><strong>matter of style</strong> and</li>\n<li>it <strong>depends on what the OP or you want to emphasize</strong> (you see, here, <strong>I think</strong> that these two points are particularly important, so I made them bold).</li>\n</ul>\n<p>The problem is that what you want to emphasize might not be what the OP thinks is really important. Maybe you're just not familiar with a concept and you think that a word needs to be emphasized, while, in reality, it's not really that important (for the OP, at least).</p>\n<p>Having said that, I think that, especially <strong>when an answer is long</strong> and there are no subsections, titles, etc, but it's just plain text, it may be a good idea to edit the post to structure it in a way to emphasize the main points (which might also include making the most important words or parts of the answer in bold or maybe just italic). This would fall into the category of &quot;improving the clarity/presentation of the post.&quot; If an answer contains only 2-3 lines, that might not be necessary. So, as a rule of thumb, I would say that the longer the answer the more necessary emphasis might be. But keep in mind that, if you make everything bold, that would have the opposite effect of what you originally wanted.</p>\n<p>As the person with the highest number of edits on this site, I can say that I've edited posts for multiple reasons, including the ones mentioned in Neil's answers (and I've edited several of his answers for those same purposes). Sometimes, I've edited posts and the OP didn't like my edits. I would say that my edits usually improve the post (although, especially in the past, that might not always have been the case) and there are some stubborn users that don't really want their posts to be touched. In that case, it may be a good reason to flag the issue to a moderator or let the user know that, <a href=\"https://ai.stackexchange.com/help/editing\">if they are not comfortable with their posts being edited, maybe this site is not for them</a>. <strong>You can and should edit posts to improve the clarity, but the boundary between clarity and style is not always clear</strong>. For example, I noticed that some users like to make certain parts of his answers bold or maybe use sections and bullets, while others don't really care about that and don't even use paragraphs and spaces (but sometimes that might just be because they didn't have the time or will to spend 1 hour to write a beautiful answer, so it might still be a good idea to edit those posts to improve their clarity!).</p>\n<p>My final suggestions about your specific question are:</p>\n<ol>\n<li><p>if you really think something needs to be made bold (because the answer is plain text and not easy to understand the key takeaways), then edit it, make it bold, or change the structure.</p>\n</li>\n<li><p>If the OP rolls back your edit, then just don't start an edit war, i.e. don't edit again, and maybe leave a comment explaining why you think that your edit was opportune, and/or flag the answer for a moderator to intervene</p>\n</li>\n<li><p>If you think that you would need to change many things in an answer to make it readable or valuable, just downvote. Don't lose your time with those answers.</p>\n</li>\n</ol>\n"}, "2862": {"ParentId": 2861, "Score": 3, "Body": "<p>Closing a question is (usually) not a unilateral decision; it is usually only closed when multiple people have voted for it to be closed. An exception is that moderators can directly close, but that is not what happened here; three different people voted to close.</p>\n<p>It is of course possible that they each of slightly different reasons for voting to close / different details they think are missing. I can't speak for them. I have taken a look though and can explain what I would recommend taking a look at to improve the clarity:</p>\n<p><strong>The title is not descriptive, it does not summarise the core of the question:</strong> <em>&quot;Training an agent to choose a string from a list of strings&quot;</em>.</p>\n<p>That title somewhat sets the context of the question (it's about training an agent in an environment where it needs to choose strings from some list of candidates apparently), but not the core of the question. To me, <strong>the core of the question</strong> seems to be that you're curious about <strong>how the actions should be represented</strong>; should you represent them simply by giving every possible word in the vocabulary a unique index, or should you actually use a multi-dimensional representation where you represent actions as the arrays of characters / strings.</p>\n<p>Furthermore, directly just mentioning the name of the game you're interested in (Wordle) is probably more descriptive than the somewhat vague description of the task as &quot;to choose a string from a list of strings&quot;. Lots of other tasks could be described like that too. So, I think I would recommend a title more like:</p>\n<blockquote>\n<p><em>How to encode actions for training a Wordle agent?</em></p>\n</blockquote>\n<hr />\n<p>Apart from that, I think the main body of the question itself right now is reasonably clear. It is possible that some of the people who voted to close actually already did before you edited, or maybe they still see things they find unclear.</p>\n<p>One thing that could maybe help would be to more explicitly state whether you really really want to use a Reinforcement Learning solution (for instance, because you want to learn more about that specific field), or whether you're just looking for any AI solution in general. Otherwise, you get comments like Neil's first comment, for example, when people may believe that RL may not necessarily be the best/easiest solution, but are not sure whether or not that's important for your question.</p>\n"}, "2865": {"ParentId": 2864, "Score": 3, "Body": "<p>In my opinion, in principle, yes that could be on-topic. However, I would try to keep the following things in mind:</p>\n<ol>\n<li><p>The <em>&quot;whether&quot;</em> version of the question would likely not be great, if the expectation is that it's just going to receive a &quot;yes&quot; or a &quot;no&quot; as answer without any elaboration. That's not the type of question that we would want on the StackExchange network in general. So it'd have to lean more towards <em>&quot;how could we apply AI for this?&quot;</em>, or even <em>&quot;what would we have to be careful of / what could go wrong if we tried to apply AI for this?&quot;</em>.</p>\n</li>\n<li><p>Make sure that the question is actually about the AI perspective. From your example, if the question is just about whether or not there would exist a connection at all between the grammatical structure of a sentence and its &quot;rudeness&quot;, that would probably more so be a question about linguistics (or even culture more broadly), rather than AI. But if we assume that such patterns do indeed exist, a question about how AI could (reliably) pick up on that (or any other form of structure/patterns in text) would be more likely to be on-topic.</p>\n</li>\n<li><p>Make sure that the question is not overly broad. Especially for people who are not already experts at AI, I think it can be very difficult to not make it either overly broad, or too &quot;small&quot;. Like I mentioned in (1), the <em>&quot;whether&quot;</em> question with just a yes/no answer would not be interesting. But a pure <em>&quot;how can AI be used for this problem?&quot;</em> question would be too broad. Valid answers to that could be getting into essentially all AI techniques that have been developed for all kinds of Natural Language Processing tasks over the past several decades, but they could also get into huge practical answers about the required data collection, or they could more into the required software engineering to put the idea into practice... several different directions, and all very broad. We prefer specific, precise questions that can be answered in specific and targeted ways.</p>\n</li>\n</ol>\n"}, "2868": {"ParentId": 2867, "Score": 1, "Body": "<p>The community indeed needs at least 2 reasonably active moderators, so that when one isn't available there's the other (hopefully). Right now, Dennis is the only active one. I would love to see people that have always cared for the community (i.e. unconditionally and for at least 1-2 years) and have a good overall knowledge of the AI field to run for mod in the next elections.</p>\n<p>In my view, the best people for this role right now are: Neil Slatter, Edoardo Guerriero or David Ireland (although he hasn't been so active recently). Hopefully, at least one of them is interested in the role. Otherwise, honestly, right now, I don't see another good person for this role, as I believe a mod should be</p>\n<ul>\n<li>an active user (visit the site at least 1 a day and handle issues)</li>\n<li>have a good knowledge of AI</li>\n<li>be reasonably patient</li>\n<li>someone that, over the years, really showed to care for the community and AI (e.g. by writing answers, asking for clarifications, closing clearly off-topic posts, voting, etc.), so not someone that comes here every once in a while with a cocky attitude showing that they know how our site works or should work</li>\n<li>know quite well the scope of our site (if you're not familiar with it at this point, I don't think you're prepared to be a mod!) and how Stack Exchange sites usually work</li>\n<li>have <strong>not</strong> gotten into heated discussions with other users (including [old] moderators, like me) or have been suspended for irregularities or poor contributions (here or somewhere else)</li>\n</ul>\n<p>Essentially, a great mod for our community would be someone like Dennis himself, who meets all the criteria above.</p>\n"}, "2870": {"ParentId": 2866, "Score": 0, "Body": "<ul>\n<li><a href=\"https://www.reddit.com/r/MachineLearning/\" rel=\"nofollow noreferrer\">https://www.reddit.com/r/MachineLearning/</a></li>\n<li><a href=\"https://stats.stackexchange.com/\">https://stats.stackexchange.com/</a></li>\n</ul>\n"}, "2872": {"ParentId": 2871, "Score": 3, "Body": "<p>I think it is okay to keep intact as there is a fundamental difference between them both in the technical and historical arena.</p>\n<p>It is true that deep neural networks form at most a subset of neural networks but have a uniqueness in terms of representation as mentioned in <a href=\"https://proceedings.mlr.press/v28/bengio13.html\" rel=\"nofollow noreferrer\">this quote</a></p>\n<blockquote>\n<p>It has been hypothesized, and supported with experimental evidence,\nthat deeper representations, when well trained, tend to do a better\njob at disentangling the underlying factors of variation.</p>\n</blockquote>\n<p>Although your proposal is considerable, most people are habituated to using neural networks for generic architectures as well as for those with fewer layers and deep neural networks for more focused architectures. So, I believe that it will be useful to keep them intact as it attracts more questions from deep neural networks with few tags attached.</p>\n"}, "2874": {"ParentId": 2873, "Score": 3, "Body": "<p>Often in elections, there's a questionnaire compiled by the community full of similar questions to the ones you've posted that candidates are encouraged to answer. Since this is technically a pro-tem election, that didn't happen this time.</p>\n<p>During the &quot;nomination&quot; phase of the election, you can leave comments on the nominations. Once voting has opened, that's no longer an option, unfortunately.</p>\n<p>I personally can be found in <a href=\"https://chat.stackexchange.com/rooms/43371/the-singularity\">The Singularity</a>, which is the main chat room for Artificial Intelligence Stack Exchange, and am willing to answer questions posed there.</p>\n<hr />\n<p>As for how many moderators are being elected, on the top right of the /election page it says this:</p>\n<blockquote>\n<p>candidates 6 | positions 1</p>\n</blockquote>\n<p>There are six candidates running; one will be selected to be added to the moderator team.</p>\n"}, "2875": {"ParentId": 2873, "Score": 0, "Body": "<p>During the nomination phase, you could interact with the candidates. Unfortunately, I was the only one to do so, i.e. I was the only one to ask clarification questions, and I asked clarification questions to all of them (but Mithical, which I interacted with in our chat room and I knew them a little bit since I was once a mod too). So, it seems that almost nobody is interested in selecting the right person for this mod role...</p>\n<p>I wish people could still see the comments, but, anyway, 2 people didn't really address my concerns at all (most of them are about their activity and contributions to the site, which were lacking or poor). I will write here their names because I think it's important for the community to choose the best candidate: quintumnia and Simbarashe Timothy Motsi. The other candidates tried, to some extent, to address my concerns, but I was not fully satisfied with their answers...</p>\n<p>Personally, I think most nominations/candidates are not suitable for the role because, actually, all of them have been inactive for many years or never contributed to the site at all in any way, and only became active to nominate themselves (can you believe this? your judgement here!!!) and only some of them have showed to have some knowledge of AI and only 1-2 know how SE really works and seem to have an idea of what it means to be a mod.</p>\n"}, "2877": {"ParentId": 2876, "Score": 3, "Body": "<p>Sounds good, I just suggested (and approved) them. Non-mods should still be able to suggest and vote on suggestions for synonyms by the way! But I guess only mods can circumvent the votes and just approve them right away, which does make things faster..</p>\n"}, "2883": {"ParentId": 2882, "Score": 9, "Body": "<p>Thank you all for putting your trust in me as a moderator! I look forward to helping with the upkeep of the site with my fancy new powers and making sure the site stays healthy alongside the existing team. :)</p>\n"}, "2885": {"ParentId": 2884, "Score": 5, "Body": "<p>Many of those have already been set up as synonyms of each other. You can see this by searching for &quot;gradient&quot; on <a href=\"https://ai.stackexchange.com/tags/synonyms\">the synonyms page</a>.</p>\n<p>I would say that there is no substantial difference between <code>gradient-methods</code>, <code>gradient-based-methods</code>, <code>gradient-based-algorithms</code>, and <code>gradient-algorithms</code>. These have all already been set up as synonyms though, so these are fine.</p>\n<p>Similarly, <code>policy-gradient-methods</code> and <code>policy-gradients</code> are already synonyms. They are different from the four tags mentioned above though, which is correct as far as I'm concerned. Policy gradients refers to a specific type of family of algorithms in Reinforcement Learning, whereas all the &quot;gradient-based&quot; things without explicit reference to &quot;policy&quot; can more generally just refer to pretty much anything that uses gradients (like, Stochastic Gradient Descent).</p>\n<p>Finally, there's <code>policy-gradient-theorem</code>. This is certainly closely related to policy gradients, but in my opinion sufficiently different. There is a single specific theorem with that name, so this tag would be solely for questions about that theorem (or its proof). The <code>policy-gradients</code> tag can be more generally for any question about policy gradient algorithms (not just theoretical ones about the original theorem).</p>\n<p>In conclusion, as far as I can see there's no need for any changes here. It's better to have the tags already set up as synonyms (such that they automatically get mapped if users type them to a single target), rather than deleting them (because then they might re-appear if users type them in again).</p>\n"}, "2897": {"ParentId": 2896, "Score": 2, "Body": "<p>I'm sorry you feel that way. Instructions for how to delete your account may be found <a href=\"https://ai.stackexchange.com/help/deleting-account\">on this page of the Help Center</a>.</p>\n"}, "2899": {"ParentId": 2898, "Score": 2, "Body": "<p>Generally speaking it is the <a href=\"https://meta.stackexchange.com/search?q=homework+tag\">advice on MSE</a> to not allow the <a href=\"https://ai.stackexchange.com/questions/tagged/homework\" class=\"post-tag\" title=\"show questions tagged &#39;homework&#39;\" aria-label=\"show questions tagged &#39;homework&#39;\" rel=\"tag\" aria-labelledby=\"homework-container\">homework</a> tag (mostly applicable to SO), <em><strong>but</strong></em> there is an important exception: <a href=\"https://meta.stackexchange.com/a/165683/282094\">some sites prohibit full answers</a> to homework questions.</p>\n<p>Of course, should we disallow the tag, <a href=\"https://meta.stackexchange.com/q/19018/282094\">moderators can ban</a> the tag's usage.</p>\n<p>This is the <a href=\"https://ai.stackexchange.com/q/10910/17742\">first non-closed usage</a>, it seems helpful; as indicated by the discussion there.</p>\n<p>Here are three examples were someone added the tag with an edit (<a href=\"https://ai.stackexchange.com/q/14032/17742\">1</a>, <a href=\"https://ai.stackexchange.com/q/21879/17742\">2</a>, <a href=\"https://ai.stackexchange.com/q/21885/17742\">3</a>), and then went on to offer what looks to be a complete answer; @Nbro may have thoughts on the usage of the tag.</p>\n<p>Other than that, the early usages of the tag seem helpful, assuming that we don't want to do people's homework for them.</p>\n"}, "2900": {"ParentId": 2898, "Score": -1, "Body": "<ul>\n<li><a href=\"https://quantumcomputing.stackexchange.com/questions/tagged/textbook-and-exercises\">Quantum Computing has the &quot;textbook-and-excerices&quot; tag</a>.</li>\n<li><a href=\"https://chemistry.stackexchange.com/questions/tagged/homework\">Chemistry has the &quot;homework&quot; tag</a> but it has been deprecated.</li>\n<li><a href=\"https://physics.stackexchange.com/questions/tagged/homework-and-exercises\">Physics has the &quot;homework-and-exercised&quot; tag</a> and it has <strong>22,000+ questions</strong>.</li>\n<li>I didn't see any &quot;homework&quot; or &quot;exercises&quot; tag on Mathematics, but I'm not sure if the search was just taking too long to work.</li>\n</ul>\n<p>If the homework tag here is burninated, it shouldn't be because SO burninated it, nor should it be for &quot;basically the same reasons&quot; as the ones SO used to justify burninating it. The tag should be burninated only if the <em><strong>consensus</strong></em> within <em><strong>this specific specific community</strong></em> is to do so.</p>\n<p>Luckily, the <a href=\"https://ai.stackexchange.com/questions/tagged/homework\" class=\"post-tag\" title=\"show questions tagged &#39;homework&#39;\" aria-label=\"show questions tagged &#39;homework&#39;\" rel=\"tag\" aria-labelledby=\"homework-container\">homework</a> tag here at AI only has 19 questions and 0 watchers so far, so it wouldn't be a big deal to burninate it, but I think the reason to do so has to be a good one (not just &quot;SO did it so we will do it too&quot;).</p>\n"}, "2907": {"ParentId": 2906, "Score": 1, "Body": "<p>I'm sorry to sound &quot;pesimistic&quot;: There is nothing that can be done in the short term to prevent that certain type of users post blatantly off-topic questions on SE sites.</p>\n<hr>\n<p>It looks that somehow certain type of users find the &quot;Ask question&quot; button and just start typing on the editable boxes ignoring any guidance provided in Ask question form other than the messages alerting them why the question cant' be posted.</p>\n<p>On Web Applications, I'm one of top ranked users there, there is a similar problem, there are a lot of questions about developing web applications, code only, complains, customer care / client service, recommendations questions. These kind of questions are off-topic as Web Applications is it focused only on <em>using</em> specific web applications.</p>\n<p>As this site, Web Applications, have community-specific close reasons that have being adapted from time to time to the most frequent tendencies of blatantly off-topic questions.</p>\n<p>P.S.</p>\n<ol>\n<li>So far on Web Applications we only have received two questions about ChatGPT, one about troubleshooing and another about installing code found in GitHub. Both type of questions are off-topic.</li>\n<li>On other sites the term &quot;spam&quot; is used for posts blatantly promoting external content. Other undesired posts are just called &quot;off-topic&quot; even those that only include a selfie.</li>\n</ol>\n"}, "2908": {"ParentId": 2898, "Score": 1, "Body": "<p>I believe this tag can be useful, and I think it should be kept, independently of the consensus on this topic that we see in meta or other SE sites. It doesn't really harm the site.</p>\n<p>The reason why I think it should be kept is simple:</p>\n<blockquote>\n<p>clearly, many of our visitors are students, and we may not want to give them the full answers to their homework problems/questions.</p>\n<p>Students may reformulate their questions in ways that do not look like homework questions and, in general, it may not be easy to distinguish a homework question/problem from a non-homework one, but, if someone decides to use this tag, they want to let us know that we probably shouldn't give them the complete answers, although one could still do that.</p>\n</blockquote>\n<p>Nevertheless, I don't really have a very strong opinion on this topic. If you want to remove it, it wouldn't also harm much the site.</p>\n"}, "2910": {"ParentId": 2909, "Score": 5, "Body": "<p>Artificial Intelligence Stack Exchange comes <a href=\"https://ai.meta.stackexchange.com/a/1144/145\">from the &quot;Science&quot; category of Area 51</a>. The site as a whole is designed for questions from a scientific, theoretical, social, historical, and ethical point of view; implementation and technical questions were not part of that.<br />\nAs the scope has evolved over the years, we've allowed more questions about the technical aspects of different AI and ML systems, but general consensus, as far as I understand, has remained that debugging and technical support questions are off-topic.</p>\n<p>The well-received questions about ChatGPT that you've linked are about the scientific background of the AI. Questions about how the backend works are coming from a scientific &quot;how does this work&quot;. Questions about using the interface are coming from a technical &quot;how do I use this&quot;. &quot;how does this work&quot; questions are generally on-topic; &quot;how do I use this&quot; are typically not.</p>\n<hr />\n<p>I migrated the question to Web Applications after browsing your <a href=\"https://webapps.stackexchange.com/help/on-topic\">on-topic page</a>. I saw that &quot;...any other website which behaves like an application&quot; was on-topic, and troubleshooting / errors didn't appear in the list of off-topic subjects. I'd recommend updating that page if such questions are indeed off-topic.</p>\n<p>The question has attracted about 50k views in its time being bounced across sites, so it's obviously a question that people are searching for. It's just unfortunate that there doesn't seem to be a SE site that it fits on.</p>\n"}, "2913": {"ParentId": 2912, "Score": 4, "Body": "<p>Closing questions is generally a &quot;community&quot; decision (voted on by members of the community), and the same is generally the case for reopening closed questions. <a href=\"https://meta.stackexchange.com/a/36423/376651\">This answer on meta.stackexchange explains the process</a>, including actions you can take to (help) initiate a re-open vote.</p>\n<p>One of those actions is editing the body of the question. I see you edited the body of your question once, but that was before it got closed. You also edited the title <em>after</em> it got closed, but that's just the title, not the body. Editing the body of the question would automatically enter your question into the queue where users with sufficiently high reputation can vote on whether or not to re-open. <strong>Of course, we do not want you to just do a tiny meaningless edit just for the sake of this: it should be an edit that actually addresses the reasons for closing.</strong></p>\n<p>As for your question in particular, I do believe that the edit you've made to the title does already help to turn your question into one that is more objectively answerable. After this edit, the focus of your question <em>if I'm going by the title</em> seems to be: <em>How could we (objectively) test this hypothesis?</em></p>\n<p>However, my impression is that there is a bit of a disconnect between the title and the body of the question still. The body of the question gives more of an impression of <em>&quot;I'm already convinced of this, can you change my mind?&quot;</em> In the body of your question, your point about capabilities that ChatGPT has, for which you are not sure how a neural network could pull that off, is objectively answerable. That's fine, although already discussed in existing questions, and already adequately answered and explained there, so there is some risk of the new question remaining closed as a duplicate of those.</p>\n<p>Asking about how likely it is for OpenAI not to follow some of its own recommended best practices, or how likely it is for them to lie or intentionally misrepresent or deceive through omission, is probably opinion-based and also not really on-topic for an AI website.</p>\n<p>There probably should not be a discussion or debate about who should have the burden of proof at all. If the question were objectively-answerable, and purely about &quot;how could this phenomenon be explained under either hypothesis&quot;, the debate of burden of proof would be nonsensical.</p>\n"}, "2916": {"ParentId": 2915, "Score": 3, "Body": "<p>We generally don't migrate questions unless they're off-topic on the site where they were originally asked. In this case, the question appears to be on-topic on MathOverflow, so migration to AI.SE isn't really on the table.</p>\n<p>Unfortunately, the cross-site linking and information sharing capabilities of the SE network are currently somewhat lacking. There's no real way to keep the question on MO and also have it linked somewhere here; such a feature simply doesn't exist.</p>\n<p>The question will show up on MO for someone searching for this question, though, and it's not like we're strangers to having AI-related content be spread out over several different sites. AI content can be found on Stack Overflow, Cross Validated, Open Data, and other SE sites. Until and unless SE improves its cross-site linking of related topics, it's just something we're going to have to live with.</p>\n"}, "2918": {"ParentId": 2917, "Score": 4, "Body": "<p>On the SE network as a whole, there's been a surge in AI-generated posts (especially using ChatGPT). Being a site <em>about</em> AI, we've attracted plenty of people who think it'd be a good idea to use AI to generate posts here.</p>\n<p>Our <a href=\"https://ai.meta.stackexchange.com/q/2905/145\">current policy</a> on AI-generated content is largely based on SO's and was implemented in response to the original surge of ChatGPT posts, which has slowed significantly (but not stopped).</p>\n<p>How would you handle AI-generated posts?</p>\n"}, "2921": {"ParentId": 2920, "Score": 2, "Body": "<p>Sure, creating a new tag like that sounds good to me. Short answer, but don't really have anything else to say... if you'd like to, please go ahead :)</p>\n"}, "2923": {"ParentId": 2922, "Score": 1, "Body": "<p>Thanks JNat. I will try to be as helpful as I can be.</p>\n"}, "2925": {"ParentId": 2924, "Score": 4, "Body": "<p>In principle, I think it's fine to have tags for specific models / programs if they are highly influential. A bit like how we have tags for <code>alphago</code> and <code>alphazero</code>, for example.</p>\n<p>However, I'm not quite sure where to draw the line between models that are &quot;sufficiently influential&quot; to warrant their own tags, and models that are not.</p>\n<p>There clearly are many questions right now that do have a model-specific tag, but actually aren't model-specific. I suppose a good start would be to simply start editing tags for such questions, and afterwards we can see how many model-specific tags actually still see much use.</p>\n"}, "2928": {"ParentId": 2927, "Score": 4, "Body": "<p>I don't think we would ever single out any particular application domain (I view art as one possible application domain for AI) as off-topic. Except probably if you get into illegal application domains. Anyway, art is not an issue here.</p>\n<p>We do consider questions that are about how to do something with a specific package, framework, library, program, etc. as off-topic though.</p>\n<blockquote>\n<p>&quot;How do I do inpainting with X package&quot; &quot;Why does my inpainting look weird with Y package&quot; &quot;How do I replicate this (insert picture here) art style in package Z&quot;</p>\n</blockquote>\n<p>So all of these example questions quoted above would be off-topic, because they are all about a specific X, Y, or Z.</p>\n<p>More general questions about things like algorithms, loss functions, neural network architectures, objective functions, etc., that you could use to train an inpainting model would be on-topic. But specifically asking e.g. which line of code to write for inpainting in a specific package would be off-topic.</p>\n"}, "2931": {"ParentId": 2930, "Score": 14, "Body": "<p>I don't personally have an extremely strong opinion, and would be open to hearing if the community disagrees.</p>\n<p>But right now, I'd lean more towards saying that prompt design / prompt engineering questions would often be off-topic here. Our site is primarily about AI itself, not about how to use tools that run AI internally, if that makes sense. Asking how best to design a prompt for a language model feels like it would be similar to... how to speak more clearly if Apple's Siri or Amazon's Alexa misunderstands your questions/commands. Or how best to play against or alongside an AI-based player in a multi-player game.</p>\n<p>The primary gray area where I could see some overlap is once you take a deep dive into how the model was trained or implemented in order to explain or hypothesize why a certain kind of prompt does or does not work well. But I expect that the vast majority of prompt design questions would not be like this.</p>\n"}, "2933": {"ParentId": 2932, "Score": 1, "Body": "<p><strong>Reviews are off-topic</strong> because they lead to opinions.</p>\n<p>Asking for (examples of) books or research papers on AI topics is on-topic.</p>\n<p>However, try to avoid  questions like &quot;What's <em>the best</em> book on X?&quot; because that can also lead to opinions. It's better to formulate these questions in a way that answers are not just based on taste but based on facts.</p>\n"}, "2935": {"ParentId": 2934, "Score": 2, "Body": "<p>&quot;Find me an external resource&quot; type questions are often considered off-topic across multiple Stack Exchange sites. Although some sites do encourage it, based on their remit.</p>\n<p>There are a few issues I can think of:</p>\n<ul>\n<li>It's hard to prove a negative, so you will very rarely get &quot;there is no such study&quot; answers, even though that could be the correct answer. Instead the question will remain unanswered, which is generally a statistic SE sites like to minimise.</li>\n<li>A correct answer that simply links to the external resource would be considered low quality.</li>\n<li>Published academic works can be behind paywalls.</li>\n<li>The results of a search for external resources can change over time, whilst an answer to a specific technical question may become more or less relevant, it should not expire as easily.</li>\n</ul>\n<p>As a question asker, you have a couple of ways to adjust your question to achieve <em>similar</em> results, but you have to shift your expectations away from obtaining links to papers to read up on a subject.</p>\n<p>You can ask any technical question, and suggest at the end &quot;Any links to academic papers on the subject would be appreciated&quot;, or similar hint about what you'd like to see.</p>\n<p>You can also phrase what you are looking for as a more direct question about the subject e.g. your example &quot;Are there any studies examining the impact of image order on the classification capabilities of Convolutional Neural Networks (CNNs)?&quot; becomes &quot;Does image order affect classification performance of CNNs?&quot;</p>\n<p>The example question is interesting, in that the answer would not refer to any studies of ordering image input to CNNs. That's because much earlier work showed that randomising dataset order for mini-batches was much better for performance. Chances are that no-one will have published a formal study of providing training data in a fixed sequential fashion for a CNN. So by asking for that, you cut yourself off from a useful technical answer of why that is a bad idea.</p>\n<hr />\n<p>In summary, I think Stack Exchange is not the correct service to collate results of literature searches. Answers can contain links to supporting literature as appropriate, but the original question should not be &quot;please find me a paper about X&quot;.</p>\n"}, "2937": {"ParentId": 2934, "Score": 1, "Body": "<blockquote>\n<p>In other words, are questions framed like, &quot;Are there any existing studies or research focusing on leveraging property P of model M?&quot; acceptable within the guidelines of this forum?</p>\n</blockquote>\n<p>That's acceptable to me. A good amount of research time is spent on finding relevant research papers, and therefore I would a correct answer that simply links to a relevant research paper as high quality. Good AI research is rarely behind paywalls, and even if when it is, it can still be accessed, e.g. via universities/library subscription or Sci-Hub, and it's not OP's fault when paper authors <a href=\"https://academia.stackexchange.com/q/51730/452\">decide</a> to support the <a href=\"https://academia.stackexchange.com/q/29923/452\">paywall industry</a>.</p>\n<p>Examples of reference-only answers:</p>\n<ul>\n<li><a href=\"https://ai.stackexchange.com/a/39570/4\">https://ai.stackexchange.com/a/39570/4</a></li>\n<li><a href=\"https://ai.stackexchange.com/a/42064/4\">https://ai.stackexchange.com/a/42064/4</a></li>\n<li><a href=\"https://ai.stackexchange.com/a/42052/4\">https://ai.stackexchange.com/a/42052/4</a></li>\n<li><a href=\"https://ai.stackexchange.com/a/41804/4\">https://ai.stackexchange.com/a/41804/4</a></li>\n</ul>\n<p>All of them have a strictly positive score and no downvotes. I didn't cherry-pick, I just looked at my latest answers.</p>\n"}, "2939": {"ParentId": 2938, "Score": 1, "Body": "<blockquote>\n<p>Where can I ask a question about formal logic?</p>\n</blockquote>\n<ul>\n<li><a href=\"https://philosophy.stackexchange.com/questions/tagged/logic\">https://philosophy.stackexchange.com/questions/tagged/logic</a></li>\n<li><a href=\"https://math.stackexchange.com/questions/tagged/logic\">https://math.stackexchange.com/questions/tagged/logic</a></li>\n<li><a href=\"https://cstheory.stackexchange.com/questions/tagged/lo.logic\">https://cstheory.stackexchange.com/questions/tagged/lo.logic</a></li>\n<li><a href=\"https://cs.stackexchange.com/questions/tagged/logic\">https://cs.stackexchange.com/questions/tagged/logic</a></li>\n</ul>\n"}, "2941": {"ParentId": 2940, "Score": 3, "Body": "<p>I'd say they'd probably be more suitable on legal SE, because I feel like answering such questions correctly would often require much more legal expertise than expertise of the inner workings of AI. But I would be open to being persuaded if our community at large disagrees.</p>\n"}, "2945": {"ParentId": 2944, "Score": 2, "Body": "<p>Maybe the wording in the close reason is not 100% precise. Sometimes questions about specific programs (especially high-profile ones like ChatGPT that dominate much of contemporary AI discourse, but also older ones like, say, DeepBlue) may be appropriate, but such questions should be about understanding how the AI algorithms behind them work, or explaining how certain phenomena (like hallucination in LLMs) follow from their inner workings.</p>\n<p>The question you linked that was closed, was not about anything like that. It was more like asking for reviews / recommendations to choose between two products, which is not directly about explaining any AI fundamentals, and also highly unlikely to have a single (and certainly not long-term-correct), objective answer.</p>\n<ul>\n<li><a href=\"https://ai.stackexchange.com/q/32477/1641\">What is the &quot;temperature&quot; in the GPT models?</a> : this is not about a single specific model, it's about a family of models, and it's really about how one of the algorithmic knobs (one of their hyperparameters) works.</li>\n<li><a href=\"https://ai.stackexchange.com/q/38220/1641\">Why is ChatGPT bad at math?</a> : this is about explaining why we observe a certain noteworthy phenomenon in a high-profile AI program, and requires an understanding of exactly how the training was done to answer.</li>\n<li><a href=\"https://ai.stackexchange.com/q/39619/1641\">Is GPT-4 based on GPT-3 or was it trained from the scratch?</a> : what was the training procedure/algorithm (of programs for which there were actually scientific publications / technical reports detailing this to some extent)?</li>\n</ul>\n<p>etc. I didn't go through every single example you listed, and of course it is possible that some slipped through that probably should be closed, but I think this should explain most of them.</p>\n"}, "2947": {"ParentId": 2946, "Score": 1, "Body": "<p>I don't think I have a definitive answer, and would be happy to have community input shaping the answer to this question.</p>\n<p>Personally, I think I would be okay with keeping this on-topic. For me, the key difference between your earlier question (comparing products) and these SOTA questions, is that the latter are more about the algorithms/fundamental AI techniques, rather than specific products.</p>\n<p>With products, it no longer becomes just about the performance of the algorithm, but also all kinds of surrounding non-AI things such as the price being charged, the convenience of the user interface built around it, the brand, etc. Product-related questions also have a greater risk of attracting answers from people with hidden motives, such as people who want to advertise/recommend something they're affiliated with, or negatively review products from companies they don't like for non-AI reasons.</p>\n<p>I do see the risk though that <em>&quot;What is the SOTA in X?&quot;</em> questions will often have the correct answer just being &quot;it depends&quot; (though, then a good answer could still elaborate on what it depends on and why and how), and will also have correct answers becoming outdated over time.</p>\n"}}