# 1ï¼šå¦‚æœåªæ˜¯æµ‹è¯•æœ¬åœ°åŸæ¨¡å‹ï¼šMistral-7Bçš„å›ç­”æ•ˆæœï¼Œç›´æ¥è¿è¡Œè¿™ä¸ªæ–‡ä»¶å³å¯ã€‚ç„¶åä¼šåŠ è½½model_loader.pyå’Œæ€ç»´é“¾çš„inference.pyæ–‡ä»¶ï¼Œè¿›è¡Œå›ç­”è¾“å‡ºã€‚
# 2ï¼šå¦‚æœç»è¿‡Loraå¾®è°ƒå’ŒPPOè®­ç»ƒåçš„å›ç­”æ•ˆæœï¼Œåªéœ€è¦åœ¨æ€ç»´é“¾æ–‡ä»¶inference.pyæ”¹MODEL_NAMEå³å¯ï¼Œæ¯”å¦‚å¾®è°ƒåçš„æ¨¡å‹åæ˜¯ï¼š./merged_mistralï¼ŒPPOè®­ç»ƒåçš„æ¨¡å‹æ˜¯ï¼š./ppo_optimized_modelã€‚

import gradio as gr
from inference import generate_response
from model_loader import load_model

# åŠ è½½æ¨¡å‹
model, tokenizer = load_model()

# å®šä¹‰å¯¹è¯å‡½æ•°
def chat(question):
    response = generate_response(model, tokenizer, question)
    return response

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("# ğŸ¤– AI Chatbot - åŸºäºä½ çš„å¾®è°ƒæ¨¡å‹")
    gr.Markdown("è¾“å…¥ä½ çš„é—®é¢˜ï¼Œæ¨¡å‹ä¼šç»™å‡ºç­”æ¡ˆ")

    with gr.Row():
        input_text = gr.Textbox(label="ä½ çš„é—®é¢˜", placeholder="è¯·è¾“å…¥é—®é¢˜...")
        output_text = gr.Textbox(label="æ¨¡å‹å›ç­”", interactive=True)

    submit_button = gr.Button("å‘é€")

    # ç»‘å®šäº¤äº’é€»è¾‘
    submit_button.click(fn=chat, inputs=[input_text], outputs=[output_text])

# è¿è¡Œ Gradio Web ç•Œé¢
if __name__ == "__main__":
    demo.launch(share=True)
